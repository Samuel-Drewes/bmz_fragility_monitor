{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4d85ca2",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8036826",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# General\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "# Data Analysis\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "\n",
    "\n",
    "# WBAPI\n",
    "\n",
    "import wbgapi as wb\n",
    "\n",
    "# Data Processing\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Aesthetic\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class color:\n",
    "   BOLD = '\\033[1m'\n",
    "   END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934e23af",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Manual Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "289ba8bd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vdem_df = pd.read_csv(\"../data/vdem/V-Dem-CY-Full+Others-v13.csv\", usecols=['country_text_id', 'v2regsupgroupssize', 'year'])\n",
    "\n",
    "owid_freedom_of_expression_df = pd.read_csv('../data/owid/freedom-of-expression-index.csv')\n",
    "\n",
    "owid_pa_index_df = pd.read_csv('../data/owid/rigorous-and-impartial-public-administration-index.csv')\n",
    "\n",
    "owid_state_control_df = pd.read_csv('../data/owid/percentage-of-territory-controlled-by-government.csv')\n",
    "\n",
    "acled_df = pd.read_csv('../data/acled/2023_all_data.csv', usecols= ['event_type', 'country', 'fatalities', 'population_best', 'year', 'iso'])\n",
    "\n",
    "nd_df = pd.read_csv('../data/nd/gain.csv')\n",
    "\n",
    "unhcr_df = pd.read_csv('../data/population.csv')\n",
    "\n",
    "geo_df = pd.read_csv('../data/geodata.csv')\n",
    "\n",
    "iso_list = pd.read_csv(\"../data/all.csv\", usecols= ['name', 'alpha-3', 'country-code'])\n",
    "\n",
    "manual_data = {\n",
    "    'V-DEM': vdem_df,\n",
    "    'OWiD': {\n",
    "        'Public Administration Index': owid_pa_index_df,\n",
    "        'Freedom of Expression Index': owid_freedom_of_expression_df,\n",
    "        'State Control over Territory': owid_state_control_df\n",
    "    },\n",
    "    'ACLED': acled_df,\n",
    "    'ND': nd_df,\n",
    "    'UNHCR': unhcr_df,\n",
    "    'iso_list': iso_list,\n",
    "    'geodata': geo_df\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44b9d11",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Fragility Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dde8e7d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dimension_weights = {\n",
    "    'G': 3,\n",
    "    'S': 2,\n",
    "    'I': 2,\n",
    "    'C': 3,\n",
    "    'E': 1,\n",
    "    'R': 1\n",
    "}\n",
    "\n",
    "indicator_dictionary = {\n",
    "    'G': {\n",
    "        1:['V-DEM', 'Size of Regime Support Group', 3],\n",
    "        2:['OWiD', 'Public Administration Index', 2],\n",
    "        3:['WB', 'Control of Corruption: Estimate', 2],\n",
    "        4:['WB', 'Rule of Law: Estimate', 2],\n",
    "        5:['WB', 'Tax Revenue', 2, slice(1,2)],\n",
    "        6:['WB', 'Proportion of Seats Held by Women', 1],\n",
    "        7:['OWiD', 'Freedom of Expression Index', 1]\n",
    "    },\n",
    "    'S': {\n",
    "        1:['WB', 'Gini Index', -3],\n",
    "        2:['WB', 'Inflation, Consumer Prices', -2],\n",
    "        3:['WB', 'Unemployment, Total', -2, slice(1,2)],\n",
    "        4:['WB', 'Women Business and the Law Index', 2],\n",
    "        5:['ACLED', 'Protest Count', -2],\n",
    "        6:['WB', 'Age Dependency Ratio', -1, slice(0,1)],\n",
    "        7:['WB', 'Ease of Doing Business Score', 1]\n",
    "    },\n",
    "    'I': {\n",
    "        1:['WB', 'GDP per Capita', 3, slice(0,1)],\n",
    "        2:['WB', 'Poverty Gap at $2.15 a Day', -3],\n",
    "        3:['WB', 'Human Capital Index', 2, slice(0,1)],\n",
    "        4:['WB', 'Women who Believe a Husband is Justified in Beating his Wife', -2, slice(4,5)],\n",
    "        5:['WB', 'Current Health Expenditure per Capita, PPP', 2],\n",
    "        6:[],\n",
    "        7:[]\n",
    "    },\n",
    "    'C': {\n",
    "        1:['ACLED', 'Battle Related Fatalities', -3],\n",
    "        2:[],\n",
    "        3:['OWiD', 'State Control over Territory', 2],\n",
    "        4:['WB', 'Intentional homicides', -2, slice(2,3)],\n",
    "        5:[],\n",
    "        6:[],\n",
    "        7:[]\n",
    "    },\n",
    "    'E': {\n",
    "        1:['ND', 'GAIN Index', 3],\n",
    "        2:[],\n",
    "        3:[],\n",
    "        4:[],\n",
    "        5:[],\n",
    "        6:[],\n",
    "        7:[]\n",
    "    },\n",
    "    'R': {\n",
    "        1:['ACLED', 'Violence in Neighbouring States', -3],\n",
    "        2:['UNHCR', 'Refugee In-Flow', -2],\n",
    "        3:['WB','Total Natural Resources Rents', -1],\n",
    "        4:[],\n",
    "        5:[],\n",
    "        6:[],\n",
    "        7:[]\n",
    "    }\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e11bef8",
   "metadata": {},
   "source": [
    "# Data Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd81b23c",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## WB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad9f8ace",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def indicator_to_df(query, specify = False):\n",
    "\n",
    "    # Function to get indicator code\n",
    "\n",
    "    if specify:\n",
    "        return pd.DataFrame(wb.series.Series(q= query)).reset_index().iloc[specify]\n",
    "    return pd.DataFrame(wb.series.Series(q= query)).reset_index()\n",
    "\n",
    "def wb_data_completer(indicator, coverage_threshold = 0.85, years_to_check = 10, database = None, specify = False):\n",
    "    \n",
    "    def fetch_data_and_calculate_completeness(database_number):\n",
    "        \n",
    "        # Checks coverage of data\n",
    "        \n",
    "        wb.db = database_number\n",
    "        db_ind = indicator_to_df(indicator, specify = specify)\n",
    "        \n",
    "        if len(db_ind) == 0:  # If no data is found for this database\n",
    "            return 0  # Completeness is 0%\n",
    "        return float(wb.data.DataFrame(db_ind['index'], mrv=1).notna().mean())\n",
    "    \n",
    "    # Check which database to use if not specified\n",
    "    \n",
    "    if database is None:\n",
    "        \n",
    "        db2_complete = fetch_data_and_calculate_completeness(2)\n",
    "        db3_complete = fetch_data_and_calculate_completeness(3)\n",
    "        \n",
    "        database = 2 if db2_complete >= db3_complete or db3_complete == 0 else 3\n",
    "    \n",
    "    # Check coverage of most recent year\n",
    "    \n",
    "    wb.db = database\n",
    "    coverage_complete = fetch_data_and_calculate_completeness(database)\n",
    "    final_ind = indicator_to_df(indicator, specify = specify)\n",
    "        \n",
    "    # Return mrv = 1 if already passing data threshold\n",
    "    \n",
    "    if coverage_complete > coverage_threshold:\n",
    "        print(f\"\"\"Data for '{indicator}' found in WB Database {database}. Returning data for the most recent year. \n",
    "        Coverage = {round(coverage_complete, 4)*100}%, greater than selected threshold of {round(coverage_threshold, 4)*100}%.\\n\"\"\")\n",
    "        final_ind = wb.data.DataFrame(final_ind['index'], mrv=1)\n",
    "        final_ind.columns = ['Final Value']\n",
    "        \n",
    "        return final_ind\n",
    "    \n",
    "    # Otherwise go back number of years specified\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        print(f\"\"\"Data for '{indicator}' does not meet the coverage threshold of {coverage_threshold*100}% in WB Database {database}.\n",
    "        Extracting data from previous years.\"\"\")\n",
    "        \n",
    "        # Get Data\n",
    "        \n",
    "        \n",
    "        multiyear_df = wb.data.DataFrame(final_ind['index'], mrv=years_to_check)\n",
    "        \n",
    "        # Loop through DF in reverse order\n",
    "        \n",
    "        current_year = int(multiyear_df.columns[-1][2:])\n",
    "        all_years = list(range(current_year, current_year - years_to_check, -1)) \n",
    "        \n",
    "        for i, year in enumerate(all_years):\n",
    "            year_column = f'YR{year}'\n",
    "            \n",
    "            # Skip years that don't have a corresponding column in the DataFrame\n",
    "            \n",
    "            if year_column not in multiyear_df.columns:\n",
    "                continue \n",
    "                \n",
    "            # For the first year, initialize 'Final_Value' with its values\n",
    "            \n",
    "            if i == 0:\n",
    "                multiyear_df['Final_Value'] = multiyear_df[year_column]\n",
    "                \n",
    "            # Fill missing values in 'Final_Value' with the current year's data\n",
    " \n",
    "            else:\n",
    "                multiyear_df['Final_Value'] = multiyear_df['Final_Value'].fillna(multiyear_df[year_column])\n",
    "            \n",
    "            # Check data completeness for 'Final_Value' after potential filling\n",
    "            \n",
    "            data_coverage = multiyear_df['Final_Value'].notna().mean()\n",
    "            if data_coverage >= coverage_threshold:\n",
    "                print(f\"\"\"Achieved {round(data_coverage,4)*100}% data coverage by going back to data from {year},\n",
    "                exceeding minimum threshold of {coverage_threshold*100}%. Returning this dataframe.\\n\"\"\")\n",
    "                break\n",
    "                \n",
    "        # Return Final DF\n",
    "                \n",
    "        if data_coverage < coverage_threshold:\n",
    "            \n",
    "            print(f\"\"\"Data coverage at {round(data_coverage,4)*100}% after going back {years_to_check} years.\n",
    "            Failed to exceed minimum threshold of {coverage_threshold*100}%. Returning best dataframe anyway.\\n\"\"\")\n",
    "            \n",
    "            \n",
    "        return multiyear_df[['Final_Value']]\n",
    "\n",
    "def indicator_returner(query, dimension = 'dim', indicator = 'ind', specify = False):\n",
    "    \n",
    "    df = wb_data_completer(query, specify = specify)\n",
    "    df.columns = [f'ind_{dimension}{indicator}']\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a556672",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c60b961",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def scale_and_weight(merged_df, weight_list, single_dimension = True):\n",
    "    \n",
    "    # Scale\n",
    "    \n",
    "    if not single_dimension:\n",
    "        temp_df = merged_df[['iso']]\n",
    "        merged_df = merged_df.drop(columns = 'iso')\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_nums = scaler.fit_transform(merged_df)\n",
    "    scaled_df = pd.DataFrame(scaled_nums, columns=scaler.get_feature_names_out()).sub(0.5)\n",
    "    scaled_df.index = merged_df.index\n",
    "    \n",
    "    # Weight\n",
    "    \n",
    "    keys = scaled_df.columns\n",
    "    \n",
    "    weights = dict(zip(keys, weight_list))\n",
    "\n",
    "    weighted_df = pd.DataFrame()\n",
    "\n",
    "    for column, weight in weights.items():\n",
    "        weighted_df[column] = scaled_df[column] * weight\n",
    "        \n",
    "    # Weighted mean\n",
    "    \n",
    "    weighted_df['weighted_mean'] = weighted_df.mean(axis=1)\n",
    "    \n",
    "    if single_dimension:\n",
    "        weighted_df['weighted_mean'] = weighted_df.apply(lambda row: np.nan if row[keys].isnull().sum() > 2 else row['weighted_mean'], axis=1)\n",
    "    \n",
    "    weighted_df = weighted_df.sort_values('weighted_mean', ascending=False)\n",
    "    \n",
    "    if not single_dimension:\n",
    "        return weighted_df.join(temp_df)\n",
    "    \n",
    "    # Adding country names as index\n",
    "    \n",
    "    world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "    listylist = list(weighted_df.columns)\n",
    "    listylist.append('name')\n",
    "    listylist.append('iso_a3')\n",
    "    final_df = weighted_df.merge(world, left_index=True, right_on='iso_a3')[listylist].set_index('name')\n",
    "    \n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d107159",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Single Dimension Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15839794",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def dimension_data_loader(dimension_dict, dimension, manual_data):\n",
    "    \n",
    "    full_df = None\n",
    "    \n",
    "    for ind_num, ind_value in dimension_dict.items():\n",
    "        \n",
    "        if ind_value[0] == 'WB':\n",
    "            \n",
    "            if len(ind_value) == 3:\n",
    "            \n",
    "                ind_x = indicator_returner(ind_value[1], f\"{dimension}\", f\"{ind_num}\")\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                ind_x = indicator_returner(ind_value[1], f\"{dimension}\", f\"{ind_num}\", specify= ind_value[-1])\n",
    "                \n",
    "            \n",
    "        if ind_value[0] == 'V-DEM':\n",
    "            \n",
    "            rel_df = manual_data[ind_value[0]]\n",
    "            \n",
    "            ind_x = rel_df[rel_df['year'] == 2022][['country_text_id', 'v2regsupgroupssize']].set_index('country_text_id')\n",
    "            ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "            \n",
    "            \n",
    "        if ind_value[0] == 'OWiD':\n",
    "            \n",
    "            rel_df = manual_data[ind_value[0]]\n",
    "            \n",
    "            if ind_value[1] ==  'Public Administration Index':\n",
    "               \n",
    "                ind_x = rel_df[ind_value[1]]\n",
    "                ind_x = ind_x[ind_x['Year'] == 2022].set_index('Code')[['public_admin_vdem_owid']]\n",
    "                ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "               \n",
    "            if ind_value[1] ==  'Freedom of Expression Index':\n",
    "                ind_x = rel_df[ind_value[1]]\n",
    "                ind_x = ind_x[ind_x['Year'] == 2022].set_index('Code')[['freeexpr_vdem_owid']]\n",
    "                ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "                \n",
    "            if ind_value[1] ==  'State Control over Territory':\n",
    "                ind_x = rel_df[ind_value[1]]\n",
    "                ind_x = ind_x[ind_x['Year'] == 2022].set_index('Code')[['terr_contr_vdem_owid']]\n",
    "                ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "                \n",
    "                \n",
    "        if ind_value[0] == 'ACLED':\n",
    "            \n",
    "            rel_df = manual_data[ind_value[0]]\n",
    "            rel_df_2 = manual_data['iso_list']\n",
    "            \n",
    "            if ind_value[1] ==  'Protest Count':\n",
    "                \n",
    "                grouped_df = rel_df[rel_df['event_type'] == 'Protests'][['country', 'year', 'iso']].groupby(by = 'iso')\\\n",
    "                    .agg({'year': 'count'})\n",
    "                ind_x = grouped_df.merge(rel_df_2, left_index=True, right_on= 'country-code').set_index('alpha-3')[['year']]\n",
    "                ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "                \n",
    "                \n",
    "#                 aclest = manual_data['ACLED'][manual_data['ACLED']['event_type'] == 'Protests'][['country', 'year', 'iso']].groupby(by = 'iso')\\\n",
    "#                     .agg({'year': 'count'})\n",
    "#                 # aclest.merge(iso_list, how = 'left', left_index=True, right_on='country-code')\n",
    "#                 ind_x = aclest.merge(iso_list, how = 'left', left_index=True, right_on='country-code').set_index('alpha-3')[['year']]\n",
    "#                 ind_x\n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "            if ind_value[1] ==  'Battle Related Fatalities':\n",
    "                \n",
    "                grouped_df = rel_df[rel_df['event_type'].isin(['Explosions/Remote violence', 'Battles'])]\\\n",
    "                    [['country', 'fatalities', 'iso']].groupby(by = 'iso').agg({'fatalities': 'sum'})\n",
    "                ind_x = grouped_df.merge(rel_df_2, left_index=True, right_on= 'country-code', how = 'right').set_index('alpha-3')[['fatalities']]\n",
    "                ind_x['fatalities'] = ind_x['fatalities'].fillna(0)\n",
    "                ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "                \n",
    "            if ind_value[1] ==  'Violence in Neighbouring States':\n",
    "                \n",
    "                ## FIX ISO NOT NAME HERE\n",
    "                \n",
    "                grouped_df = rel_df.groupby(by = 'country').sum()[['fatalities']]\n",
    "                geo_df = manual_data['geodata']\n",
    "                merged_geo = geo_df.merge(grouped_df, left_on='country_border_name', right_index=True, how = 'left')\n",
    "                merged_grouped = merged_geo.groupby('country_name').sum()\n",
    "                ind_x = merged_grouped.merge(rel_df_2, left_index=True, right_on= 'name', how = 'right').set_index('alpha-3')[['fatalities']]\n",
    "                ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "                \n",
    "\n",
    "        if ind_value[0] == 'ND':\n",
    "            \n",
    "            rel_df = manual_data[ind_value[0]]\n",
    "            ind_x = rel_df.set_index('ISO3')[['2021']]\n",
    "            ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "            \n",
    "            \n",
    "        if ind_value[0] == 'UNHCR':\n",
    "            \n",
    "            rel_df = manual_data[ind_value[0]]\n",
    "            ind_x = rel_df.set_index(\"Country of asylum (ISO)\")[[\"Refugees under UNHCR's mandate\"]]\n",
    "            ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "            \n",
    "        \n",
    "        print(f'''Successfully loaded Indicator {dimension}{ind_num} from {ind_value[0]} Database\\n''')\n",
    "        \n",
    "        ### Merging DF ###\n",
    "               \n",
    "        if not isinstance(full_df, pd.DataFrame):\n",
    "            \n",
    "            full_df = ind_x\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            full_df = full_df.merge(ind_x, left_index = True, right_index = True, how = 'left')\n",
    "        \n",
    "    return full_df\n",
    "\n",
    "\n",
    "\n",
    "def dim_X_complete(indicator_dictionary, dimension, manual_data):\n",
    "    \n",
    "    dimension_dict = indicator_dictionary[dimension]\n",
    "    dimension_dict = {k: v for k, v in dimension_dict.items() if v}\n",
    "    \n",
    "    print(f\"\"\"\\n\\n\n",
    "    --------------------------Dimension {dimension}------------------------------\\n\n",
    "    \"\"\")\n",
    "    \n",
    "    ### Loading Data ###\n",
    "    \n",
    "    print(color.BOLD + \"Loading Data.....\\n\" + color.END)\n",
    "    \n",
    "    full_df = dimension_data_loader(dimension_dict, dimension, manual_data)\n",
    "    \n",
    "    ### Scaling and Weighting ###\n",
    "    \n",
    "    print (color.BOLD + \"Scaling & Weighting Data....\" + color.END)\n",
    "    \n",
    "    weight_list = []\n",
    "    for values in dimension_dict.values():\n",
    "        weight_list.append(values[2])\n",
    "        \n",
    "    full_df = scale_and_weight(full_df, weight_list)\n",
    "    \n",
    "    print(f\"\"\"\\n**Successfully loaded , merged, scaled, and weighted Dimension {dimension} Data**\\n\"\"\")\n",
    "    print(color.BOLD  + \"\"\"Overall Data Coverage:\"\"\" + color.END + \"(Weighted Mean missing if more than 2 indicators are missing for that Dimension..)\")\n",
    "    print(1- full_df.isna().sum()/len(full_df))\n",
    "\n",
    "    print(\"\"\"\\n\\n\n",
    "    ---------------------------------------------------------------------------\\n\\n\n",
    "    \n",
    "    \"\"\")\n",
    "            \n",
    "            \n",
    "    return full_df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13d1ab6",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## All Dimensions Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e82d4da5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def all_dimension_pipeline(indicator_dictionary, dimension_weights,manual_data):\n",
    "\n",
    "    all_dim_df = None\n",
    "\n",
    "    for key in indicator_dictionary.keys():\n",
    "\n",
    "        dimension_df = dim_X_complete(indicator_dictionary, key, manual_data)[['weighted_mean', 'iso_a3']]\n",
    "\n",
    "        dimension_df.columns = [f'Dimension_{key}', 'iso']\n",
    "\n",
    "        if not isinstance(all_dim_df, pd.DataFrame):\n",
    "\n",
    "            all_dim_df = dimension_df\n",
    "\n",
    "        else:\n",
    "\n",
    "            all_dim_df = all_dim_df.merge(dimension_df, left_on = 'iso', right_on = 'iso', how = 'left')\n",
    "        \n",
    "    overall_scoring_df = scale_and_weight(all_dim_df, dimension_weights.values(), single_dimension=False)\n",
    "            \n",
    "    submit_df = overall_scoring_df.merge(manual_data['iso_list'],how='left', left_on='iso', right_on='alpha-3')\\\n",
    "        .set_index('name').drop(columns='alpha-3')\n",
    "    \n",
    "    return submit_df\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937f3ffb",
   "metadata": {},
   "source": [
    "# To CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6268547b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "    --------------------------Dimension G------------------------------\n",
      "\n",
      "    \n",
      "\u001b[1mLoading Data.....\n",
      "\u001b[0m\n",
      "Successfully loaded Indicator G1 from V-DEM Database\n",
      "\n",
      "Successfully loaded Indicator G2 from OWiD Database\n",
      "\n",
      "Data for 'Control of Corruption: Estimate' found in WB Database 3. Returning data for the most recent year. \n",
      "        Coverage = 99.53%, greater than selected threshold of 85.0%.\n",
      "\n",
      "Successfully loaded Indicator G3 from WB Database\n",
      "\n",
      "Data for 'Rule of Law: Estimate' found in WB Database 3. Returning data for the most recent year. \n",
      "        Coverage = 99.53%, greater than selected threshold of 85.0%.\n",
      "\n",
      "Successfully loaded Indicator G4 from WB Database\n",
      "\n",
      "Data for 'Tax Revenue' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Data coverage at 67.67% after going back 10 years.\n",
      "            Failed to exceed minimum threshold of 85.0%. Returning best dataframe anyway.\n",
      "\n",
      "Successfully loaded Indicator G5 from WB Database\n",
      "\n",
      "Data for 'Proportion of Seats Held by Women' found in WB Database 2. Returning data for the most recent year. \n",
      "        Coverage = 88.35%, greater than selected threshold of 85.0%.\n",
      "\n",
      "Successfully loaded Indicator G6 from WB Database\n",
      "\n",
      "Successfully loaded Indicator G7 from OWiD Database\n",
      "\n",
      "\u001b[1mScaling & Weighting Data....\u001b[0m\n",
      "\n",
      "**Successfully loaded , merged, scaled, and weighted Dimension G Data**\n",
      "\n",
      "\u001b[1mOverall Data Coverage:\u001b[0m(Weighted Mean missing if more than 2 indicators are missing for that Dimension..)\n",
      "ind_G1           0.981707\n",
      "ind_G2           0.993902\n",
      "ind_G3           1.000000\n",
      "ind_G4           1.000000\n",
      "ind_G5           0.774390\n",
      "ind_G6           0.951220\n",
      "ind_G7           0.993902\n",
      "weighted_mean    0.993902\n",
      "iso_a3           1.000000\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "    ---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "    \n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "    --------------------------Dimension S------------------------------\n",
      "\n",
      "    \n",
      "\u001b[1mLoading Data.....\n",
      "\u001b[0m\n",
      "Data for 'Gini Index' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Data coverage at 53.76% after going back 10 years.\n",
      "            Failed to exceed minimum threshold of 85.0%. Returning best dataframe anyway.\n",
      "\n",
      "Successfully loaded Indicator S1 from WB Database\n",
      "\n",
      "Data for 'Inflation, Consumer Prices' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Achieved 85.34% data coverage by going back to data from 2018,\n",
      "                exceeding minimum threshold of 85.0%. Returning this dataframe.\n",
      "\n",
      "Successfully loaded Indicator S2 from WB Database\n",
      "\n",
      "Data for 'Unemployment, Total' found in WB Database 2. Returning data for the most recent year. \n",
      "        Coverage = 87.97%, greater than selected threshold of 85.0%.\n",
      "\n",
      "Successfully loaded Indicator S3 from WB Database\n",
      "\n",
      "Data for 'Women Business and the Law Index' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Data coverage at 75.56% after going back 10 years.\n",
      "            Failed to exceed minimum threshold of 85.0%. Returning best dataframe anyway.\n",
      "\n",
      "Successfully loaded Indicator S4 from WB Database\n",
      "\n",
      "Successfully loaded Indicator S5 from ACLED Database\n",
      "\n",
      "Data for 'Age Dependency Ratio' found in WB Database 2. Returning data for the most recent year. \n",
      "        Coverage = 99.62%, greater than selected threshold of 85.0%.\n",
      "\n",
      "Successfully loaded Indicator S6 from WB Database\n",
      "\n",
      "Data for 'Ease of Doing Business Score' found in WB Database 2. Returning data for the most recent year. \n",
      "        Coverage = 89.47%, greater than selected threshold of 85.0%.\n",
      "\n",
      "Successfully loaded Indicator S7 from WB Database\n",
      "\n",
      "\u001b[1mScaling & Weighting Data....\u001b[0m\n",
      "\n",
      "**Successfully loaded , merged, scaled, and weighted Dimension S Data**\n",
      "\n",
      "\u001b[1mOverall Data Coverage:\u001b[0m(Weighted Mean missing if more than 2 indicators are missing for that Dimension..)\n",
      "ind_S1           0.763314\n",
      "ind_S2           0.911243\n",
      "ind_S3           0.988166\n",
      "ind_S4           0.970414\n",
      "ind_S5           0.970414\n",
      "ind_S6           1.000000\n",
      "ind_S7           0.970414\n",
      "weighted_mean    0.964497\n",
      "iso_a3           1.000000\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "    ---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "    \n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "    --------------------------Dimension I------------------------------\n",
      "\n",
      "    \n",
      "\u001b[1mLoading Data.....\n",
      "\u001b[0m\n",
      "Data for 'GDP per Capita' found in WB Database 2. Returning data for the most recent year. \n",
      "        Coverage = 91.35%, greater than selected threshold of 85.0%.\n",
      "\n",
      "Successfully loaded Indicator I1 from WB Database\n",
      "\n",
      "Data for 'Poverty Gap at $2.15 a Day' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Data coverage at 59.019999999999996% after going back 10 years.\n",
      "            Failed to exceed minimum threshold of 85.0%. Returning best dataframe anyway.\n",
      "\n",
      "Successfully loaded Indicator I2 from WB Database\n",
      "\n",
      "Data for 'Human Capital Index' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Data coverage at 65.41% after going back 10 years.\n",
      "            Failed to exceed minimum threshold of 85.0%. Returning best dataframe anyway.\n",
      "\n",
      "Successfully loaded Indicator I3 from WB Database\n",
      "\n",
      "Data for 'Women who Believe a Husband is Justified in Beating his Wife' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Data coverage at 22.56% after going back 10 years.\n",
      "            Failed to exceed minimum threshold of 85.0%. Returning best dataframe anyway.\n",
      "\n",
      "Successfully loaded Indicator I4 from WB Database\n",
      "\n",
      "Data for 'Current Health Expenditure per Capita, PPP' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Achieved 87.59% data coverage by going back to data from 2020,\n",
      "                exceeding minimum threshold of 85.0%. Returning this dataframe.\n",
      "\n",
      "Successfully loaded Indicator I5 from WB Database\n",
      "\n",
      "\u001b[1mScaling & Weighting Data....\u001b[0m\n",
      "\n",
      "**Successfully loaded , merged, scaled, and weighted Dimension I Data**\n",
      "\n",
      "\u001b[1mOverall Data Coverage:\u001b[0m(Weighted Mean missing if more than 2 indicators are missing for that Dimension..)\n",
      "ind_I1           0.940828\n",
      "ind_I2           0.763314\n",
      "ind_I3           0.893491\n",
      "ind_I4           0.343195\n",
      "ind_I5           0.934911\n",
      "weighted_mean    0.899408\n",
      "iso_a3           1.000000\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "    ---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "    \n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "    --------------------------Dimension C------------------------------\n",
      "\n",
      "    \n",
      "\u001b[1mLoading Data.....\n",
      "\u001b[0m\n",
      "Successfully loaded Indicator C1 from ACLED Database\n",
      "\n",
      "Successfully loaded Indicator C3 from OWiD Database\n",
      "\n",
      "Data for 'Intentional homicides' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Data coverage at 84.21% after going back 10 years.\n",
      "            Failed to exceed minimum threshold of 85.0%. Returning best dataframe anyway.\n",
      "\n",
      "Successfully loaded Indicator C4 from WB Database\n",
      "\n",
      "\u001b[1mScaling & Weighting Data....\u001b[0m\n",
      "\n",
      "**Successfully loaded , merged, scaled, and weighted Dimension C Data**\n",
      "\n",
      "\u001b[1mOverall Data Coverage:\u001b[0m(Weighted Mean missing if more than 2 indicators are missing for that Dimension..)\n",
      "ind_C1           1.000000\n",
      "ind_C3           0.936782\n",
      "ind_C4           0.816092\n",
      "weighted_mean    1.000000\n",
      "iso_a3           1.000000\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "    ---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "    \n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "    --------------------------Dimension E------------------------------\n",
      "\n",
      "    \n",
      "\u001b[1mLoading Data.....\n",
      "\u001b[0m\n",
      "Successfully loaded Indicator E1 from ND Database\n",
      "\n",
      "\u001b[1mScaling & Weighting Data....\u001b[0m\n",
      "\n",
      "**Successfully loaded , merged, scaled, and weighted Dimension E Data**\n",
      "\n",
      "\u001b[1mOverall Data Coverage:\u001b[0m(Weighted Mean missing if more than 2 indicators are missing for that Dimension..)\n",
      "ind_E1           1.0\n",
      "weighted_mean    1.0\n",
      "iso_a3           1.0\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "    ---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "    \n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "    --------------------------Dimension R------------------------------\n",
      "\n",
      "    \n",
      "\u001b[1mLoading Data.....\n",
      "\u001b[0m\n",
      "Successfully loaded Indicator R1 from ACLED Database\n",
      "\n",
      "Successfully loaded Indicator R2 from UNHCR Database\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 'Total Natural Resources Rents' found in WB Database 2. Returning data for the most recent year. \n",
      "        Coverage = 92.11%, greater than selected threshold of 85.0%.\n",
      "\n",
      "Successfully loaded Indicator R3 from WB Database\n",
      "\n",
      "\u001b[1mScaling & Weighting Data....\u001b[0m\n",
      "\n",
      "**Successfully loaded , merged, scaled, and weighted Dimension R Data**\n",
      "\n",
      "\u001b[1mOverall Data Coverage:\u001b[0m(Weighted Mean missing if more than 2 indicators are missing for that Dimension..)\n",
      "ind_R1           0.954023\n",
      "ind_R2           0.879310\n",
      "ind_R3           0.913793\n",
      "weighted_mean    0.994253\n",
      "iso_a3           1.000000\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "    ---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "    \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "all_df = all_dimension_pipeline(indicator_dictionary=indicator_dictionary, dimension_weights=dimension_weights, manual_data=manual_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fad3a512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dimension_G</th>\n",
       "      <th>Dimension_S</th>\n",
       "      <th>Dimension_I</th>\n",
       "      <th>Dimension_C</th>\n",
       "      <th>Dimension_E</th>\n",
       "      <th>Dimension_R</th>\n",
       "      <th>weighted_mean</th>\n",
       "      <th>iso</th>\n",
       "      <th>country-code</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Taiwan, Province of China</th>\n",
       "      <td>1.291125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.395562</td>\n",
       "      <td>TWN</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Denmark</th>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.937877</td>\n",
       "      <td>0.791002</td>\n",
       "      <td>1.316087</td>\n",
       "      <td>0.435523</td>\n",
       "      <td>0.220542</td>\n",
       "      <td>0.866839</td>\n",
       "      <td>DNK</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Norway</th>\n",
       "      <td>1.219741</td>\n",
       "      <td>0.945633</td>\n",
       "      <td>0.948538</td>\n",
       "      <td>1.341439</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.191078</td>\n",
       "      <td>0.857738</td>\n",
       "      <td>NOR</td>\n",
       "      <td>578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Luxembourg</th>\n",
       "      <td>1.197979</td>\n",
       "      <td>0.791160</td>\n",
       "      <td>0.948023</td>\n",
       "      <td>1.347068</td>\n",
       "      <td>0.362738</td>\n",
       "      <td>0.227067</td>\n",
       "      <td>0.812339</td>\n",
       "      <td>LUX</td>\n",
       "      <td>442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sweden</th>\n",
       "      <td>1.387357</td>\n",
       "      <td>0.777471</td>\n",
       "      <td>0.774226</td>\n",
       "      <td>1.300390</td>\n",
       "      <td>0.425640</td>\n",
       "      <td>0.196767</td>\n",
       "      <td>0.810308</td>\n",
       "      <td>SWE</td>\n",
       "      <td>752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Myanmar</th>\n",
       "      <td>-1.189872</td>\n",
       "      <td>0.394712</td>\n",
       "      <td>-0.078129</td>\n",
       "      <td>-1.397936</td>\n",
       "      <td>-0.276679</td>\n",
       "      <td>0.148125</td>\n",
       "      <td>-0.399963</td>\n",
       "      <td>MMR</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Libya</th>\n",
       "      <td>-1.049753</td>\n",
       "      <td>-0.316533</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.636338</td>\n",
       "      <td>-0.166466</td>\n",
       "      <td>-0.206130</td>\n",
       "      <td>-0.475044</td>\n",
       "      <td>LBY</td>\n",
       "      <td>434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sudan</th>\n",
       "      <td>-0.861861</td>\n",
       "      <td>-0.840882</td>\n",
       "      <td>-0.282799</td>\n",
       "      <td>-0.670154</td>\n",
       "      <td>-0.377379</td>\n",
       "      <td>-0.027945</td>\n",
       "      <td>-0.510170</td>\n",
       "      <td>SDN</td>\n",
       "      <td>729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Somalia</th>\n",
       "      <td>-1.148255</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.396857</td>\n",
       "      <td>-0.358517</td>\n",
       "      <td>0.107331</td>\n",
       "      <td>-0.559260</td>\n",
       "      <td>SOM</td>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Sudan</th>\n",
       "      <td>-1.223234</td>\n",
       "      <td>-0.186487</td>\n",
       "      <td>-0.893408</td>\n",
       "      <td>-0.517689</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.178028</td>\n",
       "      <td>-0.599769</td>\n",
       "      <td>SSD</td>\n",
       "      <td>728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Dimension_G  Dimension_S  Dimension_I  Dimension_C  \\\n",
       "name                                                                            \n",
       "Taiwan, Province of China     1.291125          NaN          NaN     1.500000   \n",
       "Denmark                       1.500000     0.937877     0.791002     1.316087   \n",
       "Norway                        1.219741     0.945633     0.948538     1.341439   \n",
       "Luxembourg                    1.197979     0.791160     0.948023     1.347068   \n",
       "Sweden                        1.387357     0.777471     0.774226     1.300390   \n",
       "...                                ...          ...          ...          ...   \n",
       "Myanmar                      -1.189872     0.394712    -0.078129    -1.397936   \n",
       "Libya                        -1.049753    -0.316533          NaN    -0.636338   \n",
       "Sudan                        -0.861861    -0.840882    -0.282799    -0.670154   \n",
       "Somalia                      -1.148255    -1.000000          NaN    -0.396857   \n",
       "South Sudan                  -1.223234    -0.186487    -0.893408    -0.517689   \n",
       "\n",
       "                           Dimension_E  Dimension_R  weighted_mean  iso  \\\n",
       "name                                                                      \n",
       "Taiwan, Province of China          NaN          NaN       1.395562  TWN   \n",
       "Denmark                       0.435523     0.220542       0.866839  DNK   \n",
       "Norway                        0.500000     0.191078       0.857738  NOR   \n",
       "Luxembourg                    0.362738     0.227067       0.812339  LUX   \n",
       "Sweden                        0.425640     0.196767       0.810308  SWE   \n",
       "...                                ...          ...            ...  ...   \n",
       "Myanmar                      -0.276679     0.148125      -0.399963  MMR   \n",
       "Libya                        -0.166466    -0.206130      -0.475044  LBY   \n",
       "Sudan                        -0.377379    -0.027945      -0.510170  SDN   \n",
       "Somalia                      -0.358517     0.107331      -0.559260  SOM   \n",
       "South Sudan                        NaN    -0.178028      -0.599769  SSD   \n",
       "\n",
       "                           country-code  \n",
       "name                                     \n",
       "Taiwan, Province of China           158  \n",
       "Denmark                             208  \n",
       "Norway                              578  \n",
       "Luxembourg                          442  \n",
       "Sweden                              752  \n",
       "...                                 ...  \n",
       "Myanmar                             104  \n",
       "Libya                               434  \n",
       "Sudan                               729  \n",
       "Somalia                             706  \n",
       "South Sudan                         728  \n",
       "\n",
       "[164 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1ac347e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.to_csv(\"../upload_data/full_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2f2b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3f383ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def all_the_data(indicator_dictionary, manual_data):\n",
    "    \n",
    "    all_data_dic = {}\n",
    "\n",
    "    for key in indicator_dictionary.keys():\n",
    "        all_data_dic[key] = dim_X_complete(indicator_dictionary, key, manual_data)\n",
    "        \n",
    "    return all_data_dic\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38734b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "    --------------------------Dimension G------------------------------\n",
      "\n",
      "    \n",
      "\u001b[1mLoading Data.....\n",
      "\u001b[0m\n",
      "Successfully loaded Indicator G1 from V-DEM Database\n",
      "\n",
      "Successfully loaded Indicator G2 from OWiD Database\n",
      "\n",
      "Data for 'Control of Corruption: Estimate' found in WB Database 3. Returning data for the most recent year. \n",
      "        Coverage = 99.53%, greater than selected threshold of 85.0%.\n",
      "\n",
      "Successfully loaded Indicator G3 from WB Database\n",
      "\n",
      "Data for 'Rule of Law: Estimate' found in WB Database 3. Returning data for the most recent year. \n",
      "        Coverage = 99.53%, greater than selected threshold of 85.0%.\n",
      "\n",
      "Successfully loaded Indicator G4 from WB Database\n",
      "\n",
      "Data for 'Tax Revenue' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Data coverage at 67.67% after going back 10 years.\n",
      "            Failed to exceed minimum threshold of 85.0%. Returning best dataframe anyway.\n",
      "\n",
      "Successfully loaded Indicator G5 from WB Database\n",
      "\n",
      "Data for 'Proportion of Seats Held by Women' found in WB Database 2. Returning data for the most recent year. \n",
      "        Coverage = 88.35%, greater than selected threshold of 85.0%.\n",
      "\n",
      "Successfully loaded Indicator G6 from WB Database\n",
      "\n",
      "Successfully loaded Indicator G7 from OWiD Database\n",
      "\n",
      "\u001b[1mScaling & Weighting Data....\u001b[0m\n",
      "\n",
      "**Successfully loaded , merged, scaled, and weighted Dimension G Data**\n",
      "\n",
      "\u001b[1mOverall Data Coverage:\u001b[0m(Weighted Mean missing if more than 2 indicators are missing for that Dimension..)\n",
      "ind_G1           0.981707\n",
      "ind_G2           0.993902\n",
      "ind_G3           1.000000\n",
      "ind_G4           1.000000\n",
      "ind_G5           0.774390\n",
      "ind_G6           0.951220\n",
      "ind_G7           0.993902\n",
      "weighted_mean    0.993902\n",
      "iso_a3           1.000000\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "    ---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "    \n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "    --------------------------Dimension S------------------------------\n",
      "\n",
      "    \n",
      "\u001b[1mLoading Data.....\n",
      "\u001b[0m\n",
      "Data for 'Gini Index' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Data coverage at 53.76% after going back 10 years.\n",
      "            Failed to exceed minimum threshold of 85.0%. Returning best dataframe anyway.\n",
      "\n",
      "Successfully loaded Indicator S1 from WB Database\n",
      "\n",
      "Data for 'Inflation, Consumer Prices' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Achieved 85.34% data coverage by going back to data from 2018,\n",
      "                exceeding minimum threshold of 85.0%. Returning this dataframe.\n",
      "\n",
      "Successfully loaded Indicator S2 from WB Database\n",
      "\n",
      "Data for 'Unemployment, Total' found in WB Database 2. Returning data for the most recent year. \n",
      "        Coverage = 87.97%, greater than selected threshold of 85.0%.\n",
      "\n",
      "Successfully loaded Indicator S3 from WB Database\n",
      "\n",
      "Data for 'Women Business and the Law Index' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Data coverage at 75.56% after going back 10 years.\n",
      "            Failed to exceed minimum threshold of 85.0%. Returning best dataframe anyway.\n",
      "\n",
      "Successfully loaded Indicator S4 from WB Database\n",
      "\n",
      "Successfully loaded Indicator S5 from ACLED Database\n",
      "\n",
      "Data for 'Age Dependency Ratio' found in WB Database 2. Returning data for the most recent year. \n",
      "        Coverage = 99.62%, greater than selected threshold of 85.0%.\n",
      "\n",
      "Successfully loaded Indicator S6 from WB Database\n",
      "\n",
      "Data for 'Ease of Doing Business Score' found in WB Database 2. Returning data for the most recent year. \n",
      "        Coverage = 89.47%, greater than selected threshold of 85.0%.\n",
      "\n",
      "Successfully loaded Indicator S7 from WB Database\n",
      "\n",
      "\u001b[1mScaling & Weighting Data....\u001b[0m\n",
      "\n",
      "**Successfully loaded , merged, scaled, and weighted Dimension S Data**\n",
      "\n",
      "\u001b[1mOverall Data Coverage:\u001b[0m(Weighted Mean missing if more than 2 indicators are missing for that Dimension..)\n",
      "ind_S1           0.763314\n",
      "ind_S2           0.911243\n",
      "ind_S3           0.988166\n",
      "ind_S4           0.970414\n",
      "ind_S5           0.970414\n",
      "ind_S6           1.000000\n",
      "ind_S7           0.970414\n",
      "weighted_mean    0.964497\n",
      "iso_a3           1.000000\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "    ---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "    \n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "    --------------------------Dimension I------------------------------\n",
      "\n",
      "    \n",
      "\u001b[1mLoading Data.....\n",
      "\u001b[0m\n",
      "Data for 'GDP per Capita' found in WB Database 2. Returning data for the most recent year. \n",
      "        Coverage = 91.35%, greater than selected threshold of 85.0%.\n",
      "\n",
      "Successfully loaded Indicator I1 from WB Database\n",
      "\n",
      "Data for 'Poverty Gap at $2.15 a Day' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Data coverage at 59.019999999999996% after going back 10 years.\n",
      "            Failed to exceed minimum threshold of 85.0%. Returning best dataframe anyway.\n",
      "\n",
      "Successfully loaded Indicator I2 from WB Database\n",
      "\n",
      "Data for 'Human Capital Index' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Data coverage at 65.41% after going back 10 years.\n",
      "            Failed to exceed minimum threshold of 85.0%. Returning best dataframe anyway.\n",
      "\n",
      "Successfully loaded Indicator I3 from WB Database\n",
      "\n",
      "Data for 'Women who Believe a Husband is Justified in Beating his Wife' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Data coverage at 22.56% after going back 10 years.\n",
      "            Failed to exceed minimum threshold of 85.0%. Returning best dataframe anyway.\n",
      "\n",
      "Successfully loaded Indicator I4 from WB Database\n",
      "\n",
      "Data for 'Current Health Expenditure per Capita, PPP' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Achieved 87.59% data coverage by going back to data from 2020,\n",
      "                exceeding minimum threshold of 85.0%. Returning this dataframe.\n",
      "\n",
      "Successfully loaded Indicator I5 from WB Database\n",
      "\n",
      "\u001b[1mScaling & Weighting Data....\u001b[0m\n",
      "\n",
      "**Successfully loaded , merged, scaled, and weighted Dimension I Data**\n",
      "\n",
      "\u001b[1mOverall Data Coverage:\u001b[0m(Weighted Mean missing if more than 2 indicators are missing for that Dimension..)\n",
      "ind_I1           0.940828\n",
      "ind_I2           0.763314\n",
      "ind_I3           0.893491\n",
      "ind_I4           0.343195\n",
      "ind_I5           0.934911\n",
      "weighted_mean    0.899408\n",
      "iso_a3           1.000000\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "    ---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "    \n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "    --------------------------Dimension C------------------------------\n",
      "\n",
      "    \n",
      "\u001b[1mLoading Data.....\n",
      "\u001b[0m\n",
      "Successfully loaded Indicator C1 from ACLED Database\n",
      "\n",
      "Successfully loaded Indicator C3 from OWiD Database\n",
      "\n",
      "Data for 'Intentional homicides' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Data coverage at 84.21% after going back 10 years.\n",
      "            Failed to exceed minimum threshold of 85.0%. Returning best dataframe anyway.\n",
      "\n",
      "Successfully loaded Indicator C4 from WB Database\n",
      "\n",
      "\u001b[1mScaling & Weighting Data....\u001b[0m\n",
      "\n",
      "**Successfully loaded , merged, scaled, and weighted Dimension C Data**\n",
      "\n",
      "\u001b[1mOverall Data Coverage:\u001b[0m(Weighted Mean missing if more than 2 indicators are missing for that Dimension..)\n",
      "ind_C1           1.000000\n",
      "ind_C3           0.936782\n",
      "ind_C4           0.816092\n",
      "weighted_mean    1.000000\n",
      "iso_a3           1.000000\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "    ---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "    \n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "    --------------------------Dimension E------------------------------\n",
      "\n",
      "    \n",
      "\u001b[1mLoading Data.....\n",
      "\u001b[0m\n",
      "Successfully loaded Indicator E1 from ND Database\n",
      "\n",
      "\u001b[1mScaling & Weighting Data....\u001b[0m\n",
      "\n",
      "**Successfully loaded , merged, scaled, and weighted Dimension E Data**\n",
      "\n",
      "\u001b[1mOverall Data Coverage:\u001b[0m(Weighted Mean missing if more than 2 indicators are missing for that Dimension..)\n",
      "ind_E1           1.0\n",
      "weighted_mean    1.0\n",
      "iso_a3           1.0\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "    ---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "    \n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "    --------------------------Dimension R------------------------------\n",
      "\n",
      "    \n",
      "\u001b[1mLoading Data.....\n",
      "\u001b[0m\n",
      "Successfully loaded Indicator R1 from ACLED Database\n",
      "\n",
      "Successfully loaded Indicator R2 from UNHCR Database\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 'Total Natural Resources Rents' found in WB Database 2. Returning data for the most recent year. \n",
      "        Coverage = 92.11%, greater than selected threshold of 85.0%.\n",
      "\n",
      "Successfully loaded Indicator R3 from WB Database\n",
      "\n",
      "\u001b[1mScaling & Weighting Data....\u001b[0m\n",
      "\n",
      "**Successfully loaded , merged, scaled, and weighted Dimension R Data**\n",
      "\n",
      "\u001b[1mOverall Data Coverage:\u001b[0m(Weighted Mean missing if more than 2 indicators are missing for that Dimension..)\n",
      "ind_R1           0.954023\n",
      "ind_R2           0.879310\n",
      "ind_R3           0.913793\n",
      "weighted_mean    0.994253\n",
      "iso_a3           1.000000\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "    ---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "    \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "all_the_data_dictionary = all_the_data(indicator_dictionary, manual_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "335d0294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['G', 'S', 'I', 'C', 'E', 'R'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_the_data_dictionary.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cbf1944f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in all_the_data_dictionary.keys():\n",
    "    \n",
    "    df = all_the_data_dictionary[key]\n",
    "    \n",
    "    df.to_csv(f\"../upload_data/dim_{key}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bffc6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594f4f2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db34de7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99757db9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9debf9c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b209fc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa75791",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a94cda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_list = []\n",
    "for values in dimension_weights.values():\n",
    "    weight_list.append(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59d4ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163ab5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_and_weight(all_df, weight_list, return_nulls= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1579e63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "geo_merge = world.merge(all_df, left_on = 'name', right_index = True)\n",
    "\n",
    "nrows, ncols = 4, 2\n",
    "\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(15, 10))\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, column in enumerate(all_df.columns):\n",
    "    geo_merge.plot(column=column, cmap='RdYlGn', missing_kwds={'color': 'black'}, ax=axes[idx])\n",
    "    axes[idx].set_title(f'Map for {column}')\n",
    "    axes[idx].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b1e1c1",
   "metadata": {},
   "source": [
    "# Compared to OECD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39be6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "oecd_df = pd.read_excel('../data/state_o_f/List of fragile contexts (2022) (1).xlsx')\n",
    "\n",
    "oecd_df = oecd_df.reset_index().rename(columns={'index':'oecd_rank'}).set_index('iso3c')\n",
    "\n",
    "oecd_df['oecd_rank'] = oecd_df['oecd_rank']+1\n",
    "\n",
    "score_df = all_df.set_index('iso')[['weighted_mean']]\n",
    "\n",
    "score_df['bmz_rank'] = score_df['weighted_mean'].rank()\n",
    "\n",
    "score_df['bmz_rank'] = score_df['bmz_rank'].astype(int)\n",
    "\n",
    "compare_df = oecd_df.merge(score_df, left_index=True, right_index=True, how = 'left')[['context', 'oecd_rank', 'bmz_rank']]\n",
    "\n",
    "compare_df = compare_df.fillna(999)\n",
    "\n",
    "compare_df['bmz_rank'] = compare_df['bmz_rank'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9899dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f08d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df[all_df['iso'] == 'PSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8d46cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_C_check = dim_X_complete(indicator_dictionary, \"C\", manual_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9f960c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_C_check[dim_C_check['iso_a3'] == 'UKR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d09221",
   "metadata": {},
   "outputs": [],
   "source": [
    "acled_df.groupby('country').sum()[['fatalities']].sort_values('fatalities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1a9e86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d0a457",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf4ff68c",
   "metadata": {},
   "source": [
    "# Visuallizing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07cc471",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_X_complete(indicator_dictionary, \"R\", manual_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccf70de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_individual_indicators(dimension_df):\n",
    "    \n",
    "    just_ind_df = dimension_df.drop(columns='weighted_mean')\n",
    "\n",
    "    world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "    geo_merge = world.merge(just_ind_df, left_on = 'name', right_index = True)\n",
    "\n",
    "    nrows, ncols = 4, 2\n",
    "\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(15, 10))\n",
    "\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, column in enumerate(just_ind_df.columns):\n",
    "        geo_merge.plot(column=column, cmap='RdYlGn', missing_kwds={'color': 'black'}, ax=axes[idx])\n",
    "        axes[idx].set_title(f'Map for {column}')\n",
    "        axes[idx].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d2f23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_individual_indicators(dim_X_complete(indicator_dictionary, 'R', manual_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
