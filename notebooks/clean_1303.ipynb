{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0b17e0f",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04fa63ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "# Data Analysis\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "\n",
    "\n",
    "# WBAPI\n",
    "\n",
    "import wbgapi as wb\n",
    "\n",
    "# Data Processing\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Aesthetic\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class color:\n",
    "   BOLD = '\\033[1m'\n",
    "   END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c12ed3d",
   "metadata": {},
   "source": [
    "# Manual Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5b1d2703",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdem_df = pd.read_csv(\"../data/vdem/V-Dem-CY-Full+Others-v13.csv\", usecols=['country_text_id', 'v2regsupgroupssize', 'year'])\n",
    "\n",
    "owid_freedom_of_expression_df = pd.read_csv('../data/owid/freedom-of-expression-index.csv')\n",
    "\n",
    "owid_pa_index_df = pd.read_csv('../data/owid/rigorous-and-impartial-public-administration-index.csv')\n",
    "\n",
    "owid_state_control_df = pd.read_csv('../data/owid/percentage-of-territory-controlled-by-government.csv')\n",
    "\n",
    "acled_df = pd.read_csv('../data/acled/2023_all_data.csv', usecols= ['event_type', 'country', 'fatalities', 'population_best', 'year'])\n",
    "\n",
    "nd_df = pd.read_csv('../data/nd/gain.csv')\n",
    "\n",
    "iso_list = pd.read_csv(\"../data/all.csv\", usecols= ['name', 'alpha-3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5d46405b",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_data = {\n",
    "    'V-DEM': vdem_df,\n",
    "    'OWiD': {\n",
    "        'Public Administration Index': owid_pa_index_df,\n",
    "        'Freedom of Expression Index': owid_freedom_of_expression_df,\n",
    "        'State Control over Territory': owid_state_control_df\n",
    "    },\n",
    "    'ACLED': acled_df,\n",
    "    'nd': nd_df,\n",
    "    'iso_list': iso_list\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6703edb8",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8175a160",
   "metadata": {},
   "source": [
    "## WB API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e96f37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indicator_to_df(query, specify = False):\n",
    "\n",
    "    # Function to get indicator code\n",
    "\n",
    "    if specify:\n",
    "        return pd.DataFrame(wb.series.Series(q= query)).reset_index().iloc[specify]\n",
    "    return pd.DataFrame(wb.series.Series(q= query)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "165cd8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wb_data_completer(indicator, coverage_threshold = 0.85, years_to_check = 10, database = None, specify = False):\n",
    "    \n",
    "    def indicator_to_df(query, specify = False):\n",
    "        \n",
    "        # Function to get indicator code\n",
    "        \n",
    "        if specify:\n",
    "            return pd.DataFrame(wb.series.Series(q= query)).reset_index().iloc[specify]\n",
    "        return pd.DataFrame(wb.series.Series(q= query)).reset_index()\n",
    "    \n",
    "    def fetch_data_and_calculate_completeness(database_number):\n",
    "        \n",
    "        # Checks coverage of data\n",
    "        \n",
    "        wb.db = database_number\n",
    "        db_ind = indicator_to_df(indicator, specify = specify)\n",
    "        \n",
    "        if len(db_ind) == 0:  # If no data is found for this database\n",
    "            return 0  # Completeness is 0%\n",
    "        return float(wb.data.DataFrame(db_ind['index'], mrv=1).notna().mean())\n",
    "    \n",
    "    # Check which database to use if not specified\n",
    "    \n",
    "    if database is None:\n",
    "        \n",
    "        db2_complete = fetch_data_and_calculate_completeness(2)\n",
    "        db3_complete = fetch_data_and_calculate_completeness(3)\n",
    "        \n",
    "        database = 2 if db2_complete >= db3_complete or db3_complete == 0 else 3\n",
    "    \n",
    "    # Check coverage of most recent year\n",
    "    \n",
    "    wb.db = database\n",
    "    coverage_complete = fetch_data_and_calculate_completeness(database)\n",
    "    final_ind = indicator_to_df(indicator, specify = specify)\n",
    "        \n",
    "    # Return mrv = 1 if already passing data threshold\n",
    "    \n",
    "    if coverage_complete > coverage_threshold:\n",
    "        print(f\"\"\"Data for '{indicator}' found in WB Database {database}. Returning data for the most recent year. \n",
    "        Coverage = {round(coverage_complete, 4)*100}%, greater than selected threshold of {round(coverage_threshold, 4)*100}%.\\n\"\"\")\n",
    "        final_ind = wb.data.DataFrame(final_ind['index'], mrv=1)\n",
    "        final_ind.columns = ['Final Value']\n",
    "        \n",
    "        return final_ind\n",
    "    \n",
    "    # Otherwise go back number of years specified\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        print(f\"\"\"Data for '{indicator}' does not meet the coverage threshold of {coverage_threshold*100}% in WB Database {database}.\n",
    "        Extracting data from previous years.\"\"\")\n",
    "        \n",
    "        # Get Data\n",
    "        \n",
    "        \n",
    "        multiyear_df = wb.data.DataFrame(final_ind['index'], mrv=years_to_check)\n",
    "        \n",
    "        # Loop through DF in reverse order\n",
    "        \n",
    "        current_year = int(multiyear_df.columns[-1][2:])\n",
    "        all_years = list(range(current_year, current_year - years_to_check, -1)) \n",
    "        \n",
    "        for i, year in enumerate(all_years):\n",
    "            year_column = f'YR{year}'\n",
    "            \n",
    "            # Skip years that don't have a corresponding column in the DataFrame\n",
    "            \n",
    "            if year_column not in multiyear_df.columns:\n",
    "                continue \n",
    "                \n",
    "            # For the first year, initialize 'Final_Value' with its values\n",
    "            \n",
    "            if i == 0:\n",
    "                multiyear_df['Final_Value'] = multiyear_df[year_column]\n",
    "                \n",
    "            # Fill missing values in 'Final_Value' with the current year's data\n",
    " \n",
    "            else:\n",
    "                multiyear_df['Final_Value'] = multiyear_df['Final_Value'].fillna(multiyear_df[year_column])\n",
    "            \n",
    "            # Check data completeness for 'Final_Value' after potential filling\n",
    "            \n",
    "            data_coverage = multiyear_df['Final_Value'].notna().mean()\n",
    "            if data_coverage >= coverage_threshold:\n",
    "                print(f\"\"\"Achieved {round(data_coverage,4)*100}% data coverage by going back to data from {year},\n",
    "                exceeding minimum threshold of {coverage_threshold*100}%. Returning this dataframe.\\n\"\"\")\n",
    "                break\n",
    "                \n",
    "        # Return Final DF\n",
    "                \n",
    "        if data_coverage < coverage_threshold:\n",
    "            \n",
    "            print(f\"\"\"Data coverage at {round(data_coverage,4)*100}% after going back {years_to_check} years.\n",
    "            Failed to exceed minimum threshold of {coverage_threshold*100}%. Returning best dataframe anyway.\\n\"\"\")\n",
    "            \n",
    "            \n",
    "        return multiyear_df[['Final_Value']]\n",
    "\n",
    "def indicator_returner(query, dimension = 'dim', indicator = 'ind', specify = False):\n",
    "    \n",
    "    df = wb_data_completer(query, specify = specify)\n",
    "    df.columns = [f'ind_{dimension}{indicator}']\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd39d364",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09b4f025",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_and_weight(merged_df, weight_list, return_nulls = False):\n",
    "    \n",
    "    # Scale\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_df = scaler.fit_transform(merged_df)\n",
    "    scaled_df = pd.DataFrame(scaled_df, columns=scaler.get_feature_names_out()).sub(0.5)\n",
    "    scaled_df.index = merged_df.index\n",
    "    \n",
    "    # Weight\n",
    "    \n",
    "    keys = scaled_df.columns\n",
    "    \n",
    "    weights = dict(zip(keys, weight_list))\n",
    "\n",
    "    weighted_df = pd.DataFrame()\n",
    "\n",
    "    for column, weight in weights.items():\n",
    "        weighted_df[column] = scaled_df[column] * weight\n",
    "        \n",
    "    # Weighted mean\n",
    "    \n",
    "    weighted_df['weighted_mean'] = weighted_df.mean(axis=1)\n",
    "    weighted_df['weighted_mean'] = weighted_df.apply(lambda row: np.nan if row[keys].isnull().sum() > 2 else row['weighted_mean'], axis=1)\n",
    "    weighted_df = weighted_df.sort_values('weighted_mean', ascending=False)\n",
    "    \n",
    "    # Adding country names as index\n",
    "    \n",
    "    world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "    listylist = list(weighted_df.columns)\n",
    "    listylist.append('name')\n",
    "    final_df = weighted_df.merge(world, left_index=True, right_on='iso_a3')[listylist].set_index('name')\n",
    "    \n",
    "    if return_nulls:\n",
    "        return final_df\n",
    "    \n",
    "    return final_df[final_df['weighted_mean'].notnull()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246b7b11",
   "metadata": {},
   "source": [
    "## Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8fd92ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>SeriesName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VC.IHR.PSRC.P5</td>\n",
       "      <td>Intentional homicides (per 100,000 people)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            index                                  SeriesName\n",
       "2  VC.IHR.PSRC.P5  Intentional homicides (per 100,000 people)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indicator_to_df('Intentional homicides', specify= slice(2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7fed18e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2021</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISO3</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AFG</th>\n",
       "      <td>32.797710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALB</th>\n",
       "      <td>50.758476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DZA</th>\n",
       "      <td>47.853701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AND</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGO</th>\n",
       "      <td>37.909703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VEN</th>\n",
       "      <td>40.220612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VNM</th>\n",
       "      <td>47.525898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEM</th>\n",
       "      <td>34.998525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZMB</th>\n",
       "      <td>42.187454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZWE</th>\n",
       "      <td>35.581529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           2021\n",
       "ISO3           \n",
       "AFG   32.797710\n",
       "ALB   50.758476\n",
       "DZA   47.853701\n",
       "AND         NaN\n",
       "AGO   37.909703\n",
       "...         ...\n",
       "VEN   40.220612\n",
       "VNM   47.525898\n",
       "YEM   34.998525\n",
       "ZMB   42.187454\n",
       "ZWE   35.581529\n",
       "\n",
       "[192 rows x 1 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nd_df.set_index('ISO3')[['2021']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fa023653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fatalities</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha-3</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AFG</th>\n",
       "      <td>708.0</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALA</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Åland Islands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALB</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Albania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DZA</th>\n",
       "      <td>6.0</td>\n",
       "      <td>Algeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASM</th>\n",
       "      <td>0.0</td>\n",
       "      <td>American Samoa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WLF</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Wallis and Futuna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESH</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Western Sahara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEM</th>\n",
       "      <td>2894.0</td>\n",
       "      <td>Yemen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZMB</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Zambia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZWE</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Zimbabwe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>249 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         fatalities               name\n",
       "alpha-3                               \n",
       "AFG           708.0        Afghanistan\n",
       "ALA             0.0      Åland Islands\n",
       "ALB             0.0            Albania\n",
       "DZA             6.0            Algeria\n",
       "ASM             0.0     American Samoa\n",
       "...             ...                ...\n",
       "WLF             0.0  Wallis and Futuna\n",
       "ESH             0.0     Western Sahara\n",
       "YEM          2894.0              Yemen\n",
       "ZMB             0.0             Zambia\n",
       "ZWE             0.0           Zimbabwe\n",
       "\n",
       "[249 rows x 2 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df = acled_df[acled_df['event_type'].isin(['Explosions/Remote violence', 'Battles'])]\\\n",
    "[['country', 'fatalities']].groupby(by = 'country')\\\n",
    ".agg({'fatalities': 'sum'})\n",
    "ind_x = grouped_df.merge(manual_data['iso_list'], left_index=True, right_on= 'name', how = 'right').set_index('alpha-3')\n",
    "ind_x['fatalities'] = ind_x['fatalities'].fillna(0)\n",
    "ind_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "853cfad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dim_X_complete(indicator_dictionary, dimension, manual_data):\n",
    "    \n",
    "    dimension_dict = indicator_dictionary[dimension]\n",
    "    dimension_dict = {k: v for k, v in dimension_dict.items() if v}\n",
    "    \n",
    "    print(f\"\"\"\\n\\n\n",
    "    --------------------------Dimension {dimension}------------------------------\\n\n",
    "    \"\"\")\n",
    "    \n",
    "    ### Loading Data ###\n",
    "    \n",
    "    print(color.BOLD + \"Loading Data.....\\n\" + color.END)\n",
    "    \n",
    "    full_df = None\n",
    "    \n",
    "    for ind_num, ind_value in dimension_dict.items():\n",
    "        \n",
    "        if ind_value[0] == 'WB':\n",
    "            \n",
    "            if len(ind_value) == 3:\n",
    "            \n",
    "                ind_x = indicator_returner(ind_value[1], f\"{dimension}\", f\"{ind_num}\")\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                ind_x = indicator_returner(ind_value[1], f\"{dimension}\", f\"{ind_num}\", specify= ind_value[-1])\n",
    "                \n",
    "            \n",
    "        if ind_value[0] == 'V-DEM':\n",
    "            \n",
    "            rel_df = manual_data[ind_value[0]]\n",
    "            \n",
    "            ind_x = rel_df[rel_df['year'] == 2022][['country_text_id', 'v2regsupgroupssize']].set_index('country_text_id')\n",
    "            ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "            \n",
    "        if ind_value[0] == 'OWiD':\n",
    "            \n",
    "            rel_df = manual_data[ind_value[0]]\n",
    "            \n",
    "            if ind_value[1] ==  'Public Administration Index':\n",
    "               \n",
    "                ind_x = rel_df[ind_value[1]]\n",
    "                ind_x = ind_x[ind_x['Year'] == 2022].set_index('Code')[['public_admin_vdem_owid']]\n",
    "                ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "               \n",
    "            if ind_value[1] ==  'Freedom of Expression Index':\n",
    "                ind_x = rel_df[ind_value[1]]\n",
    "                ind_x = ind_x[ind_x['Year'] == 2022].set_index('Code')[['freeexpr_vdem_owid']]\n",
    "                ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "                \n",
    "            if ind_value[1] ==  'State Control over Territory':\n",
    "                ind_x = rel_df[ind_value[1]]\n",
    "                ind_x = ind_x[ind_x['Year'] == 2022].set_index('Code')[['terr_contr_vdem_owid']]\n",
    "                ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "                \n",
    "                \n",
    "        if ind_value[0] == 'ACLED':\n",
    "            \n",
    "            rel_df = manual_data[ind_value[0]]\n",
    "            rel_df_2 = manual_data['iso_list']\n",
    "            \n",
    "            if ind_value[1] ==  'Protest Count':\n",
    "                \n",
    "                grouped_df = rel_df[rel_df['event_type'] == 'Protests'][['country', 'year']].groupby(by = 'country')\\\n",
    "                    .agg({'year': 'count'})\n",
    "                ind_x = grouped_df.merge(rel_df_2, left_index=True, right_on= 'name').set_index('alpha-3')[['year']]\n",
    "                ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "                \n",
    "            if ind_value[1] ==  'Battle Related Fatalities':\n",
    "                \n",
    "                grouped_df = rel_df[rel_df['event_type'].isin(['Explosions/Remote violence', 'Battles'])]\\\n",
    "                    [['country', 'fatalities']].groupby(by = 'country').agg({'fatalities': 'sum'})\n",
    "                ind_x = grouped_df.merge(rel_df_2, left_index=True, right_on= 'name', how = 'right').set_index('alpha-3')[['fatalities']]\n",
    "                ind_x['fatalities'] = ind_x['fatalities'].fillna(0)\n",
    "                ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "            \n",
    "        \n",
    "        print(f'''Successfully loaded Indicator {dimension}{ind_num} from {ind_value[0]} Database\\n''')\n",
    "               \n",
    "        ### Merging DF ###\n",
    "               \n",
    "        if not isinstance(full_df, pd.DataFrame):\n",
    "            \n",
    "            full_df = ind_x\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            full_df = full_df.merge(ind_x, left_index = True, right_index = True, how = 'left')\n",
    "            \n",
    "        \n",
    "    \n",
    "    \n",
    "    ### Scaling and Weighting ###\n",
    "    \n",
    "    print (color.BOLD + \"Scaling & Weighting Data....\" + color.END)\n",
    "    \n",
    "    weight_list = []\n",
    "    for values in dimension_dict.values():\n",
    "        weight_list.append(values[2])\n",
    "        \n",
    "    full_df = scale_and_weight(full_df, weight_list)\n",
    "    \n",
    "    print(f\"\"\"\\n**Successfully loaded , merged, scaled, and weighted Dimension {dimension} Data**\\n\"\"\")\n",
    "    print(color.BOLD  + \"\"\"Overall Data Coverage:\n",
    "    \"\"\" + color.END)\n",
    "    print(1- full_df.isna().sum()/len(full_df))\n",
    "\n",
    "    print(\"\"\"\\n\\n\n",
    "    ---------------------------------------------------------------------------\\n\\n\n",
    "    \n",
    "    \"\"\")\n",
    "            \n",
    "            \n",
    "    return full_df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6baab1",
   "metadata": {},
   "source": [
    "# Fragility Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cd2abc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator_dictionary = {\n",
    "    'G': {\n",
    "        1:['V-DEM', 'Size of Regime Support Group', 3],\n",
    "        2:['OWiD', 'Public Administration Index', 2],\n",
    "        3:['WB', 'Control of Corruption: Estimate', 2],\n",
    "        4:['WB', 'Rule of Law: Estimate', 2],\n",
    "        5:['WB', 'Tax Revenue', 2, slice(1,2)],\n",
    "        6:['WB', 'Proportion of Seats Held by Women', 1],\n",
    "        7:['OWiD', 'Freedom of Expression Index', 1]\n",
    "    },\n",
    "    'S': {\n",
    "        1:['WB', 'Gini Index', -3],\n",
    "        2:['WB', 'Inflation, Consumer Prices', -2],\n",
    "        3:['WB', 'Unemployment, Total', -2, slice(1,2)],\n",
    "        4:['WB', 'Women Business and the Law Index', 2],\n",
    "        5:['ACLED', 'Protest Count', -2],\n",
    "        6:['WB', 'Age Dependency Ratio', -1, slice(0,1)],\n",
    "        7:['WB', 'Ease of Doing Business Score', 1]\n",
    "    },\n",
    "    'I': {\n",
    "        1:['WB', 'GDP per Capita', 3, slice(0,1)],\n",
    "        2:['WB', 'Poverty Gap at $2.15 a Day', -3],\n",
    "        3:['WB', 'Human Capital Index', 2, slice(0,1)],\n",
    "        4:['WB', 'Women who Believe a Husband is Justified in Beating his Wife', -2, slice(4,5)],\n",
    "        5:['WB', 'Current Health Expenditure per Capita, PPP', 2],\n",
    "        6:[],\n",
    "        7:[]\n",
    "    },\n",
    "    'C': {\n",
    "        1:['ACLED', 'Battle Related Fatalities', -3],\n",
    "        2:[],\n",
    "        3:['OWiD', 'State Control over Territory', 2],\n",
    "        4:['WB', 'Intentional homicides', -2, slice(2,3)],\n",
    "        5:[],\n",
    "        6:[],\n",
    "        7:[]\n",
    "    },\n",
    "    'E': {\n",
    "        1:[],\n",
    "        2:[],\n",
    "        3:[],\n",
    "        4:[],\n",
    "        5:[],\n",
    "        6:[],\n",
    "        7:[]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6992d08",
   "metadata": {},
   "source": [
    "# Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f97bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wb.db =2\n",
    "pd.set_option('max_colwidth', 400)\n",
    "indicator_to_df('Financial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba3f700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7c2a5eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "    --------------------------Dimension C------------------------------\n",
      "\n",
      "    \n",
      "\u001b[1mLoading Data.....\n",
      "\u001b[0m\n",
      "Successfully loaded Indicator C1 from ACLED Database\n",
      "\n",
      "Successfully loaded Indicator C3 from OWiD Database\n",
      "\n",
      "Data for 'Intentional homicides' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Data coverage at 84.21% after going back 10 years.\n",
      "            Failed to exceed minimum threshold of 85.0%. Returning best dataframe anyway.\n",
      "\n",
      "Successfully loaded Indicator C4 from WB Database\n",
      "\n",
      "\u001b[1mScaling & Weighting Data....\u001b[0m\n",
      "\n",
      "**Successfully loaded , merged, scaled, and weighted Dimension C Data**\n",
      "\n",
      "\u001b[1mOverall Data Coverage:\n",
      "    \u001b[0m\n",
      "ind_C1           1.000000\n",
      "ind_C3           0.936782\n",
      "ind_C4           0.816092\n",
      "weighted_mean    1.000000\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "    ---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "    \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "s_df = dim_X_complete(indicator_dictionary, \"C\", manual_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916ee577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_tables_and_maps(dimensions, indicators = False, table = True, geomap = True):\n",
    "    \n",
    "    for dimension in dimensions:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab94099",
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator_dictionary.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d51810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def display_all_dimensions(indicator_dictionary, manual_data):\n",
    "\n",
    "#     world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "\n",
    "# `\n",
    "#     for key in indicator_dictionary.keys():\n",
    "\n",
    "#         dimension_df = dim_X_complete(indicator_dictionary, key, manual_data)\n",
    "#         geo_merge = world.merge(dimension_df, left_on = 'name', right_index = True)\n",
    "\n",
    "#         geo_merge.plot(column='weighted_mean', cmap='RdYlGn', missing_kwds={'color': 'black'}, figsize=(10, 8))\n",
    "#         plt.title(f'Map for Dimension {key}')\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc62f7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_individual_indicators(dimension_df):\n",
    "    \n",
    "    just_ind_df = dimension_df.drop(columns='weighted_mean')\n",
    "\n",
    "    world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "    geo_merge = world.merge(just_ind_df, left_on = 'name', right_index = True)\n",
    "\n",
    "    nrows, ncols = 4, 2\n",
    "\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(15, 10))\n",
    "\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, column in enumerate(just_ind_df.columns):\n",
    "        geo_merge.plot(column=column, cmap='RdYlGn', missing_kwds={'color': 'black'}, ax=axes[idx])\n",
    "        axes[idx].set_title(f'Map for {column}')\n",
    "        axes[idx].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a08050",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_individual_indicators(dim_X_complete(indicator_dictionary, 'S', manual_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
