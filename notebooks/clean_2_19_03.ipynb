{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a46fa277",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f13d7004",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# General\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "# Data Analysis\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "\n",
    "\n",
    "# WBAPI\n",
    "\n",
    "import wbgapi as wb\n",
    "\n",
    "# Data Processing\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Aesthetic\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class color:\n",
    "   BOLD = '\\033[1m'\n",
    "   END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f60626",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Manual Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1223e0c0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vdem_df = pd.read_csv(\"../data/vdem/V-Dem-CY-Full+Others-v13.csv\", usecols=['country_text_id', 'v2regsupgroupssize', 'year'])\n",
    "\n",
    "owid_freedom_of_expression_df = pd.read_csv('../data/owid/freedom-of-expression-index.csv')\n",
    "\n",
    "owid_pa_index_df = pd.read_csv('../data/owid/rigorous-and-impartial-public-administration-index.csv')\n",
    "\n",
    "owid_state_control_df = pd.read_csv('../data/owid/percentage-of-territory-controlled-by-government.csv')\n",
    "\n",
    "acled_df = pd.read_csv('../data/acled/2023_all_data.csv', usecols= ['event_type', 'country', 'fatalities', 'population_best', 'year'])\n",
    "\n",
    "nd_df = pd.read_csv('../data/nd/gain.csv')\n",
    "\n",
    "unhcr_df = pd.read_csv('../data/population.csv')\n",
    "\n",
    "geo_df = pd.read_csv('../data/geodata.csv')\n",
    "\n",
    "iso_list = pd.read_csv(\"../data/all.csv\", usecols= ['name', 'alpha-3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3938cc7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "manual_data = {\n",
    "    'V-DEM': vdem_df,\n",
    "    'OWiD': {\n",
    "        'Public Administration Index': owid_pa_index_df,\n",
    "        'Freedom of Expression Index': owid_freedom_of_expression_df,\n",
    "        'State Control over Territory': owid_state_control_df\n",
    "    },\n",
    "    'ACLED': acled_df,\n",
    "    'ND': nd_df,\n",
    "    'UNHCR': unhcr_df,\n",
    "    'iso_list': iso_list,\n",
    "    'geodata': geo_df\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726eb2bd",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Fragility Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fb07cba",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dimension_weights = {\n",
    "    'G': 3,\n",
    "    'S': 2,\n",
    "    'I': 2,\n",
    "    'C': 3,\n",
    "    'E': 1,\n",
    "    'R': 1\n",
    "}\n",
    "\n",
    "indicator_dictionary = {\n",
    "    'G': {\n",
    "        1:['V-DEM', 'Size of Regime Support Group', 3],\n",
    "        2:['OWiD', 'Public Administration Index', 2],\n",
    "        3:['WB', 'Control of Corruption: Estimate', 2],\n",
    "        4:['WB', 'Rule of Law: Estimate', 2],\n",
    "        5:['WB', 'Tax Revenue', 2, slice(1,2)],\n",
    "        6:['WB', 'Proportion of Seats Held by Women', 1],\n",
    "        7:['OWiD', 'Freedom of Expression Index', 1]\n",
    "    },\n",
    "    'S': {\n",
    "        1:['WB', 'Gini Index', -3],\n",
    "        2:['WB', 'Inflation, Consumer Prices', -2],\n",
    "        3:['WB', 'Unemployment, Total', -2, slice(1,2)],\n",
    "        4:['WB', 'Women Business and the Law Index', 2],\n",
    "        5:['ACLED', 'Protest Count', -2],\n",
    "        6:['WB', 'Age Dependency Ratio', -1, slice(0,1)],\n",
    "        7:['WB', 'Ease of Doing Business Score', 1]\n",
    "    },\n",
    "    'I': {\n",
    "        1:['WB', 'GDP per Capita', 3, slice(0,1)],\n",
    "        2:['WB', 'Poverty Gap at $2.15 a Day', -3],\n",
    "        3:['WB', 'Human Capital Index', 2, slice(0,1)],\n",
    "        4:['WB', 'Women who Believe a Husband is Justified in Beating his Wife', -2, slice(4,5)],\n",
    "        5:['WB', 'Current Health Expenditure per Capita, PPP', 2],\n",
    "        6:[],\n",
    "        7:[]\n",
    "    },\n",
    "    'C': {\n",
    "        1:['ACLED', 'Battle Related Fatalities', -3],\n",
    "        2:[],\n",
    "        3:['OWiD', 'State Control over Territory', 2],\n",
    "        4:['WB', 'Intentional homicides', -2, slice(2,3)],\n",
    "        5:[],\n",
    "        6:[],\n",
    "        7:[]\n",
    "    },\n",
    "    'E': {\n",
    "        1:['ND', 'GAIN Index', 3],\n",
    "        2:[],\n",
    "        3:[],\n",
    "        4:[],\n",
    "        5:[],\n",
    "        6:[],\n",
    "        7:[]\n",
    "    },\n",
    "    'R': {\n",
    "        1:['ACLED', 'Violence in Neighbouring States', -3],\n",
    "        2:['UNHCR', 'Refugee In-Flow', -2],\n",
    "        3:['WB','Total Natural Resources Rents', -1],\n",
    "        4:[],\n",
    "        5:[],\n",
    "        6:[],\n",
    "        7:[]\n",
    "    }\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f60da6",
   "metadata": {},
   "source": [
    "# Data Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9beb19d2",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## WB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f79be9a0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def indicator_to_df(query, specify = False):\n",
    "\n",
    "    # Function to get indicator code\n",
    "\n",
    "    if specify:\n",
    "        return pd.DataFrame(wb.series.Series(q= query)).reset_index().iloc[specify]\n",
    "    return pd.DataFrame(wb.series.Series(q= query)).reset_index()\n",
    "\n",
    "def wb_data_completer(indicator, coverage_threshold = 0.85, years_to_check = 10, database = None, specify = False):\n",
    "    \n",
    "    def fetch_data_and_calculate_completeness(database_number):\n",
    "        \n",
    "        # Checks coverage of data\n",
    "        \n",
    "        wb.db = database_number\n",
    "        db_ind = indicator_to_df(indicator, specify = specify)\n",
    "        \n",
    "        if len(db_ind) == 0:  # If no data is found for this database\n",
    "            return 0  # Completeness is 0%\n",
    "        return float(wb.data.DataFrame(db_ind['index'], mrv=1).notna().mean())\n",
    "    \n",
    "    # Check which database to use if not specified\n",
    "    \n",
    "    if database is None:\n",
    "        \n",
    "        db2_complete = fetch_data_and_calculate_completeness(2)\n",
    "        db3_complete = fetch_data_and_calculate_completeness(3)\n",
    "        \n",
    "        database = 2 if db2_complete >= db3_complete or db3_complete == 0 else 3\n",
    "    \n",
    "    # Check coverage of most recent year\n",
    "    \n",
    "    wb.db = database\n",
    "    coverage_complete = fetch_data_and_calculate_completeness(database)\n",
    "    final_ind = indicator_to_df(indicator, specify = specify)\n",
    "        \n",
    "    # Return mrv = 1 if already passing data threshold\n",
    "    \n",
    "    if coverage_complete > coverage_threshold:\n",
    "        print(f\"\"\"Data for '{indicator}' found in WB Database {database}. Returning data for the most recent year. \n",
    "        Coverage = {round(coverage_complete, 4)*100}%, greater than selected threshold of {round(coverage_threshold, 4)*100}%.\\n\"\"\")\n",
    "        final_ind = wb.data.DataFrame(final_ind['index'], mrv=1)\n",
    "        final_ind.columns = ['Final Value']\n",
    "        \n",
    "        return final_ind\n",
    "    \n",
    "    # Otherwise go back number of years specified\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        print(f\"\"\"Data for '{indicator}' does not meet the coverage threshold of {coverage_threshold*100}% in WB Database {database}.\n",
    "        Extracting data from previous years.\"\"\")\n",
    "        \n",
    "        # Get Data\n",
    "        \n",
    "        \n",
    "        multiyear_df = wb.data.DataFrame(final_ind['index'], mrv=years_to_check)\n",
    "        \n",
    "        # Loop through DF in reverse order\n",
    "        \n",
    "        current_year = int(multiyear_df.columns[-1][2:])\n",
    "        all_years = list(range(current_year, current_year - years_to_check, -1)) \n",
    "        \n",
    "        for i, year in enumerate(all_years):\n",
    "            year_column = f'YR{year}'\n",
    "            \n",
    "            # Skip years that don't have a corresponding column in the DataFrame\n",
    "            \n",
    "            if year_column not in multiyear_df.columns:\n",
    "                continue \n",
    "                \n",
    "            # For the first year, initialize 'Final_Value' with its values\n",
    "            \n",
    "            if i == 0:\n",
    "                multiyear_df['Final_Value'] = multiyear_df[year_column]\n",
    "                \n",
    "            # Fill missing values in 'Final_Value' with the current year's data\n",
    " \n",
    "            else:\n",
    "                multiyear_df['Final_Value'] = multiyear_df['Final_Value'].fillna(multiyear_df[year_column])\n",
    "            \n",
    "            # Check data completeness for 'Final_Value' after potential filling\n",
    "            \n",
    "            data_coverage = multiyear_df['Final_Value'].notna().mean()\n",
    "            if data_coverage >= coverage_threshold:\n",
    "                print(f\"\"\"Achieved {round(data_coverage,4)*100}% data coverage by going back to data from {year},\n",
    "                exceeding minimum threshold of {coverage_threshold*100}%. Returning this dataframe.\\n\"\"\")\n",
    "                break\n",
    "                \n",
    "        # Return Final DF\n",
    "                \n",
    "        if data_coverage < coverage_threshold:\n",
    "            \n",
    "            print(f\"\"\"Data coverage at {round(data_coverage,4)*100}% after going back {years_to_check} years.\n",
    "            Failed to exceed minimum threshold of {coverage_threshold*100}%. Returning best dataframe anyway.\\n\"\"\")\n",
    "            \n",
    "            \n",
    "        return multiyear_df[['Final_Value']]\n",
    "\n",
    "def indicator_returner(query, dimension = 'dim', indicator = 'ind', specify = False):\n",
    "    \n",
    "    df = wb_data_completer(query, specify = specify)\n",
    "    df.columns = [f'ind_{dimension}{indicator}']\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122f502c",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97378b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_and_weight(merged_df, weight_list, return_nulls = False):\n",
    "    \n",
    "    # Scale\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_df = scaler.fit_transform(merged_df)\n",
    "    scaled_df = pd.DataFrame(scaled_df, columns=scaler.get_feature_names_out()).sub(0.5)\n",
    "    scaled_df.index = merged_df.index\n",
    "    \n",
    "    # Weight\n",
    "    \n",
    "    keys = scaled_df.columns\n",
    "    \n",
    "    weights = dict(zip(keys, weight_list))\n",
    "\n",
    "    weighted_df = pd.DataFrame()\n",
    "\n",
    "    for column, weight in weights.items():\n",
    "        weighted_df[column] = scaled_df[column] * weight\n",
    "        \n",
    "    # Weighted mean\n",
    "    \n",
    "    weighted_df['weighted_mean'] = weighted_df.mean(axis=1)\n",
    "    weighted_df['weighted_mean'] = weighted_df.apply(lambda row: np.nan if row[keys].isnull().sum() > 2 else row['weighted_mean'], axis=1)\n",
    "    weighted_df = weighted_df.sort_values('weighted_mean', ascending=False)\n",
    "    \n",
    "    # Adding country names as index\n",
    "    \n",
    "    world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "    listylist = list(weighted_df.columns)\n",
    "    listylist.append('name')\n",
    "    final_df = weighted_df.merge(world, left_index=True, right_on='iso_a3')[listylist].set_index('name')\n",
    "    \n",
    "    if return_nulls:\n",
    "        return final_df\n",
    "    \n",
    "    return final_df[final_df['weighted_mean'].notnull()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9eb5b7b",
   "metadata": {},
   "source": [
    "## Single Dimension Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae02c972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dimension_data_loader(dimension_dict, dimension):\n",
    "    \n",
    "    full_df = None\n",
    "    \n",
    "    for ind_num, ind_value in dimension_dict.items():\n",
    "        \n",
    "        if ind_value[0] == 'WB':\n",
    "            \n",
    "            if len(ind_value) == 3:\n",
    "            \n",
    "                ind_x = indicator_returner(ind_value[1], f\"{dimension}\", f\"{ind_num}\")\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                ind_x = indicator_returner(ind_value[1], f\"{dimension}\", f\"{ind_num}\", specify= ind_value[-1])\n",
    "                \n",
    "            \n",
    "        if ind_value[0] == 'V-DEM':\n",
    "            \n",
    "            rel_df = manual_data[ind_value[0]]\n",
    "            \n",
    "            ind_x = rel_df[rel_df['year'] == 2022][['country_text_id', 'v2regsupgroupssize']].set_index('country_text_id')\n",
    "            ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "            \n",
    "            \n",
    "        if ind_value[0] == 'OWiD':\n",
    "            \n",
    "            rel_df = manual_data[ind_value[0]]\n",
    "            \n",
    "            if ind_value[1] ==  'Public Administration Index':\n",
    "               \n",
    "                ind_x = rel_df[ind_value[1]]\n",
    "                ind_x = ind_x[ind_x['Year'] == 2022].set_index('Code')[['public_admin_vdem_owid']]\n",
    "                ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "               \n",
    "            if ind_value[1] ==  'Freedom of Expression Index':\n",
    "                ind_x = rel_df[ind_value[1]]\n",
    "                ind_x = ind_x[ind_x['Year'] == 2022].set_index('Code')[['freeexpr_vdem_owid']]\n",
    "                ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "                \n",
    "            if ind_value[1] ==  'State Control over Territory':\n",
    "                ind_x = rel_df[ind_value[1]]\n",
    "                ind_x = ind_x[ind_x['Year'] == 2022].set_index('Code')[['terr_contr_vdem_owid']]\n",
    "                ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "                \n",
    "                \n",
    "        if ind_value[0] == 'ACLED':\n",
    "            \n",
    "            rel_df = manual_data[ind_value[0]]\n",
    "            rel_df_2 = manual_data['iso_list']\n",
    "            \n",
    "            if ind_value[1] ==  'Protest Count':\n",
    "                \n",
    "                grouped_df = rel_df[rel_df['event_type'] == 'Protests'][['country', 'year']].groupby(by = 'country')\\\n",
    "                    .agg({'year': 'count'})\n",
    "                ind_x = grouped_df.merge(rel_df_2, left_index=True, right_on= 'name').set_index('alpha-3')[['year']]\n",
    "                ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "                \n",
    "            if ind_value[1] ==  'Battle Related Fatalities':\n",
    "                \n",
    "                grouped_df = rel_df[rel_df['event_type'].isin(['Explosions/Remote violence', 'Battles'])]\\\n",
    "                    [['country', 'fatalities']].groupby(by = 'country').agg({'fatalities': 'sum'})\n",
    "                ind_x = grouped_df.merge(rel_df_2, left_index=True, right_on= 'name', how = 'right').set_index('alpha-3')[['fatalities']]\n",
    "                ind_x['fatalities'] = ind_x['fatalities'].fillna(0)\n",
    "                ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "                \n",
    "            if ind_value[1] ==  'Violence in Neighbouring States':\n",
    "                \n",
    "                grouped_df = rel_df.groupby(by = 'country').sum()[['fatalities']]\n",
    "                geo_df = manual_data['geodata']\n",
    "                merged_geo = geo_df.merge(grouped_df, left_on='country_border_name', right_index=True, how = 'left')\n",
    "                merged_grouped = merged_geo.groupby('country_name').sum()\n",
    "                ind_x = merged_grouped.merge(rel_df_2, left_index=True, right_on= 'name', how = 'right').set_index('alpha-3')[['fatalities']]\n",
    "                ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "                \n",
    "\n",
    "        if ind_value[0] == 'ND':\n",
    "            \n",
    "            rel_df = manual_data[ind_value[0]]\n",
    "            ind_x = rel_df.set_index('ISO3')[['2021']]\n",
    "            ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "            \n",
    "            \n",
    "        if ind_value[0] == 'UNHCR':\n",
    "            \n",
    "            rel_df = manual_data[ind_value[0]]\n",
    "            ind_x = rel_df.set_index(\"Country of asylum (ISO)\")[[\"Refugees under UNHCR's mandate\"]]\n",
    "            ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "            \n",
    "        \n",
    "        print(f'''Successfully loaded Indicator {dimension}{ind_num} from {ind_value[0]} Database\\n''')\n",
    "        \n",
    "        ### Merging DF ###\n",
    "               \n",
    "        if not isinstance(full_df, pd.DataFrame):\n",
    "            \n",
    "            full_df = ind_x\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            full_df = full_df.merge(ind_x, left_index = True, right_index = True, how = 'left')\n",
    "        \n",
    "    return full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea33a5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dim_X_complete(indicator_dictionary, dimension, manual_data):\n",
    "    \n",
    "    dimension_dict = indicator_dictionary[dimension]\n",
    "    dimension_dict = {k: v for k, v in dimension_dict.items() if v}\n",
    "    \n",
    "    print(f\"\"\"\\n\\n\n",
    "    --------------------------Dimension {dimension}------------------------------\\n\n",
    "    \"\"\")\n",
    "    \n",
    "    ### Loading Data ###\n",
    "    \n",
    "    print(color.BOLD + \"Loading Data.....\\n\" + color.END)\n",
    "    \n",
    "    full_df = dimension_data_loader(dimension_dict, dimension)\n",
    "    \n",
    "#     full_df = None\n",
    "    \n",
    "#     for ind_num, ind_value in dimension_dict.items():\n",
    "        \n",
    "#         if ind_value[0] == 'WB':\n",
    "            \n",
    "#             if len(ind_value) == 3:\n",
    "            \n",
    "#                 ind_x = indicator_returner(ind_value[1], f\"{dimension}\", f\"{ind_num}\")\n",
    "            \n",
    "#             else:\n",
    "                \n",
    "#                 ind_x = indicator_returner(ind_value[1], f\"{dimension}\", f\"{ind_num}\", specify= ind_value[-1])\n",
    "                \n",
    "            \n",
    "#         if ind_value[0] == 'V-DEM':\n",
    "            \n",
    "#             rel_df = manual_data[ind_value[0]]\n",
    "            \n",
    "#             ind_x = rel_df[rel_df['year'] == 2022][['country_text_id', 'v2regsupgroupssize']].set_index('country_text_id')\n",
    "#             ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "            \n",
    "            \n",
    "#         if ind_value[0] == 'OWiD':\n",
    "            \n",
    "#             rel_df = manual_data[ind_value[0]]\n",
    "            \n",
    "#             if ind_value[1] ==  'Public Administration Index':\n",
    "               \n",
    "#                 ind_x = rel_df[ind_value[1]]\n",
    "#                 ind_x = ind_x[ind_x['Year'] == 2022].set_index('Code')[['public_admin_vdem_owid']]\n",
    "#                 ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "               \n",
    "#             if ind_value[1] ==  'Freedom of Expression Index':\n",
    "#                 ind_x = rel_df[ind_value[1]]\n",
    "#                 ind_x = ind_x[ind_x['Year'] == 2022].set_index('Code')[['freeexpr_vdem_owid']]\n",
    "#                 ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "                \n",
    "#             if ind_value[1] ==  'State Control over Territory':\n",
    "#                 ind_x = rel_df[ind_value[1]]\n",
    "#                 ind_x = ind_x[ind_x['Year'] == 2022].set_index('Code')[['terr_contr_vdem_owid']]\n",
    "#                 ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "                \n",
    "                \n",
    "#         if ind_value[0] == 'ACLED':\n",
    "            \n",
    "#             rel_df = manual_data[ind_value[0]]\n",
    "#             rel_df_2 = manual_data['iso_list']\n",
    "            \n",
    "#             if ind_value[1] ==  'Protest Count':\n",
    "                \n",
    "#                 grouped_df = rel_df[rel_df['event_type'] == 'Protests'][['country', 'year']].groupby(by = 'country')\\\n",
    "#                     .agg({'year': 'count'})\n",
    "#                 ind_x = grouped_df.merge(rel_df_2, left_index=True, right_on= 'name').set_index('alpha-3')[['year']]\n",
    "#                 ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "                \n",
    "#             if ind_value[1] ==  'Battle Related Fatalities':\n",
    "                \n",
    "#                 grouped_df = rel_df[rel_df['event_type'].isin(['Explosions/Remote violence', 'Battles'])]\\\n",
    "#                     [['country', 'fatalities']].groupby(by = 'country').agg({'fatalities': 'sum'})\n",
    "#                 ind_x = grouped_df.merge(rel_df_2, left_index=True, right_on= 'name', how = 'right').set_index('alpha-3')[['fatalities']]\n",
    "#                 ind_x['fatalities'] = ind_x['fatalities'].fillna(0)\n",
    "#                 ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "                \n",
    "#             if ind_value[1] ==  'Violence in Neighbouring States':\n",
    "                \n",
    "#                 grouped_df = rel_df.groupby(by = 'country').sum()[['fatalities']]\n",
    "#                 geo_df = manual_data['geodata']\n",
    "#                 merged_geo = geo_df.merge(grouped_df, left_on='country_border_name', right_index=True, how = 'left')\n",
    "#                 merged_grouped = merged_geo.groupby('country_name').sum()\n",
    "#                 ind_x = merged_grouped.merge(rel_df_2, left_index=True, right_on= 'name', how = 'right').set_index('alpha-3')[['fatalities']]\n",
    "#                 ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "                \n",
    "\n",
    "#         if ind_value[0] == 'ND':\n",
    "            \n",
    "#             rel_df = manual_data[ind_value[0]]\n",
    "#             ind_x = rel_df.set_index('ISO3')[['2021']]\n",
    "#             ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "            \n",
    "            \n",
    "#         if ind_value[0] == 'UNHCR':\n",
    "            \n",
    "#             rel_df = manual_data[ind_value[0]]\n",
    "#             ind_x = rel_df.set_index(\"Country of asylum (ISO)\")[[\"Refugees under UNHCR's mandate\"]]\n",
    "#             ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "            \n",
    "        \n",
    "#         print(f'''Successfully loaded Indicator {dimension}{ind_num} from {ind_value[0]} Database\\n''')\n",
    "               \n",
    "#         ### Merging DF ###\n",
    "               \n",
    "#         if not isinstance(full_df, pd.DataFrame):\n",
    "            \n",
    "#             full_df = ind_x\n",
    "            \n",
    "#         else:\n",
    "            \n",
    "#             full_df = full_df.merge(ind_x, left_index = True, right_index = True, how = 'left')\n",
    "            \n",
    "        \n",
    "    \n",
    "    \n",
    "    ### Scaling and Weighting ###\n",
    "    \n",
    "    print (color.BOLD + \"Scaling & Weighting Data....\" + color.END)\n",
    "    \n",
    "    weight_list = []\n",
    "    for values in dimension_dict.values():\n",
    "        weight_list.append(values[2])\n",
    "        \n",
    "    full_df = scale_and_weight(full_df, weight_list)\n",
    "    \n",
    "    print(f\"\"\"\\n**Successfully loaded , merged, scaled, and weighted Dimension {dimension} Data**\\n\"\"\")\n",
    "    print(color.BOLD  + \"\"\"Overall Data Coverage:\n",
    "    \"\"\" + color.END)\n",
    "    print(1- full_df.isna().sum()/len(full_df))\n",
    "\n",
    "    print(\"\"\"\\n\\n\n",
    "    ---------------------------------------------------------------------------\\n\\n\n",
    "    \n",
    "    \"\"\")\n",
    "            \n",
    "            \n",
    "    return full_df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b859e02",
   "metadata": {},
   "source": [
    "## All Dimensions Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea85cbf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479f343f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_dimension_pipeline(indicator_dictionary, manual_data):\n",
    "\n",
    "    all_dim_df = None\n",
    "\n",
    "    for key in indicator_dictionary.keys():\n",
    "\n",
    "        dimension_df = dim_X_complete(indicator_dictionary, key, manual_data)[['weighted_mean']]\n",
    "\n",
    "        dimension_df.columns = [f'Dimension_{key}']\n",
    "\n",
    "        if not isinstance(all_dim_df, pd.DataFrame):\n",
    "\n",
    "            all_dim_df = dimension_df\n",
    "\n",
    "        else:\n",
    "\n",
    "            all_dim_df = all_dim_df.merge(dimension_df, left_index = True, right_index = True, how = 'left')\n",
    "            \n",
    "    return all_dim_df\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27e8624",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = all_dimension_pipeline(indicator_dictionary=indicator_dictionary, manual_data=manual_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94162b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_list = []\n",
    "for values in dimension_weights.values():\n",
    "    weight_list.append(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930f9ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2256fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_and_weight(all_df, weight_list, return_nulls= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e1c101",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "geo_merge = world.merge(all_df, left_on = 'name', right_index = True)\n",
    "\n",
    "nrows, ncols = 4, 2\n",
    "\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(15, 10))\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, column in enumerate(all_df.columns):\n",
    "    geo_merge.plot(column=column, cmap='RdYlGn', missing_kwds={'color': 'black'}, ax=axes[idx])\n",
    "    axes[idx].set_title(f'Map for {column}')\n",
    "    axes[idx].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93c6ff4",
   "metadata": {},
   "source": [
    "# Visuallizing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2baec8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "    --------------------------Dimension R------------------------------\n",
      "\n",
      "    \n",
      "\u001b[1mLoading Data.....\n",
      "\u001b[0m\n",
      "Successfully loaded Indicator R1 from ACLED Database\n",
      "\n",
      "Successfully loaded Indicator R2 from UNHCR Database\n",
      "\n",
      "Data for 'Total Natural Resources Rents' found in WB Database 2. Returning data for the most recent year. \n",
      "        Coverage = 92.11%, greater than selected threshold of 85.0%.\n",
      "\n",
      "Successfully loaded Indicator R3 from WB Database\n",
      "\n",
      "\u001b[1mScaling & Weighting Data....\u001b[0m\n",
      "\n",
      "**Successfully loaded , merged, scaled, and weighted Dimension R Data**\n",
      "\n",
      "\u001b[1mOverall Data Coverage:\n",
      "    \u001b[0m\n",
      "ind_R1           0.959538\n",
      "ind_R2           0.884393\n",
      "ind_R3           0.919075\n",
      "weighted_mean    1.000000\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "    ---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "    \n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ind_R1</th>\n",
       "      <th>ind_R2</th>\n",
       "      <th>ind_R3</th>\n",
       "      <th>weighted_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fr. S. Antarctic Lands</th>\n",
       "      <td>1.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Greenland</th>\n",
       "      <td>1.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Falkland Is.</th>\n",
       "      <td>1.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Antarctica</th>\n",
       "      <td>1.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North Korea</th>\n",
       "      <td>1.499144</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.499144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Slovakia</th>\n",
       "      <td>-1.444332</td>\n",
       "      <td>0.945877</td>\n",
       "      <td>0.496295</td>\n",
       "      <td>-0.000720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Romania</th>\n",
       "      <td>-1.445759</td>\n",
       "      <td>0.940800</td>\n",
       "      <td>0.481250</td>\n",
       "      <td>-0.007903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chad</th>\n",
       "      <td>-0.867379</td>\n",
       "      <td>0.667757</td>\n",
       "      <td>0.150315</td>\n",
       "      <td>-0.016436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Poland</th>\n",
       "      <td>-1.444998</td>\n",
       "      <td>0.455685</td>\n",
       "      <td>0.483120</td>\n",
       "      <td>-0.168731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Russia</th>\n",
       "      <td>-1.500000</td>\n",
       "      <td>0.283868</td>\n",
       "      <td>0.196715</td>\n",
       "      <td>-0.339806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>173 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          ind_R1    ind_R2    ind_R3  weighted_mean\n",
       "name                                                               \n",
       "Fr. S. Antarctic Lands  1.500000       NaN       NaN       1.500000\n",
       "Greenland               1.500000       NaN       NaN       1.500000\n",
       "Falkland Is.            1.500000       NaN       NaN       1.500000\n",
       "Antarctica              1.500000       NaN       NaN       1.500000\n",
       "North Korea             1.499144       NaN       NaN       1.499144\n",
       "...                          ...       ...       ...            ...\n",
       "Slovakia               -1.444332  0.945877  0.496295      -0.000720\n",
       "Romania                -1.445759  0.940800  0.481250      -0.007903\n",
       "Chad                   -0.867379  0.667757  0.150315      -0.016436\n",
       "Poland                 -1.444998  0.455685  0.483120      -0.168731\n",
       "Russia                 -1.500000  0.283868  0.196715      -0.339806\n",
       "\n",
       "[173 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_X_complete(indicator_dictionary, \"R\", manual_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2c0ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_individual_indicators(dimension_df):\n",
    "    \n",
    "    just_ind_df = dimension_df.drop(columns='weighted_mean')\n",
    "\n",
    "    world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "    geo_merge = world.merge(just_ind_df, left_on = 'name', right_index = True)\n",
    "\n",
    "    nrows, ncols = 4, 2\n",
    "\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(15, 10))\n",
    "\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, column in enumerate(just_ind_df.columns):\n",
    "        geo_merge.plot(column=column, cmap='RdYlGn', missing_kwds={'color': 'black'}, ax=axes[idx])\n",
    "        axes[idx].set_title(f'Map for {column}')\n",
    "        axes[idx].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5b23e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_individual_indicators(dim_X_complete(indicator_dictionary, 'R', manual_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
