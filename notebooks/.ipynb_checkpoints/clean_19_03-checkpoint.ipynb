{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0b17e0f",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04fa63ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "# Data Analysis\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "\n",
    "\n",
    "# WBAPI\n",
    "\n",
    "import wbgapi as wb\n",
    "\n",
    "# Data Processing\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Aesthetic\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class color:\n",
    "   BOLD = '\\033[1m'\n",
    "   END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c12ed3d",
   "metadata": {},
   "source": [
    "# Manual Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5b1d2703",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdem_df = pd.read_csv(\"../data/vdem/V-Dem-CY-Full+Others-v13.csv\", usecols=['country_text_id', 'v2regsupgroupssize', 'year'])\n",
    "\n",
    "owid_freedom_of_expression_df = pd.read_csv('../data/owid/freedom-of-expression-index.csv')\n",
    "\n",
    "owid_pa_index_df = pd.read_csv('../data/owid/rigorous-and-impartial-public-administration-index.csv')\n",
    "\n",
    "owid_state_control_df = pd.read_csv('../data/owid/percentage-of-territory-controlled-by-government.csv')\n",
    "\n",
    "acled_df = pd.read_csv('../data/acled/2023_all_data.csv', usecols= ['event_type', 'country', 'fatalities', 'population_best', 'year'])\n",
    "\n",
    "nd_df = pd.read_csv('../data/nd/gain.csv')\n",
    "\n",
    "unhcr_df = pd.read_csv('../data/population.csv')\n",
    "\n",
    "geo_df = pd.read_csv('../data/geodata.csv')\n",
    "\n",
    "iso_list = pd.read_csv(\"../data/all.csv\", usecols= ['name', 'alpha-3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5d46405b",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_data = {\n",
    "    'V-DEM': vdem_df,\n",
    "    'OWiD': {\n",
    "        'Public Administration Index': owid_pa_index_df,\n",
    "        'Freedom of Expression Index': owid_freedom_of_expression_df,\n",
    "        'State Control over Territory': owid_state_control_df\n",
    "    },\n",
    "    'ACLED': acled_df,\n",
    "    'ND': nd_df,\n",
    "    'UNHCR': unhcr_df,\n",
    "    'iso_list': iso_list,\n",
    "    'geodata': geo_df\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6703edb8",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8175a160",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## WB API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e96f37e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def indicator_to_df(query, specify = False):\n",
    "\n",
    "    # Function to get indicator code\n",
    "\n",
    "    if specify:\n",
    "        return pd.DataFrame(wb.series.Series(q= query)).reset_index().iloc[specify]\n",
    "    return pd.DataFrame(wb.series.Series(q= query)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "165cd8b6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def wb_data_completer(indicator, coverage_threshold = 0.85, years_to_check = 10, database = None, specify = False):\n",
    "    \n",
    "    def indicator_to_df(query, specify = False):\n",
    "        \n",
    "        # Function to get indicator code\n",
    "        \n",
    "        if specify:\n",
    "            return pd.DataFrame(wb.series.Series(q= query)).reset_index().iloc[specify]\n",
    "        return pd.DataFrame(wb.series.Series(q= query)).reset_index()\n",
    "    \n",
    "    def fetch_data_and_calculate_completeness(database_number):\n",
    "        \n",
    "        # Checks coverage of data\n",
    "        \n",
    "        wb.db = database_number\n",
    "        db_ind = indicator_to_df(indicator, specify = specify)\n",
    "        \n",
    "        if len(db_ind) == 0:  # If no data is found for this database\n",
    "            return 0  # Completeness is 0%\n",
    "        return float(wb.data.DataFrame(db_ind['index'], mrv=1).notna().mean())\n",
    "    \n",
    "    # Check which database to use if not specified\n",
    "    \n",
    "    if database is None:\n",
    "        \n",
    "        db2_complete = fetch_data_and_calculate_completeness(2)\n",
    "        db3_complete = fetch_data_and_calculate_completeness(3)\n",
    "        \n",
    "        database = 2 if db2_complete >= db3_complete or db3_complete == 0 else 3\n",
    "    \n",
    "    # Check coverage of most recent year\n",
    "    \n",
    "    wb.db = database\n",
    "    coverage_complete = fetch_data_and_calculate_completeness(database)\n",
    "    final_ind = indicator_to_df(indicator, specify = specify)\n",
    "        \n",
    "    # Return mrv = 1 if already passing data threshold\n",
    "    \n",
    "    if coverage_complete > coverage_threshold:\n",
    "        print(f\"\"\"Data for '{indicator}' found in WB Database {database}. Returning data for the most recent year. \n",
    "        Coverage = {round(coverage_complete, 4)*100}%, greater than selected threshold of {round(coverage_threshold, 4)*100}%.\\n\"\"\")\n",
    "        final_ind = wb.data.DataFrame(final_ind['index'], mrv=1)\n",
    "        final_ind.columns = ['Final Value']\n",
    "        \n",
    "        return final_ind\n",
    "    \n",
    "    # Otherwise go back number of years specified\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        print(f\"\"\"Data for '{indicator}' does not meet the coverage threshold of {coverage_threshold*100}% in WB Database {database}.\n",
    "        Extracting data from previous years.\"\"\")\n",
    "        \n",
    "        # Get Data\n",
    "        \n",
    "        \n",
    "        multiyear_df = wb.data.DataFrame(final_ind['index'], mrv=years_to_check)\n",
    "        \n",
    "        # Loop through DF in reverse order\n",
    "        \n",
    "        current_year = int(multiyear_df.columns[-1][2:])\n",
    "        all_years = list(range(current_year, current_year - years_to_check, -1)) \n",
    "        \n",
    "        for i, year in enumerate(all_years):\n",
    "            year_column = f'YR{year}'\n",
    "            \n",
    "            # Skip years that don't have a corresponding column in the DataFrame\n",
    "            \n",
    "            if year_column not in multiyear_df.columns:\n",
    "                continue \n",
    "                \n",
    "            # For the first year, initialize 'Final_Value' with its values\n",
    "            \n",
    "            if i == 0:\n",
    "                multiyear_df['Final_Value'] = multiyear_df[year_column]\n",
    "                \n",
    "            # Fill missing values in 'Final_Value' with the current year's data\n",
    " \n",
    "            else:\n",
    "                multiyear_df['Final_Value'] = multiyear_df['Final_Value'].fillna(multiyear_df[year_column])\n",
    "            \n",
    "            # Check data completeness for 'Final_Value' after potential filling\n",
    "            \n",
    "            data_coverage = multiyear_df['Final_Value'].notna().mean()\n",
    "            if data_coverage >= coverage_threshold:\n",
    "                print(f\"\"\"Achieved {round(data_coverage,4)*100}% data coverage by going back to data from {year},\n",
    "                exceeding minimum threshold of {coverage_threshold*100}%. Returning this dataframe.\\n\"\"\")\n",
    "                break\n",
    "                \n",
    "        # Return Final DF\n",
    "                \n",
    "        if data_coverage < coverage_threshold:\n",
    "            \n",
    "            print(f\"\"\"Data coverage at {round(data_coverage,4)*100}% after going back {years_to_check} years.\n",
    "            Failed to exceed minimum threshold of {coverage_threshold*100}%. Returning best dataframe anyway.\\n\"\"\")\n",
    "            \n",
    "            \n",
    "        return multiyear_df[['Final_Value']]\n",
    "\n",
    "def indicator_returner(query, dimension = 'dim', indicator = 'ind', specify = False):\n",
    "    \n",
    "    df = wb_data_completer(query, specify = specify)\n",
    "    df.columns = [f'ind_{dimension}{indicator}']\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d766e7c",
   "metadata": {},
   "source": [
    "## GeoProcessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd39d364",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09b4f025",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def scale_and_weight(merged_df, weight_list, return_nulls = False):\n",
    "    \n",
    "    # Scale\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_df = scaler.fit_transform(merged_df)\n",
    "    scaled_df = pd.DataFrame(scaled_df, columns=scaler.get_feature_names_out()).sub(0.5)\n",
    "    scaled_df.index = merged_df.index\n",
    "    \n",
    "    # Weight\n",
    "    \n",
    "    keys = scaled_df.columns\n",
    "    \n",
    "    weights = dict(zip(keys, weight_list))\n",
    "\n",
    "    weighted_df = pd.DataFrame()\n",
    "\n",
    "    for column, weight in weights.items():\n",
    "        weighted_df[column] = scaled_df[column] * weight\n",
    "        \n",
    "    # Weighted mean\n",
    "    \n",
    "    weighted_df['weighted_mean'] = weighted_df.mean(axis=1)\n",
    "    weighted_df['weighted_mean'] = weighted_df.apply(lambda row: np.nan if row[keys].isnull().sum() > 2 else row['weighted_mean'], axis=1)\n",
    "    weighted_df = weighted_df.sort_values('weighted_mean', ascending=False)\n",
    "    \n",
    "    # Adding country names as index\n",
    "    \n",
    "    world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "    listylist = list(weighted_df.columns)\n",
    "    listylist.append('name')\n",
    "    final_df = weighted_df.merge(world, left_index=True, right_on='iso_a3')[listylist].set_index('name')\n",
    "    \n",
    "    if return_nulls:\n",
    "        return final_df\n",
    "    \n",
    "    return final_df[final_df['weighted_mean'].notnull()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246b7b11",
   "metadata": {},
   "source": [
    "## Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8fd92ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>SeriesName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VC.IHR.PSRC.FE.P5</td>\n",
       "      <td>Intentional homicides, female (per 100,000 fem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VC.IHR.PSRC.MA.P5</td>\n",
       "      <td>Intentional homicides, male (per 100,000 male)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VC.IHR.PSRC.P5</td>\n",
       "      <td>Intentional homicides (per 100,000 people)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               index                                         SeriesName\n",
       "0  VC.IHR.PSRC.FE.P5  Intentional homicides, female (per 100,000 fem...\n",
       "1  VC.IHR.PSRC.MA.P5     Intentional homicides, male (per 100,000 male)\n",
       "2     VC.IHR.PSRC.P5         Intentional homicides (per 100,000 people)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indicator_to_df('Intentional homicides')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "853cfad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dim_X_complete(indicator_dictionary, dimension, manual_data):\n",
    "    \n",
    "    dimension_dict = indicator_dictionary[dimension]\n",
    "    dimension_dict = {k: v for k, v in dimension_dict.items() if v}\n",
    "    \n",
    "    print(f\"\"\"\\n\\n\n",
    "    --------------------------Dimension {dimension}------------------------------\\n\n",
    "    \"\"\")\n",
    "    \n",
    "    ### Loading Data ###\n",
    "    \n",
    "    print(color.BOLD + \"Loading Data.....\\n\" + color.END)\n",
    "    \n",
    "    full_df = None\n",
    "    \n",
    "    for ind_num, ind_value in dimension_dict.items():\n",
    "        \n",
    "        if ind_value[0] == 'WB':\n",
    "            \n",
    "            if len(ind_value) == 3:\n",
    "            \n",
    "                ind_x = indicator_returner(ind_value[1], f\"{dimension}\", f\"{ind_num}\")\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                ind_x = indicator_returner(ind_value[1], f\"{dimension}\", f\"{ind_num}\", specify= ind_value[-1])\n",
    "                \n",
    "            \n",
    "        if ind_value[0] == 'V-DEM':\n",
    "            \n",
    "            rel_df = manual_data[ind_value[0]]\n",
    "            \n",
    "            ind_x = rel_df[rel_df['year'] == 2022][['country_text_id', 'v2regsupgroupssize']].set_index('country_text_id')\n",
    "            ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "            \n",
    "            \n",
    "        if ind_value[0] == 'OWiD':\n",
    "            \n",
    "            rel_df = manual_data[ind_value[0]]\n",
    "            \n",
    "            if ind_value[1] ==  'Public Administration Index':\n",
    "               \n",
    "                ind_x = rel_df[ind_value[1]]\n",
    "                ind_x = ind_x[ind_x['Year'] == 2022].set_index('Code')[['public_admin_vdem_owid']]\n",
    "                ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "               \n",
    "            if ind_value[1] ==  'Freedom of Expression Index':\n",
    "                ind_x = rel_df[ind_value[1]]\n",
    "                ind_x = ind_x[ind_x['Year'] == 2022].set_index('Code')[['freeexpr_vdem_owid']]\n",
    "                ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "                \n",
    "            if ind_value[1] ==  'State Control over Territory':\n",
    "                ind_x = rel_df[ind_value[1]]\n",
    "                ind_x = ind_x[ind_x['Year'] == 2022].set_index('Code')[['terr_contr_vdem_owid']]\n",
    "                ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "                \n",
    "                \n",
    "        if ind_value[0] == 'ACLED':\n",
    "            \n",
    "            rel_df = manual_data[ind_value[0]]\n",
    "            rel_df_2 = manual_data['iso_list']\n",
    "            \n",
    "            if ind_value[1] ==  'Protest Count':\n",
    "                \n",
    "                grouped_df = rel_df[rel_df['event_type'] == 'Protests'][['country', 'year']].groupby(by = 'country')\\\n",
    "                    .agg({'year': 'count'})\n",
    "                ind_x = grouped_df.merge(rel_df_2, left_index=True, right_on= 'name').set_index('alpha-3')[['year']]\n",
    "                ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "                \n",
    "            if ind_value[1] ==  'Battle Related Fatalities':\n",
    "                \n",
    "                grouped_df = rel_df[rel_df['event_type'].isin(['Explosions/Remote violence', 'Battles'])]\\\n",
    "                    [['country', 'fatalities']].groupby(by = 'country').agg({'fatalities': 'sum'})\n",
    "                ind_x = grouped_df.merge(rel_df_2, left_index=True, right_on= 'name', how = 'right').set_index('alpha-3')[['fatalities']]\n",
    "                ind_x['fatalities'] = ind_x['fatalities'].fillna(0)\n",
    "                ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "                \n",
    "            if ind_value[1] ==  'Violence in Neighbouring States':\n",
    "                \n",
    "                grouped_df = rel_df.groupby(by = 'country').sum()[['fatalities']]\n",
    "                geo_df = manual_data['geodata']\n",
    "                merged_geo = geo_df.merge(grouped_df, left_on='country_border_name', right_index=True, how = 'left')\n",
    "                merged_grouped = merged_geo.groupby('country_name').sum()\n",
    "                ind_x = merged_grouped.merge(rel_df_2, left_index=True, right_on= 'name', how = 'right').set_index('alpha-3')[['fatalities']]\n",
    "                ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "                \n",
    "\n",
    "        if ind_value[0] == 'ND':\n",
    "            \n",
    "            rel_df = manual_data[ind_value[0]]\n",
    "            ind_x = rel_df.set_index('ISO3')[['2021']]\n",
    "            ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "            \n",
    "            \n",
    "        if ind_value[0] == 'UNHCR':\n",
    "            \n",
    "            rel_df = manual_data[ind_value[0]]\n",
    "            ind_x = rel_df.set_index(\"Country of asylum (ISO)\")[[\"Refugees under UNHCR's mandate\"]]\n",
    "            ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "            \n",
    "        \n",
    "        print(f'''Successfully loaded Indicator {dimension}{ind_num} from {ind_value[0]} Database\\n''')\n",
    "               \n",
    "        ### Merging DF ###\n",
    "               \n",
    "        if not isinstance(full_df, pd.DataFrame):\n",
    "            \n",
    "            full_df = ind_x\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            full_df = full_df.merge(ind_x, left_index = True, right_index = True, how = 'left')\n",
    "            \n",
    "        \n",
    "    \n",
    "    \n",
    "    ### Scaling and Weighting ###\n",
    "    \n",
    "    print (color.BOLD + \"Scaling & Weighting Data....\" + color.END)\n",
    "    \n",
    "    weight_list = []\n",
    "    for values in dimension_dict.values():\n",
    "        weight_list.append(values[2])\n",
    "        \n",
    "    full_df = scale_and_weight(full_df, weight_list)\n",
    "    \n",
    "    print(f\"\"\"\\n**Successfully loaded , merged, scaled, and weighted Dimension {dimension} Data**\\n\"\"\")\n",
    "    print(color.BOLD  + \"\"\"Overall Data Coverage:\n",
    "    \"\"\" + color.END)\n",
    "    print(1- full_df.isna().sum()/len(full_df))\n",
    "\n",
    "    print(\"\"\"\\n\\n\n",
    "    ---------------------------------------------------------------------------\\n\\n\n",
    "    \n",
    "    \"\"\")\n",
    "            \n",
    "            \n",
    "    return full_df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6baab1",
   "metadata": {},
   "source": [
    "# Fragility Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cd2abc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator_dictionary = {\n",
    "    'G': {\n",
    "        1:['V-DEM', 'Size of Regime Support Group', 3],\n",
    "        2:['OWiD', 'Public Administration Index', 2],\n",
    "        3:['WB', 'Control of Corruption: Estimate', 2],\n",
    "        4:['WB', 'Rule of Law: Estimate', 2],\n",
    "        5:['WB', 'Tax Revenue', 2, slice(1,2)],\n",
    "        6:['WB', 'Proportion of Seats Held by Women', 1],\n",
    "        7:['OWiD', 'Freedom of Expression Index', 1]\n",
    "    },\n",
    "    'S': {\n",
    "        1:['WB', 'Gini Index', -3],\n",
    "        2:['WB', 'Inflation, Consumer Prices', -2],\n",
    "        3:['WB', 'Unemployment, Total', -2, slice(1,2)],\n",
    "        4:['WB', 'Women Business and the Law Index', 2],\n",
    "        5:['ACLED', 'Protest Count', -2],\n",
    "        6:['WB', 'Age Dependency Ratio', -1, slice(0,1)],\n",
    "        7:['WB', 'Ease of Doing Business Score', 1]\n",
    "    },\n",
    "    'I': {\n",
    "        1:['WB', 'GDP per Capita', 3, slice(0,1)],\n",
    "        2:['WB', 'Poverty Gap at $2.15 a Day', -3],\n",
    "        3:['WB', 'Human Capital Index', 2, slice(0,1)],\n",
    "        4:['WB', 'Women who Believe a Husband is Justified in Beating his Wife', -2, slice(4,5)],\n",
    "        5:['WB', 'Current Health Expenditure per Capita, PPP', 2],\n",
    "        6:[],\n",
    "        7:[]\n",
    "    },\n",
    "    'C': {\n",
    "        1:['ACLED', 'Battle Related Fatalities', -3],\n",
    "        2:[],\n",
    "        3:['OWiD', 'State Control over Territory', 2],\n",
    "        4:['WB', 'Intentional homicides', -2, slice(2,3)],\n",
    "        5:[],\n",
    "        6:[],\n",
    "        7:[]\n",
    "    },\n",
    "    'E': {\n",
    "        1:['ND', 'GAIN Index', 3],\n",
    "        2:[],\n",
    "        3:[],\n",
    "        4:[],\n",
    "        5:[],\n",
    "        6:[],\n",
    "        7:[]\n",
    "    },\n",
    "    'R': {\n",
    "        1:['ACLED', 'Violence in Neighbouring States', -3],\n",
    "        2:['UNHCR', 'Refugee In-Flow', -2],\n",
    "        3:[],\n",
    "        4:[],\n",
    "        5:[],\n",
    "        6:[],\n",
    "        7:[]\n",
    "    }\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6992d08",
   "metadata": {},
   "source": [
    "# Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f97bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wb.db =2\n",
    "pd.set_option('max_colwidth', 400)\n",
    "indicator_to_df('Financial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba3f700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7c2a5eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "    --------------------------Dimension R------------------------------\n",
      "\n",
      "    \n",
      "\u001b[1mLoading Data.....\n",
      "\u001b[0m\n",
      "Successfully loaded Indicator R1 from ACLED Database\n",
      "\n",
      "Successfully loaded Indicator R2 from UNHCR Database\n",
      "\n",
      "\u001b[1mScaling & Weighting Data....\u001b[0m\n",
      "\n",
      "**Successfully loaded , merged, scaled, and weighted Dimension R Data**\n",
      "\n",
      "\u001b[1mOverall Data Coverage:\n",
      "    \u001b[0m\n",
      "ind_R1           0.959538\n",
      "ind_R2           0.884393\n",
      "weighted_mean    1.000000\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "    ---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "    \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "s_df = dim_X_complete(indicator_dictionary, \"R\", manual_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "49d92233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ind_R1</th>\n",
       "      <th>ind_R2</th>\n",
       "      <th>weighted_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Russia</th>\n",
       "      <td>-1.500000</td>\n",
       "      <td>0.283868</td>\n",
       "      <td>-0.608066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Poland</th>\n",
       "      <td>-1.444998</td>\n",
       "      <td>0.455685</td>\n",
       "      <td>-0.494657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Romania</th>\n",
       "      <td>-1.445759</td>\n",
       "      <td>0.940800</td>\n",
       "      <td>-0.252480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Slovakia</th>\n",
       "      <td>-1.444332</td>\n",
       "      <td>0.945877</td>\n",
       "      <td>-0.249227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hungary</th>\n",
       "      <td>-1.445759</td>\n",
       "      <td>0.980175</td>\n",
       "      <td>-0.232792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fr. S. Antarctic Lands</th>\n",
       "      <td>1.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Puerto Rico</th>\n",
       "      <td>1.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Greenland</th>\n",
       "      <td>1.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Falkland Is.</th>\n",
       "      <td>1.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Solomon Is.</th>\n",
       "      <td>1.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>173 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          ind_R1    ind_R2  weighted_mean\n",
       "name                                                     \n",
       "Russia                 -1.500000  0.283868      -0.608066\n",
       "Poland                 -1.444998  0.455685      -0.494657\n",
       "Romania                -1.445759  0.940800      -0.252480\n",
       "Slovakia               -1.444332  0.945877      -0.249227\n",
       "Hungary                -1.445759  0.980175      -0.232792\n",
       "...                          ...       ...            ...\n",
       "Fr. S. Antarctic Lands  1.500000       NaN       1.500000\n",
       "Puerto Rico             1.500000       NaN       1.500000\n",
       "Greenland               1.500000       NaN       1.500000\n",
       "Falkland Is.            1.500000       NaN       1.500000\n",
       "Solomon Is.             1.500000       NaN       1.500000\n",
       "\n",
       "[173 rows x 3 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_df.sort_values('weighted_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916ee577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_tables_and_maps(dimensions, indicators = False, table = True, geomap = True):\n",
    "    \n",
    "    for dimension in dimensions:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab94099",
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator_dictionary.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d51810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def display_all_dimensions(indicator_dictionary, manual_data):\n",
    "\n",
    "#     world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "\n",
    "# `\n",
    "#     for key in indicator_dictionary.keys():\n",
    "\n",
    "#         dimension_df = dim_X_complete(indicator_dictionary, key, manual_data)\n",
    "#         geo_merge = world.merge(dimension_df, left_on = 'name', right_index = True)\n",
    "\n",
    "#         geo_merge.plot(column='weighted_mean', cmap='RdYlGn', missing_kwds={'color': 'black'}, figsize=(10, 8))\n",
    "#         plt.title(f'Map for Dimension {key}')\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc62f7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_individual_indicators(dimension_df):\n",
    "    \n",
    "    just_ind_df = dimension_df.drop(columns='weighted_mean')\n",
    "\n",
    "    world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "    geo_merge = world.merge(just_ind_df, left_on = 'name', right_index = True)\n",
    "\n",
    "    nrows, ncols = 4, 2\n",
    "\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(15, 10))\n",
    "\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, column in enumerate(just_ind_df.columns):\n",
    "        geo_merge.plot(column=column, cmap='RdYlGn', missing_kwds={'color': 'black'}, ax=axes[idx])\n",
    "        axes[idx].set_title(f'Map for {column}')\n",
    "        axes[idx].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a08050",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_individual_indicators(dim_X_complete(indicator_dictionary, 'S', manual_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
