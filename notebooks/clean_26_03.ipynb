{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4d85ca2",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8036826",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# General\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "# Data Analysis\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "# WBAPI\n",
    "\n",
    "import wbgapi as wb\n",
    "\n",
    "# Data Processing\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Aesthetic\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class color:\n",
    "   BOLD = '\\033[1m'\n",
    "   END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934e23af",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Manual Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "289ba8bd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vdem_df = pd.read_csv(\"../data/vdem/V-Dem-CY-Full+Others-v13.csv\", usecols=['country_text_id', 'v2regsupgroupssize', 'year'])\n",
    "\n",
    "owid_freedom_of_expression_df = pd.read_csv('../data/owid/freedom-of-expression-index.csv')\n",
    "\n",
    "owid_pa_index_df = pd.read_csv('../data/owid/rigorous-and-impartial-public-administration-index.csv')\n",
    "\n",
    "owid_state_control_df = pd.read_csv('../data/owid/percentage-of-territory-controlled-by-government.csv')\n",
    "\n",
    "acled_df = pd.read_csv('../data/acled/2023_all_data.csv', usecols= ['event_type', 'country', 'fatalities', 'population_best', 'year', 'iso'])\n",
    "\n",
    "nd_df = pd.read_csv('../data/nd/gain.csv')\n",
    "\n",
    "unhcr_df = pd.read_csv('../data/population.csv')\n",
    "\n",
    "geo_df = pd.read_csv('../data/geodata.csv')\n",
    "\n",
    "iso_list = pd.read_csv(\"../data/all.csv\", usecols= ['name', 'alpha-3', 'country-code'])\n",
    "\n",
    "manual_data = {\n",
    "    'V-DEM': vdem_df,\n",
    "    'OWiD': {\n",
    "        'Public Administration Index': owid_pa_index_df,\n",
    "        'Freedom of Expression Index': owid_freedom_of_expression_df,\n",
    "        'State Control over Territory': owid_state_control_df\n",
    "    },\n",
    "    'ACLED': acled_df,\n",
    "    'ND': nd_df,\n",
    "    'UNHCR': unhcr_df,\n",
    "    'iso_list': iso_list,\n",
    "    'geodata': geo_df\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44b9d11",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Fragility Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dde8e7d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dimension_weights = {\n",
    "    'G': 3,\n",
    "    'S': 2,\n",
    "    'I': 2,\n",
    "    'C': 3,\n",
    "    'E': 1,\n",
    "    'R': 1\n",
    "}\n",
    "\n",
    "indicator_dictionary = {\n",
    "    'G': {\n",
    "        1:['V-DEM', 'Size of Regime Support Group', 3],\n",
    "        2:['OWiD', 'Public Administration Index', 2],\n",
    "        3:['WB', 'Control of Corruption: Estimate', 2],\n",
    "        4:['WB', 'Rule of Law: Estimate', 2],\n",
    "        5:['WB', 'Tax Revenue', 2, slice(1,2)],\n",
    "        6:['WB', 'Proportion of Seats Held by Women', 1],\n",
    "        7:['OWiD', 'Freedom of Expression Index', 1]\n",
    "    },\n",
    "    'S': {\n",
    "        1:['WB', 'Gini Index', -3],\n",
    "        2:['WB', 'Inflation, Consumer Prices', -2],\n",
    "        3:['WB', 'Unemployment, Total', -2, slice(1,2)],\n",
    "        4:['WB', 'Women Business and the Law Index', 2],\n",
    "        5:['ACLED', 'Protest Count', -2],\n",
    "        6:['WB', 'Age Dependency Ratio', -1, slice(0,1)],\n",
    "        7:['WB', 'Ease of Doing Business Score', 1]\n",
    "    },\n",
    "    'I': {\n",
    "        1:['WB', 'GDP per Capita', 3, slice(0,1)],\n",
    "        2:['WB', 'Poverty Gap at $2.15 a Day', -3],\n",
    "        3:['WB', 'Human Capital Index', 2, slice(0,1)],\n",
    "        4:['WB', 'Women who Believe a Husband is Justified in Beating his Wife', -2, slice(4,5)],\n",
    "        5:['WB', 'Current Health Expenditure per Capita, PPP', 2],\n",
    "        6:[],\n",
    "        7:[]\n",
    "    },\n",
    "    'C': {\n",
    "        1:['ACLED', 'Battle Related Fatalities', -3],\n",
    "        2:[],\n",
    "        3:['OWiD', 'State Control over Territory', 2],\n",
    "        4:['WB', 'Intentional homicides', -2, slice(2,3)],\n",
    "        5:[],\n",
    "        6:[],\n",
    "        7:[]\n",
    "    },\n",
    "    'E': {\n",
    "        1:['ND', 'GAIN Index', 3],\n",
    "        2:[],\n",
    "        3:[],\n",
    "        4:[],\n",
    "        5:[],\n",
    "        6:[],\n",
    "        7:[]\n",
    "    },\n",
    "    'R': {\n",
    "        1:['ACLED', 'Violence in Neighbouring States', -3],\n",
    "        2:['UNHCR', 'Refugee In-Flow', -2],\n",
    "        3:['WB','Total Natural Resources Rents', -1],\n",
    "        4:[],\n",
    "        5:[],\n",
    "        6:[],\n",
    "        7:[]\n",
    "    }\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e11bef8",
   "metadata": {},
   "source": [
    "# Data Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd81b23c",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## WB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad9f8ace",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def indicator_to_df(query, specify = False):\n",
    "\n",
    "    # Function to get indicator code\n",
    "\n",
    "    if specify:\n",
    "        return pd.DataFrame(wb.series.Series(q= query)).reset_index().iloc[specify]\n",
    "    return pd.DataFrame(wb.series.Series(q= query)).reset_index()\n",
    "\n",
    "def wb_data_completer(indicator, coverage_threshold = 0.85, years_to_check = 10, database = None, specify = False):\n",
    "    \n",
    "    def fetch_data_and_calculate_completeness(database_number):\n",
    "        \n",
    "        # Checks coverage of data\n",
    "        \n",
    "        wb.db = database_number\n",
    "        db_ind = indicator_to_df(indicator, specify = specify)\n",
    "        \n",
    "        if len(db_ind) == 0:  # If no data is found for this database\n",
    "            return 0  # Completeness is 0%\n",
    "        return float(wb.data.DataFrame(db_ind['index'], mrv=1).notna().mean())\n",
    "    \n",
    "    # Check which database to use if not specified\n",
    "    \n",
    "    if database is None:\n",
    "        \n",
    "        db2_complete = fetch_data_and_calculate_completeness(2)\n",
    "        db3_complete = fetch_data_and_calculate_completeness(3)\n",
    "        \n",
    "        database = 2 if db2_complete >= db3_complete or db3_complete == 0 else 3\n",
    "    \n",
    "    # Check coverage of most recent year\n",
    "    \n",
    "    wb.db = database\n",
    "    coverage_complete = fetch_data_and_calculate_completeness(database)\n",
    "    final_ind = indicator_to_df(indicator, specify = specify)\n",
    "        \n",
    "    # Return mrv = 1 if already passing data threshold\n",
    "    \n",
    "    if coverage_complete > coverage_threshold:\n",
    "        print(f\"\"\"Data for '{indicator}' found in WB Database {database}. Returning data for the most recent year. \n",
    "        Coverage = {round(coverage_complete, 4)*100}%, greater than selected threshold of {round(coverage_threshold, 4)*100}%.\\n\"\"\")\n",
    "        final_ind = wb.data.DataFrame(final_ind['index'], mrv=1)\n",
    "        final_ind.columns = ['Final Value']\n",
    "        \n",
    "        return final_ind\n",
    "    \n",
    "    # Otherwise go back number of years specified\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        print(f\"\"\"Data for '{indicator}' does not meet the coverage threshold of {coverage_threshold*100}% in WB Database {database}.\n",
    "        Extracting data from previous years.\"\"\")\n",
    "        \n",
    "        # Get Data\n",
    "        \n",
    "        \n",
    "        multiyear_df = wb.data.DataFrame(final_ind['index'], mrv=years_to_check)\n",
    "        \n",
    "        # Loop through DF in reverse order\n",
    "        \n",
    "        current_year = int(multiyear_df.columns[-1][2:])\n",
    "        all_years = list(range(current_year, current_year - years_to_check, -1)) \n",
    "        \n",
    "        for i, year in enumerate(all_years):\n",
    "            year_column = f'YR{year}'\n",
    "            \n",
    "            # Skip years that don't have a corresponding column in the DataFrame\n",
    "            \n",
    "            if year_column not in multiyear_df.columns:\n",
    "                continue \n",
    "                \n",
    "            # For the first year, initialize 'Final_Value' with its values\n",
    "            \n",
    "            if i == 0:\n",
    "                multiyear_df['Final_Value'] = multiyear_df[year_column]\n",
    "                \n",
    "            # Fill missing values in 'Final_Value' with the current year's data\n",
    " \n",
    "            else:\n",
    "                multiyear_df['Final_Value'] = multiyear_df['Final_Value'].fillna(multiyear_df[year_column])\n",
    "            \n",
    "            # Check data completeness for 'Final_Value' after potential filling\n",
    "            \n",
    "            data_coverage = multiyear_df['Final_Value'].notna().mean()\n",
    "            if data_coverage >= coverage_threshold:\n",
    "                print(f\"\"\"Achieved {round(data_coverage,4)*100}% data coverage by going back to data from {year},\n",
    "                exceeding minimum threshold of {coverage_threshold*100}%. Returning this dataframe.\\n\"\"\")\n",
    "                break\n",
    "                \n",
    "        # Return Final DF\n",
    "                \n",
    "        if data_coverage < coverage_threshold:\n",
    "            \n",
    "            print(f\"\"\"Data coverage at {round(data_coverage,4)*100}% after going back {years_to_check} years.\n",
    "            Failed to exceed minimum threshold of {coverage_threshold*100}%. Returning best dataframe anyway.\\n\"\"\")\n",
    "            \n",
    "            \n",
    "        return multiyear_df[['Final_Value']]\n",
    "\n",
    "def indicator_returner(query, dimension = 'dim', indicator = 'ind', specify = False):\n",
    "    \n",
    "    df = wb_data_completer(query, specify = specify)\n",
    "    df.columns = [f'ind_{dimension}{indicator}']\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a556672",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c60b961",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def scale_and_weight(merged_df, weight_list, single_dimension = True):\n",
    "    \n",
    "    # Scale\n",
    "    \n",
    "    if not single_dimension:\n",
    "        temp_df = merged_df[['iso']]\n",
    "        merged_df = merged_df.drop(columns = 'iso')\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_nums = scaler.fit_transform(merged_df)\n",
    "    scaled_df = pd.DataFrame(scaled_nums, columns=scaler.get_feature_names_out()).sub(0.5)\n",
    "    scaled_df.index = merged_df.index\n",
    "    \n",
    "    # Weight\n",
    "    \n",
    "    keys = scaled_df.columns\n",
    "    \n",
    "    weights = dict(zip(keys, weight_list))\n",
    "\n",
    "    weighted_df = pd.DataFrame()\n",
    "\n",
    "    for column, weight in weights.items():\n",
    "        weighted_df[column] = scaled_df[column] * weight\n",
    "        \n",
    "    # Weighted mean\n",
    "    \n",
    "    weighted_df['weighted_mean'] = weighted_df.mean(axis=1)\n",
    "    \n",
    "    if single_dimension:\n",
    "        weighted_df['weighted_mean'] = weighted_df.apply(lambda row: np.nan if row[keys].isnull().sum() > 2 else row['weighted_mean'], axis=1)\n",
    "    \n",
    "    weighted_df = weighted_df.sort_values('weighted_mean', ascending=False)\n",
    "    \n",
    "    if not single_dimension:\n",
    "        return weighted_df.join(temp_df)\n",
    "    \n",
    "    # Adding country names as index\n",
    "    \n",
    "    world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "    listylist = list(weighted_df.columns)\n",
    "    listylist.append('name')\n",
    "    listylist.append('iso_a3')\n",
    "    final_df = weighted_df.merge(world, left_index=True, right_on='iso_a3')[listylist].set_index('name')\n",
    "    \n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d107159",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Single Dimension Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15839794",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def dimension_data_loader(dimension_dict, dimension, manual_data):\n",
    "    \n",
    "    full_df = None\n",
    "    \n",
    "    for ind_num, ind_value in dimension_dict.items():\n",
    "        \n",
    "        if ind_value[0] == 'WB':\n",
    "            \n",
    "            if len(ind_value) == 3:\n",
    "            \n",
    "                ind_x = indicator_returner(ind_value[1], f\"{dimension}\", f\"{ind_num}\")\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                ind_x = indicator_returner(ind_value[1], f\"{dimension}\", f\"{ind_num}\", specify= ind_value[-1])\n",
    "                \n",
    "            \n",
    "        if ind_value[0] == 'V-DEM':\n",
    "            \n",
    "            rel_df = manual_data[ind_value[0]]\n",
    "            \n",
    "            ind_x = rel_df[rel_df['year'] == 2022][['country_text_id', 'v2regsupgroupssize']].set_index('country_text_id')\n",
    "            ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "            \n",
    "            \n",
    "        if ind_value[0] == 'OWiD':\n",
    "            \n",
    "            rel_df = manual_data[ind_value[0]]\n",
    "            \n",
    "            if ind_value[1] ==  'Public Administration Index':\n",
    "               \n",
    "                ind_x = rel_df[ind_value[1]]\n",
    "                ind_x = ind_x[ind_x['Year'] == 2022].set_index('Code')[['public_admin_vdem_owid']]\n",
    "                ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "               \n",
    "            if ind_value[1] ==  'Freedom of Expression Index':\n",
    "                ind_x = rel_df[ind_value[1]]\n",
    "                ind_x = ind_x[ind_x['Year'] == 2022].set_index('Code')[['freeexpr_vdem_owid']]\n",
    "                ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "                \n",
    "            if ind_value[1] ==  'State Control over Territory':\n",
    "                ind_x = rel_df[ind_value[1]]\n",
    "                ind_x = ind_x[ind_x['Year'] == 2022].set_index('Code')[['terr_contr_vdem_owid']]\n",
    "                ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "                \n",
    "                \n",
    "        if ind_value[0] == 'ACLED':\n",
    "            \n",
    "            rel_df = manual_data[ind_value[0]]\n",
    "            rel_df_2 = manual_data['iso_list']\n",
    "            \n",
    "            if ind_value[1] ==  'Protest Count':\n",
    "                \n",
    "                grouped_df = rel_df[rel_df['event_type'] == 'Protests'][['country', 'year', 'iso']].groupby(by = 'iso')\\\n",
    "                    .agg({'year': 'count'})\n",
    "                ind_x = grouped_df.merge(rel_df_2, left_index=True, right_on= 'country-code').set_index('alpha-3')[['year']]\n",
    "                ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "                \n",
    "                \n",
    "#                 aclest = manual_data['ACLED'][manual_data['ACLED']['event_type'] == 'Protests'][['country', 'year', 'iso']].groupby(by = 'iso')\\\n",
    "#                     .agg({'year': 'count'})\n",
    "#                 # aclest.merge(iso_list, how = 'left', left_index=True, right_on='country-code')\n",
    "#                 ind_x = aclest.merge(iso_list, how = 'left', left_index=True, right_on='country-code').set_index('alpha-3')[['year']]\n",
    "#                 ind_x\n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "            if ind_value[1] ==  'Battle Related Fatalities':\n",
    "                \n",
    "                grouped_df = rel_df[rel_df['event_type'].isin(['Explosions/Remote violence', 'Battles'])]\\\n",
    "                    [['country', 'fatalities', 'iso']].groupby(by = 'iso').agg({'fatalities': 'sum'})\n",
    "                ind_x = grouped_df.merge(rel_df_2, left_index=True, right_on= 'country-code', how = 'right').set_index('alpha-3')[['fatalities']]\n",
    "                ind_x['fatalities'] = ind_x['fatalities'].fillna(0)\n",
    "                ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "                \n",
    "            if ind_value[1] ==  'Violence in Neighbouring States':\n",
    "                \n",
    "                ## FIX ISO NOT NAME HERE\n",
    "                \n",
    "                grouped_df = rel_df.groupby(by = 'country').sum()[['fatalities']]\n",
    "                geo_df = manual_data['geodata']\n",
    "                merged_geo = geo_df.merge(grouped_df, left_on='country_border_name', right_index=True, how = 'left')\n",
    "                merged_grouped = merged_geo.groupby('country_name').sum()\n",
    "                ind_x = merged_grouped.merge(rel_df_2, left_index=True, right_on= 'name', how = 'right').set_index('alpha-3')[['fatalities']]\n",
    "                ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "                \n",
    "\n",
    "        if ind_value[0] == 'ND':\n",
    "            \n",
    "            rel_df = manual_data[ind_value[0]]\n",
    "            ind_x = rel_df.set_index('ISO3')[['2021']]\n",
    "            ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "            \n",
    "            \n",
    "        if ind_value[0] == 'UNHCR':\n",
    "            \n",
    "            rel_df = manual_data[ind_value[0]]\n",
    "            ind_x = rel_df.set_index(\"Country of asylum (ISO)\")[[\"Refugees under UNHCR's mandate\"]]\n",
    "            ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "            \n",
    "        \n",
    "        print(f'''Successfully loaded Indicator {dimension}{ind_num} from {ind_value[0]} Database\\n''')\n",
    "        \n",
    "        ### Merging DF ###\n",
    "               \n",
    "        if not isinstance(full_df, pd.DataFrame):\n",
    "            \n",
    "            full_df = ind_x\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            full_df = full_df.merge(ind_x, left_index = True, right_index = True, how = 'left')\n",
    "        \n",
    "    return full_df\n",
    "\n",
    "\n",
    "\n",
    "def dim_X_complete(indicator_dictionary, dimension, manual_data):\n",
    "    \n",
    "    dimension_dict = indicator_dictionary[dimension]\n",
    "    dimension_dict = {k: v for k, v in dimension_dict.items() if v}\n",
    "    \n",
    "    print(f\"\"\"\\n\\n\n",
    "    --------------------------Dimension {dimension}------------------------------\\n\n",
    "    \"\"\")\n",
    "    \n",
    "    ### Loading Data ###\n",
    "    \n",
    "    print(color.BOLD + \"Loading Data.....\\n\" + color.END)\n",
    "    \n",
    "    full_df = dimension_data_loader(dimension_dict, dimension, manual_data)\n",
    "    \n",
    "    ### Scaling and Weighting ###\n",
    "    \n",
    "    print (color.BOLD + \"Scaling & Weighting Data....\" + color.END)\n",
    "    \n",
    "    weight_list = []\n",
    "    for values in dimension_dict.values():\n",
    "        weight_list.append(values[2])\n",
    "        \n",
    "    full_df = scale_and_weight(full_df, weight_list)\n",
    "    \n",
    "    print(f\"\"\"\\n**Successfully loaded , merged, scaled, and weighted Dimension {dimension} Data**\\n\"\"\")\n",
    "    print(color.BOLD  + \"\"\"Overall Data Coverage:\"\"\" + color.END + \"(Weighted Mean missing if more than 2 indicators are missing for that Dimension..)\")\n",
    "    print(1- full_df.isna().sum()/len(full_df))\n",
    "\n",
    "    print(\"\"\"\\n\\n\n",
    "    ---------------------------------------------------------------------------\\n\\n\n",
    "    \n",
    "    \"\"\")\n",
    "            \n",
    "            \n",
    "    return full_df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13d1ab6",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## All Dimensions Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e82d4da5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def all_dimension_pipeline(indicator_dictionary, dimension_weights,manual_data):\n",
    "\n",
    "    all_dim_df = None\n",
    "\n",
    "    for key in indicator_dictionary.keys():\n",
    "\n",
    "        dimension_df = dim_X_complete(indicator_dictionary, key, manual_data)[['weighted_mean', 'iso_a3']]\n",
    "\n",
    "        dimension_df.columns = [f'Dimension_{key}', 'iso']\n",
    "\n",
    "        if not isinstance(all_dim_df, pd.DataFrame):\n",
    "\n",
    "            all_dim_df = dimension_df\n",
    "\n",
    "        else:\n",
    "\n",
    "            all_dim_df = all_dim_df.merge(dimension_df, left_on = 'iso', right_on = 'iso', how = 'left')\n",
    "        \n",
    "    overall_scoring_df = scale_and_weight(all_dim_df, dimension_weights.values(), single_dimension=False)\n",
    "            \n",
    "    submit_df = overall_scoring_df.merge(manual_data['iso_list'],how='left', left_on='iso', right_on='alpha-3')\\\n",
    "        .set_index('name').drop(columns='alpha-3')\n",
    "    \n",
    "    return submit_df\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7646df12",
   "metadata": {},
   "source": [
    "## Compare to OECD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b938beff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "    --------------------------Dimension G------------------------------\n",
      "\n",
      "    \n",
      "\u001b[1mLoading Data.....\n",
      "\u001b[0m\n",
      "Successfully loaded Indicator G1 from V-DEM Database\n",
      "\n",
      "Successfully loaded Indicator G2 from OWiD Database\n",
      "\n",
      "Data for 'Control of Corruption: Estimate' found in WB Database 3. Returning data for the most recent year. \n",
      "        Coverage = 99.53%, greater than selected threshold of 85.0%.\n",
      "\n",
      "Successfully loaded Indicator G3 from WB Database\n",
      "\n",
      "Data for 'Rule of Law: Estimate' found in WB Database 3. Returning data for the most recent year. \n",
      "        Coverage = 99.53%, greater than selected threshold of 85.0%.\n",
      "\n",
      "Successfully loaded Indicator G4 from WB Database\n",
      "\n",
      "Data for 'Tax Revenue' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Data coverage at 67.67% after going back 10 years.\n",
      "            Failed to exceed minimum threshold of 85.0%. Returning best dataframe anyway.\n",
      "\n",
      "Successfully loaded Indicator G5 from WB Database\n",
      "\n",
      "Data for 'Proportion of Seats Held by Women' found in WB Database 2. Returning data for the most recent year. \n",
      "        Coverage = 88.35%, greater than selected threshold of 85.0%.\n",
      "\n",
      "Successfully loaded Indicator G6 from WB Database\n",
      "\n",
      "Successfully loaded Indicator G7 from OWiD Database\n",
      "\n",
      "\u001b[1mScaling & Weighting Data....\u001b[0m\n",
      "\n",
      "**Successfully loaded , merged, scaled, and weighted Dimension G Data**\n",
      "\n",
      "\u001b[1mOverall Data Coverage:\u001b[0m(Weighted Mean missing if more than 2 indicators are missing for that Dimension..)\n",
      "ind_G1           0.981707\n",
      "ind_G2           0.993902\n",
      "ind_G3           1.000000\n",
      "ind_G4           1.000000\n",
      "ind_G5           0.774390\n",
      "ind_G6           0.951220\n",
      "ind_G7           0.993902\n",
      "weighted_mean    0.993902\n",
      "iso_a3           1.000000\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "    ---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "    \n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "    --------------------------Dimension S------------------------------\n",
      "\n",
      "    \n",
      "\u001b[1mLoading Data.....\n",
      "\u001b[0m\n",
      "Data for 'Gini Index' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Data coverage at 53.76% after going back 10 years.\n",
      "            Failed to exceed minimum threshold of 85.0%. Returning best dataframe anyway.\n",
      "\n",
      "Successfully loaded Indicator S1 from WB Database\n",
      "\n",
      "Data for 'Inflation, Consumer Prices' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Achieved 85.34% data coverage by going back to data from 2018,\n",
      "                exceeding minimum threshold of 85.0%. Returning this dataframe.\n",
      "\n",
      "Successfully loaded Indicator S2 from WB Database\n",
      "\n",
      "Data for 'Unemployment, Total' found in WB Database 2. Returning data for the most recent year. \n",
      "        Coverage = 87.97%, greater than selected threshold of 85.0%.\n",
      "\n",
      "Successfully loaded Indicator S3 from WB Database\n",
      "\n",
      "Data for 'Women Business and the Law Index' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Data coverage at 75.56% after going back 10 years.\n",
      "            Failed to exceed minimum threshold of 85.0%. Returning best dataframe anyway.\n",
      "\n",
      "Successfully loaded Indicator S4 from WB Database\n",
      "\n",
      "Successfully loaded Indicator S5 from ACLED Database\n",
      "\n",
      "Data for 'Age Dependency Ratio' found in WB Database 2. Returning data for the most recent year. \n",
      "        Coverage = 99.62%, greater than selected threshold of 85.0%.\n",
      "\n",
      "Successfully loaded Indicator S6 from WB Database\n",
      "\n",
      "Data for 'Ease of Doing Business Score' found in WB Database 2. Returning data for the most recent year. \n",
      "        Coverage = 89.47%, greater than selected threshold of 85.0%.\n",
      "\n",
      "Successfully loaded Indicator S7 from WB Database\n",
      "\n",
      "\u001b[1mScaling & Weighting Data....\u001b[0m\n",
      "\n",
      "**Successfully loaded , merged, scaled, and weighted Dimension S Data**\n",
      "\n",
      "\u001b[1mOverall Data Coverage:\u001b[0m(Weighted Mean missing if more than 2 indicators are missing for that Dimension..)\n",
      "ind_S1           0.763314\n",
      "ind_S2           0.911243\n",
      "ind_S3           0.988166\n",
      "ind_S4           0.970414\n",
      "ind_S5           0.970414\n",
      "ind_S6           1.000000\n",
      "ind_S7           0.970414\n",
      "weighted_mean    0.964497\n",
      "iso_a3           1.000000\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "    ---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "    \n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "    --------------------------Dimension I------------------------------\n",
      "\n",
      "    \n",
      "\u001b[1mLoading Data.....\n",
      "\u001b[0m\n",
      "Data for 'GDP per Capita' found in WB Database 2. Returning data for the most recent year. \n",
      "        Coverage = 91.35%, greater than selected threshold of 85.0%.\n",
      "\n",
      "Successfully loaded Indicator I1 from WB Database\n",
      "\n",
      "Data for 'Poverty Gap at $2.15 a Day' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Data coverage at 59.019999999999996% after going back 10 years.\n",
      "            Failed to exceed minimum threshold of 85.0%. Returning best dataframe anyway.\n",
      "\n",
      "Successfully loaded Indicator I2 from WB Database\n",
      "\n",
      "Data for 'Human Capital Index' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Data coverage at 65.41% after going back 10 years.\n",
      "            Failed to exceed minimum threshold of 85.0%. Returning best dataframe anyway.\n",
      "\n",
      "Successfully loaded Indicator I3 from WB Database\n",
      "\n",
      "Data for 'Women who Believe a Husband is Justified in Beating his Wife' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Data coverage at 22.56% after going back 10 years.\n",
      "            Failed to exceed minimum threshold of 85.0%. Returning best dataframe anyway.\n",
      "\n",
      "Successfully loaded Indicator I4 from WB Database\n",
      "\n",
      "Data for 'Current Health Expenditure per Capita, PPP' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Achieved 87.59% data coverage by going back to data from 2020,\n",
      "                exceeding minimum threshold of 85.0%. Returning this dataframe.\n",
      "\n",
      "Successfully loaded Indicator I5 from WB Database\n",
      "\n",
      "\u001b[1mScaling & Weighting Data....\u001b[0m\n",
      "\n",
      "**Successfully loaded , merged, scaled, and weighted Dimension I Data**\n",
      "\n",
      "\u001b[1mOverall Data Coverage:\u001b[0m(Weighted Mean missing if more than 2 indicators are missing for that Dimension..)\n",
      "ind_I1           0.940828\n",
      "ind_I2           0.763314\n",
      "ind_I3           0.893491\n",
      "ind_I4           0.343195\n",
      "ind_I5           0.934911\n",
      "weighted_mean    0.899408\n",
      "iso_a3           1.000000\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "    ---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "    \n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "    --------------------------Dimension C------------------------------\n",
      "\n",
      "    \n",
      "\u001b[1mLoading Data.....\n",
      "\u001b[0m\n",
      "Successfully loaded Indicator C1 from ACLED Database\n",
      "\n",
      "Successfully loaded Indicator C3 from OWiD Database\n",
      "\n",
      "Data for 'Intentional homicides' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Data coverage at 84.21% after going back 10 years.\n",
      "            Failed to exceed minimum threshold of 85.0%. Returning best dataframe anyway.\n",
      "\n",
      "Successfully loaded Indicator C4 from WB Database\n",
      "\n",
      "\u001b[1mScaling & Weighting Data....\u001b[0m\n",
      "\n",
      "**Successfully loaded , merged, scaled, and weighted Dimension C Data**\n",
      "\n",
      "\u001b[1mOverall Data Coverage:\u001b[0m(Weighted Mean missing if more than 2 indicators are missing for that Dimension..)\n",
      "ind_C1           1.000000\n",
      "ind_C3           0.936782\n",
      "ind_C4           0.816092\n",
      "weighted_mean    1.000000\n",
      "iso_a3           1.000000\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "    ---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "    \n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "    --------------------------Dimension E------------------------------\n",
      "\n",
      "    \n",
      "\u001b[1mLoading Data.....\n",
      "\u001b[0m\n",
      "Successfully loaded Indicator E1 from ND Database\n",
      "\n",
      "\u001b[1mScaling & Weighting Data....\u001b[0m\n",
      "\n",
      "**Successfully loaded , merged, scaled, and weighted Dimension E Data**\n",
      "\n",
      "\u001b[1mOverall Data Coverage:\u001b[0m(Weighted Mean missing if more than 2 indicators are missing for that Dimension..)\n",
      "ind_E1           1.0\n",
      "weighted_mean    1.0\n",
      "iso_a3           1.0\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "    ---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "    \n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "    --------------------------Dimension R------------------------------\n",
      "\n",
      "    \n",
      "\u001b[1mLoading Data.....\n",
      "\u001b[0m\n",
      "Successfully loaded Indicator R1 from ACLED Database\n",
      "\n",
      "Successfully loaded Indicator R2 from UNHCR Database\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 'Total Natural Resources Rents' found in WB Database 2. Returning data for the most recent year. \n",
      "        Coverage = 92.11%, greater than selected threshold of 85.0%.\n",
      "\n",
      "Successfully loaded Indicator R3 from WB Database\n",
      "\n",
      "\u001b[1mScaling & Weighting Data....\u001b[0m\n",
      "\n",
      "**Successfully loaded , merged, scaled, and weighted Dimension R Data**\n",
      "\n",
      "\u001b[1mOverall Data Coverage:\u001b[0m(Weighted Mean missing if more than 2 indicators are missing for that Dimension..)\n",
      "ind_R1           0.954023\n",
      "ind_R2           0.879310\n",
      "ind_R3           0.913793\n",
      "weighted_mean    0.994253\n",
      "iso_a3           1.000000\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "    ---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "    \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "all_df = all_dimension_pipeline(indicator_dictionary=indicator_dictionary, dimension_weights=dimension_weights, manual_data=manual_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20bbee7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "oecd_df = pd.read_excel('../data/state_o_f/List of fragile contexts (2022) (1).xlsx')\n",
    "\n",
    "oecd_df = oecd_df.reset_index().rename(columns={'index':'OECD Rank'}).set_index('iso3c')\n",
    "\n",
    "oecd_df['OECD Rank'] = oecd_df['OECD Rank']+1\n",
    "\n",
    "score_df = all_df.set_index('iso')[['weighted_mean']]\n",
    "\n",
    "score_df['BMZ Rank'] = score_df['weighted_mean'].rank()\n",
    "\n",
    "score_df['BMZ Rank'] = score_df['BMZ Rank'].astype(int)\n",
    "\n",
    "compare_df = oecd_df.merge(score_df, left_index=True, right_index=True, how = 'left')[['context', 'OECD Rank', 'BMZ Rank']]\n",
    "\n",
    "compare_df = compare_df.fillna(999)\n",
    "\n",
    "compare_df['BMZ Rank'] = compare_df['BMZ Rank'].astype(int)\n",
    "\n",
    "compare_df = compare_df.rename(columns={'context': \"Country Name\"}).set_index('Country Name')\n",
    "\n",
    "compare_df['Comparison'] = compare_df['BMZ Rank'] - compare_df['OECD Rank']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61ac108",
   "metadata": {},
   "source": [
    "## All Dimensions Seperately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05959c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def all_the_data(indicator_dictionary, manual_data):\n",
    "    \n",
    "    all_data_dic = {}\n",
    "\n",
    "    for key in indicator_dictionary.keys():\n",
    "        all_data_dic[key] = dim_X_complete(indicator_dictionary, key, manual_data)\n",
    "        \n",
    "    return all_data_dic\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecff3fa6",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# To CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee54276",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Overall Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6268547b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ac347e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_df.to_csv(\"../upload_data/full_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c245f76",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Each Dim Seperately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6abede98",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "    --------------------------Dimension G------------------------------\n",
      "\n",
      "    \n",
      "\u001b[1mLoading Data.....\n",
      "\u001b[0m\n",
      "Successfully loaded Indicator G1 from V-DEM Database\n",
      "\n",
      "Successfully loaded Indicator G2 from OWiD Database\n",
      "\n",
      "Data for 'Control of Corruption: Estimate' found in WB Database 3. Returning data for the most recent year. \n",
      "        Coverage = 99.53%, greater than selected threshold of 85.0%.\n",
      "\n",
      "Successfully loaded Indicator G3 from WB Database\n",
      "\n",
      "Data for 'Rule of Law: Estimate' found in WB Database 3. Returning data for the most recent year. \n",
      "        Coverage = 99.53%, greater than selected threshold of 85.0%.\n",
      "\n",
      "Successfully loaded Indicator G4 from WB Database\n",
      "\n",
      "Data for 'Tax Revenue' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Data coverage at 67.67% after going back 10 years.\n",
      "            Failed to exceed minimum threshold of 85.0%. Returning best dataframe anyway.\n",
      "\n",
      "Successfully loaded Indicator G5 from WB Database\n",
      "\n",
      "Data for 'Proportion of Seats Held by Women' found in WB Database 2. Returning data for the most recent year. \n",
      "        Coverage = 88.35%, greater than selected threshold of 85.0%.\n",
      "\n",
      "Successfully loaded Indicator G6 from WB Database\n",
      "\n",
      "Successfully loaded Indicator G7 from OWiD Database\n",
      "\n",
      "\u001b[1mScaling & Weighting Data....\u001b[0m\n",
      "\n",
      "**Successfully loaded , merged, scaled, and weighted Dimension G Data**\n",
      "\n",
      "\u001b[1mOverall Data Coverage:\u001b[0m(Weighted Mean missing if more than 2 indicators are missing for that Dimension..)\n",
      "ind_G1           0.981707\n",
      "ind_G2           0.993902\n",
      "ind_G3           1.000000\n",
      "ind_G4           1.000000\n",
      "ind_G5           0.774390\n",
      "ind_G6           0.951220\n",
      "ind_G7           0.993902\n",
      "weighted_mean    0.993902\n",
      "iso_a3           1.000000\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "    ---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "    \n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "    --------------------------Dimension S------------------------------\n",
      "\n",
      "    \n",
      "\u001b[1mLoading Data.....\n",
      "\u001b[0m\n",
      "Data for 'Gini Index' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Data coverage at 53.76% after going back 10 years.\n",
      "            Failed to exceed minimum threshold of 85.0%. Returning best dataframe anyway.\n",
      "\n",
      "Successfully loaded Indicator S1 from WB Database\n",
      "\n",
      "Data for 'Inflation, Consumer Prices' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Achieved 85.34% data coverage by going back to data from 2018,\n",
      "                exceeding minimum threshold of 85.0%. Returning this dataframe.\n",
      "\n",
      "Successfully loaded Indicator S2 from WB Database\n",
      "\n",
      "Data for 'Unemployment, Total' found in WB Database 2. Returning data for the most recent year. \n",
      "        Coverage = 87.97%, greater than selected threshold of 85.0%.\n",
      "\n",
      "Successfully loaded Indicator S3 from WB Database\n",
      "\n",
      "Data for 'Women Business and the Law Index' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Data coverage at 75.56% after going back 10 years.\n",
      "            Failed to exceed minimum threshold of 85.0%. Returning best dataframe anyway.\n",
      "\n",
      "Successfully loaded Indicator S4 from WB Database\n",
      "\n",
      "Successfully loaded Indicator S5 from ACLED Database\n",
      "\n",
      "Data for 'Age Dependency Ratio' found in WB Database 2. Returning data for the most recent year. \n",
      "        Coverage = 99.62%, greater than selected threshold of 85.0%.\n",
      "\n",
      "Successfully loaded Indicator S6 from WB Database\n",
      "\n",
      "Data for 'Ease of Doing Business Score' found in WB Database 2. Returning data for the most recent year. \n",
      "        Coverage = 89.47%, greater than selected threshold of 85.0%.\n",
      "\n",
      "Successfully loaded Indicator S7 from WB Database\n",
      "\n",
      "\u001b[1mScaling & Weighting Data....\u001b[0m\n",
      "\n",
      "**Successfully loaded , merged, scaled, and weighted Dimension S Data**\n",
      "\n",
      "\u001b[1mOverall Data Coverage:\u001b[0m(Weighted Mean missing if more than 2 indicators are missing for that Dimension..)\n",
      "ind_S1           0.763314\n",
      "ind_S2           0.911243\n",
      "ind_S3           0.988166\n",
      "ind_S4           0.970414\n",
      "ind_S5           0.970414\n",
      "ind_S6           1.000000\n",
      "ind_S7           0.970414\n",
      "weighted_mean    0.964497\n",
      "iso_a3           1.000000\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "    ---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "    \n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "    --------------------------Dimension I------------------------------\n",
      "\n",
      "    \n",
      "\u001b[1mLoading Data.....\n",
      "\u001b[0m\n",
      "Data for 'GDP per Capita' found in WB Database 2. Returning data for the most recent year. \n",
      "        Coverage = 91.35%, greater than selected threshold of 85.0%.\n",
      "\n",
      "Successfully loaded Indicator I1 from WB Database\n",
      "\n",
      "Data for 'Poverty Gap at $2.15 a Day' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Data coverage at 59.019999999999996% after going back 10 years.\n",
      "            Failed to exceed minimum threshold of 85.0%. Returning best dataframe anyway.\n",
      "\n",
      "Successfully loaded Indicator I2 from WB Database\n",
      "\n",
      "Data for 'Human Capital Index' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Data coverage at 65.41% after going back 10 years.\n",
      "            Failed to exceed minimum threshold of 85.0%. Returning best dataframe anyway.\n",
      "\n",
      "Successfully loaded Indicator I3 from WB Database\n",
      "\n",
      "Data for 'Women who Believe a Husband is Justified in Beating his Wife' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Data coverage at 22.56% after going back 10 years.\n",
      "            Failed to exceed minimum threshold of 85.0%. Returning best dataframe anyway.\n",
      "\n",
      "Successfully loaded Indicator I4 from WB Database\n",
      "\n",
      "Data for 'Current Health Expenditure per Capita, PPP' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Achieved 87.59% data coverage by going back to data from 2020,\n",
      "                exceeding minimum threshold of 85.0%. Returning this dataframe.\n",
      "\n",
      "Successfully loaded Indicator I5 from WB Database\n",
      "\n",
      "\u001b[1mScaling & Weighting Data....\u001b[0m\n",
      "\n",
      "**Successfully loaded , merged, scaled, and weighted Dimension I Data**\n",
      "\n",
      "\u001b[1mOverall Data Coverage:\u001b[0m(Weighted Mean missing if more than 2 indicators are missing for that Dimension..)\n",
      "ind_I1           0.940828\n",
      "ind_I2           0.763314\n",
      "ind_I3           0.893491\n",
      "ind_I4           0.343195\n",
      "ind_I5           0.934911\n",
      "weighted_mean    0.899408\n",
      "iso_a3           1.000000\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "    ---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "    \n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "    --------------------------Dimension C------------------------------\n",
      "\n",
      "    \n",
      "\u001b[1mLoading Data.....\n",
      "\u001b[0m\n",
      "Successfully loaded Indicator C1 from ACLED Database\n",
      "\n",
      "Successfully loaded Indicator C3 from OWiD Database\n",
      "\n",
      "Data for 'Intentional homicides' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Data coverage at 84.21% after going back 10 years.\n",
      "            Failed to exceed minimum threshold of 85.0%. Returning best dataframe anyway.\n",
      "\n",
      "Successfully loaded Indicator C4 from WB Database\n",
      "\n",
      "\u001b[1mScaling & Weighting Data....\u001b[0m\n",
      "\n",
      "**Successfully loaded , merged, scaled, and weighted Dimension C Data**\n",
      "\n",
      "\u001b[1mOverall Data Coverage:\u001b[0m(Weighted Mean missing if more than 2 indicators are missing for that Dimension..)\n",
      "ind_C1           1.000000\n",
      "ind_C3           0.936782\n",
      "ind_C4           0.816092\n",
      "weighted_mean    1.000000\n",
      "iso_a3           1.000000\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "    ---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "    \n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "    --------------------------Dimension E------------------------------\n",
      "\n",
      "    \n",
      "\u001b[1mLoading Data.....\n",
      "\u001b[0m\n",
      "Successfully loaded Indicator E1 from ND Database\n",
      "\n",
      "\u001b[1mScaling & Weighting Data....\u001b[0m\n",
      "\n",
      "**Successfully loaded , merged, scaled, and weighted Dimension E Data**\n",
      "\n",
      "\u001b[1mOverall Data Coverage:\u001b[0m(Weighted Mean missing if more than 2 indicators are missing for that Dimension..)\n",
      "ind_E1           1.0\n",
      "weighted_mean    1.0\n",
      "iso_a3           1.0\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "    ---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "    \n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "    --------------------------Dimension R------------------------------\n",
      "\n",
      "    \n",
      "\u001b[1mLoading Data.....\n",
      "\u001b[0m\n",
      "Successfully loaded Indicator R1 from ACLED Database\n",
      "\n",
      "Successfully loaded Indicator R2 from UNHCR Database\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 'Total Natural Resources Rents' found in WB Database 2. Returning data for the most recent year. \n",
      "        Coverage = 92.11%, greater than selected threshold of 85.0%.\n",
      "\n",
      "Successfully loaded Indicator R3 from WB Database\n",
      "\n",
      "\u001b[1mScaling & Weighting Data....\u001b[0m\n",
      "\n",
      "**Successfully loaded , merged, scaled, and weighted Dimension R Data**\n",
      "\n",
      "\u001b[1mOverall Data Coverage:\u001b[0m(Weighted Mean missing if more than 2 indicators are missing for that Dimension..)\n",
      "ind_R1           0.954023\n",
      "ind_R2           0.879310\n",
      "ind_R3           0.913793\n",
      "weighted_mean    0.994253\n",
      "iso_a3           1.000000\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "    ---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "    \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "all_the_data_dictionary = all_the_data(indicator_dictionary, manual_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf1944f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for key in all_the_data_dictionary.keys():\n",
    "    \n",
    "    df = all_the_data_dictionary[key]\n",
    "    \n",
    "    df.to_csv(f\"../upload_data/dim_{key}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3b8732",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## OECD Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bffc6c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "compare_df.to_csv(\"../upload_data/compare_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4549e075",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbf5c83",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b799c8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dd75e9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594f4f2c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db34de7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99757db9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9debf9c4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b209fc0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa75791",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1a9e86",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d0a457",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_the_data_dictionary = all_the_data(indicator_dictionary, manual_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35029692",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# PCA Methodology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d33963",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_the_data_dictionary['G']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032738c4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ed7b00",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376e983e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = all_the_data_dictionary['G'].drop(columns=['weighted_mean', 'iso_a3', 'ind_G5']).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dbe9e0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cfb51e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_dim_x = pd.read_csv(\"../upload_data/full_df.csv\").drop(columns=['weighted_mean', 'iso', 'country-code']).dropna().set_index('name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b030147",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.read_csv(\"../upload_data/dim_G.csv\").drop(columns=['weighted_mean', 'iso_a3', 'ind_G5']).dropna().set_index('name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc659ba",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b2a863",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "\n",
    "principalComponents = pca.fit_transform(x.values)\n",
    "\n",
    "\n",
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['principal component 1', 'principal component 2'], index = x.index).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3504fc1c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(principalDf,\n",
    "                 x='principal component 1',\n",
    "                 y='principal component 2',\n",
    "                 hover_name='name',  \n",
    "                 title='Scatter plot of Principal Components')\n",
    "\n",
    "fig.update_traces(marker=dict(size=10),\n",
    "                  selector=dict(mode='markers'))  # Optional: Adjust the marker size\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273d7d82",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## CLustering??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda44525",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import Birch, KMeans\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "\n",
    "def pca_and_clustering(df_of_indicators, model_choice = \"Birch\", num_of_clusters = 5, random_state = False):\n",
    "    \n",
    "    pca = PCA(n_components=2)\n",
    "\n",
    "    principalComponents = pca.fit_transform(df_of_indicators.values)\n",
    "    \n",
    "    principalDf = pd.DataFrame(data = principalComponents,\\\n",
    "                               columns = ['principal component 1', 'principal component 2'],\\\n",
    "                               index = df_of_indicators.index).reset_index()\n",
    "    \n",
    "    X = principalDf.drop(columns=['name']).values\n",
    "    \n",
    "    if model_choice == \"Birch\":\n",
    "        if random_state:\n",
    "            model = Birch(n_clusters=num_of_clusters, random_state = 25)\n",
    "        else:\n",
    "            model = Birch(n_clusters=num_of_clusters)\n",
    "    if model_choice == \"KMeans\":\n",
    "        if random_state:\n",
    "            model = KMeans(n_clusters=num_of_clusters, random_state=25)\n",
    "        else:\n",
    "            model = KMeans(n_clusters=num_of_clusters)\n",
    "    if model_choice == \"GaussianMixture\":\n",
    "        if random_state:\n",
    "            model = GaussianMixture(n_components=num_of_clusters, random_state=25)\n",
    "        else:\n",
    "            model = GaussianMixture(n_components=num_of_clusters)\n",
    "    model.fit(X)\n",
    "    yhat = model.predict(X)  \n",
    "    principalDf = pd.concat([pd.DataFrame(yhat, columns=['Cluster']), principalDf], axis=1)\n",
    "    principalDf['Cluster'] = principalDf['Cluster'].astype(str)\n",
    "    fig = px.scatter(principalDf,\n",
    "                 x='principal component 1',\n",
    "                 y='principal component 2',\n",
    "                 hover_name='name',\n",
    "                 color = 'Cluster',\n",
    "                 title='Scatter plot of Principal Components')\n",
    "\n",
    "    fig.update_traces(marker=dict(size=10), selector=dict(mode='markers'))  \n",
    "\n",
    "    fig.show()\n",
    "pca_and_clustering(all_dim_x, model_choice= \"GaussianMixture\",num_of_clusters=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06016af3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "\n",
    "principalComponents = pca.fit_transform(x.values)\n",
    "\n",
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['principal component 1', 'principal component 2'], index = x.index).reset_index()\n",
    "\n",
    "principalDf\n",
    "\n",
    "X = principalDf.drop(columns=['name']).values\n",
    "\n",
    "model = Birch(n_clusters=6)\n",
    "\n",
    "model.fit(X)\n",
    "\n",
    "yhat = model.predict(X)\n",
    "\n",
    "\n",
    "principalDf = pd.concat([pd.DataFrame(yhat, columns=['Cluster']), principalDf], axis=1)\n",
    "principalDf['Cluster'] = principalDf['Cluster'].astype(str)\n",
    "\n",
    "\n",
    "\n",
    "fig = px.scatter(principalDf,\n",
    "                 x='principal component 1',\n",
    "                 y='principal component 2',\n",
    "                 hover_name='name',\n",
    "                 color = 'Cluster',\n",
    "                 title='Scatter plot of Principal Components')\n",
    "\n",
    "fig.update_traces(marker=dict(size=10),\n",
    "                  selector=dict(mode='markers'))  \n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6505355c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4e8446",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc148697",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646ab9ec",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8af353f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d66058",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd26dd5e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c9737f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42439abc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec171e4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020fb6b5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa2ee14",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf4ff68c",
   "metadata": {},
   "source": [
    "# Visuallizing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "89e1eec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ind_G1</th>\n",
       "      <th>ind_G2</th>\n",
       "      <th>ind_G3</th>\n",
       "      <th>ind_G4</th>\n",
       "      <th>ind_G5</th>\n",
       "      <th>ind_G6</th>\n",
       "      <th>ind_G7</th>\n",
       "      <th>Weighted Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Denmark</th>\n",
       "      <td>1.234519</td>\n",
       "      <td>0.785184</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.972645</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.211435</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.814826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sweden</th>\n",
       "      <td>1.386573</td>\n",
       "      <td>0.897720</td>\n",
       "      <td>0.839809</td>\n",
       "      <td>0.873597</td>\n",
       "      <td>0.563604</td>\n",
       "      <td>0.257850</td>\n",
       "      <td>0.483556</td>\n",
       "      <td>0.757530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Zealand</th>\n",
       "      <td>1.225935</td>\n",
       "      <td>0.532047</td>\n",
       "      <td>0.887561</td>\n",
       "      <td>0.893256</td>\n",
       "      <td>0.710350</td>\n",
       "      <td>0.323186</td>\n",
       "      <td>0.460946</td>\n",
       "      <td>0.719040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Taiwan</th>\n",
       "      <td>1.400674</td>\n",
       "      <td>0.670220</td>\n",
       "      <td>0.410776</td>\n",
       "      <td>0.670174</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.391059</td>\n",
       "      <td>0.708581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Norway</th>\n",
       "      <td>1.003372</td>\n",
       "      <td>0.790582</td>\n",
       "      <td>0.842675</td>\n",
       "      <td>0.907566</td>\n",
       "      <td>0.440850</td>\n",
       "      <td>0.234211</td>\n",
       "      <td>0.486639</td>\n",
       "      <td>0.672271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Haiti</th>\n",
       "      <td>-1.152974</td>\n",
       "      <td>-0.698826</td>\n",
       "      <td>-0.813682</td>\n",
       "      <td>-0.571521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.196814</td>\n",
       "      <td>-0.608038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eritrea</th>\n",
       "      <td>-0.919375</td>\n",
       "      <td>-0.399541</td>\n",
       "      <td>-0.730584</td>\n",
       "      <td>-0.757154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.457862</td>\n",
       "      <td>-0.652903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Turkmenistan</th>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-0.596816</td>\n",
       "      <td>-0.803226</td>\n",
       "      <td>-0.625641</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.077762</td>\n",
       "      <td>-0.473279</td>\n",
       "      <td>-0.679454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Venezuela</th>\n",
       "      <td>-0.788167</td>\n",
       "      <td>-0.671030</td>\n",
       "      <td>-0.903901</td>\n",
       "      <td>-0.957769</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.234841</td>\n",
       "      <td>-0.711141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Palestine</th>\n",
       "      <td>-0.050582</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.458460</td>\n",
       "      <td>-0.183120</td>\n",
       "      <td>0.233810</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ind_G1    ind_G2    ind_G3    ind_G4    ind_G5    ind_G6  \\\n",
       "name                                                                       \n",
       "Denmark       1.234519  0.785184  1.000000  0.972645  1.000000  0.211435   \n",
       "Sweden        1.386573  0.897720  0.839809  0.873597  0.563604  0.257850   \n",
       "New Zealand   1.225935  0.532047  0.887561  0.893256  0.710350  0.323186   \n",
       "Taiwan        1.400674  0.670220  0.410776  0.670174       NaN       NaN   \n",
       "Norway        1.003372  0.790582  0.842675  0.907566  0.440850  0.234211   \n",
       "...                ...       ...       ...       ...       ...       ...   \n",
       "Haiti        -1.152974 -0.698826 -0.813682 -0.571521       NaN       NaN   \n",
       "Eritrea      -0.919375 -0.399541 -0.730584 -0.757154       NaN       NaN   \n",
       "Turkmenistan -1.500000 -0.596816 -0.803226 -0.625641       NaN -0.077762   \n",
       "Venezuela    -0.788167 -0.671030 -0.903901 -0.957769       NaN       NaN   \n",
       "Palestine    -0.050582       NaN -0.458460 -0.183120  0.233810       NaN   \n",
       "\n",
       "                ind_G7  Weighted Score  \n",
       "name                                    \n",
       "Denmark       0.500000        0.814826  \n",
       "Sweden        0.483556        0.757530  \n",
       "New Zealand   0.460946        0.719040  \n",
       "Taiwan        0.391059        0.708581  \n",
       "Norway        0.486639        0.672271  \n",
       "...                ...             ...  \n",
       "Haiti         0.196814       -0.608038  \n",
       "Eritrea      -0.457862       -0.652903  \n",
       "Turkmenistan -0.473279       -0.679454  \n",
       "Venezuela    -0.234841       -0.711141  \n",
       "Palestine          NaN             NaN  \n",
       "\n",
       "[164 rows x 8 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimension = 'G'\n",
    "\n",
    "dim_df = pd.read_csv(f'../upload_data/dim_{dimension}.csv').set_index('name').drop(columns=['iso_a3']).rename(columns = {'weighted_mean': 'Weighted Score'})\n",
    "\n",
    "dim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6700ea39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name', 'ind_G1', 'ind_G2', 'ind_G3', 'ind_G4', 'ind_G5', 'ind_G6',\n",
       "       'ind_G7', 'Weighted Score', 'iso_a3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5979ac58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_x</th>\n",
       "      <th>geometry</th>\n",
       "      <th>ind_G1</th>\n",
       "      <th>ind_G2</th>\n",
       "      <th>ind_G3</th>\n",
       "      <th>ind_G4</th>\n",
       "      <th>ind_G5</th>\n",
       "      <th>ind_G6</th>\n",
       "      <th>ind_G7</th>\n",
       "      <th>Weighted Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fiji</td>\n",
       "      <td>MULTIPOLYGON (((180.00000 -16.06713, 180.00000...</td>\n",
       "      <td>0.252912</td>\n",
       "      <td>0.095938</td>\n",
       "      <td>0.054045</td>\n",
       "      <td>0.228927</td>\n",
       "      <td>-0.087957</td>\n",
       "      <td>-0.179872</td>\n",
       "      <td>0.028263</td>\n",
       "      <td>0.056037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tanzania</td>\n",
       "      <td>POLYGON ((33.90371 -0.95000, 34.07262 -1.05982...</td>\n",
       "      <td>1.075720</td>\n",
       "      <td>0.517204</td>\n",
       "      <td>-0.288644</td>\n",
       "      <td>-0.131403</td>\n",
       "      <td>-0.328067</td>\n",
       "      <td>0.101725</td>\n",
       "      <td>0.248201</td>\n",
       "      <td>0.170677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Canada</td>\n",
       "      <td>MULTIPOLYGON (((-122.84000 49.00000, -122.9742...</td>\n",
       "      <td>0.748314</td>\n",
       "      <td>0.495615</td>\n",
       "      <td>0.650504</td>\n",
       "      <td>0.815250</td>\n",
       "      <td>-0.263090</td>\n",
       "      <td>-0.002476</td>\n",
       "      <td>0.460946</td>\n",
       "      <td>0.415009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>United States of America</td>\n",
       "      <td>MULTIPOLYGON (((-122.84000 49.00000, -120.0000...</td>\n",
       "      <td>0.294605</td>\n",
       "      <td>0.424099</td>\n",
       "      <td>0.390168</td>\n",
       "      <td>0.723603</td>\n",
       "      <td>-0.291956</td>\n",
       "      <td>-0.031368</td>\n",
       "      <td>0.444502</td>\n",
       "      <td>0.279093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kazakhstan</td>\n",
       "      <td>POLYGON ((87.35997 49.21498, 86.59878 48.54918...</td>\n",
       "      <td>-0.555794</td>\n",
       "      <td>-0.237080</td>\n",
       "      <td>-0.215473</td>\n",
       "      <td>-0.146118</td>\n",
       "      <td>-0.457223</td>\n",
       "      <td>-0.053331</td>\n",
       "      <td>-0.081706</td>\n",
       "      <td>-0.249532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>North Macedonia</td>\n",
       "      <td>POLYGON ((22.38053 42.32026, 22.88137 41.99930...</td>\n",
       "      <td>0.606070</td>\n",
       "      <td>-0.163945</td>\n",
       "      <td>-0.280346</td>\n",
       "      <td>0.032018</td>\n",
       "      <td>-0.000697</td>\n",
       "      <td>0.180272</td>\n",
       "      <td>0.241007</td>\n",
       "      <td>0.087768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>Serbia</td>\n",
       "      <td>POLYGON ((18.82982 45.90887, 18.82984 45.90888...</td>\n",
       "      <td>0.730533</td>\n",
       "      <td>0.264337</td>\n",
       "      <td>-0.342695</td>\n",
       "      <td>0.024004</td>\n",
       "      <td>0.184370</td>\n",
       "      <td>0.096810</td>\n",
       "      <td>-0.081706</td>\n",
       "      <td>0.125093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Montenegro</td>\n",
       "      <td>POLYGON ((20.07070 42.58863, 19.80161 42.50009...</td>\n",
       "      <td>0.411711</td>\n",
       "      <td>0.173121</td>\n",
       "      <td>-0.183989</td>\n",
       "      <td>0.018298</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.056563</td>\n",
       "      <td>0.257451</td>\n",
       "      <td>0.103338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>Trinidad and Tobago</td>\n",
       "      <td>POLYGON ((-61.68000 10.76000, -61.10500 10.890...</td>\n",
       "      <td>0.545371</td>\n",
       "      <td>0.239779</td>\n",
       "      <td>-0.306766</td>\n",
       "      <td>-0.001712</td>\n",
       "      <td>-0.049309</td>\n",
       "      <td>-0.072400</td>\n",
       "      <td>0.441418</td>\n",
       "      <td>0.113769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>S. Sudan</td>\n",
       "      <td>POLYGON ((30.83385 3.50917, 29.95350 4.17370, ...</td>\n",
       "      <td>-0.650828</td>\n",
       "      <td>-0.489947</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.890980</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.028386</td>\n",
       "      <td>-0.418808</td>\n",
       "      <td>-0.570363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name_x  \\\n",
       "0                        Fiji   \n",
       "1                    Tanzania   \n",
       "2                      Canada   \n",
       "3    United States of America   \n",
       "4                  Kazakhstan   \n",
       "..                        ...   \n",
       "159           North Macedonia   \n",
       "160                    Serbia   \n",
       "161                Montenegro   \n",
       "162       Trinidad and Tobago   \n",
       "163                  S. Sudan   \n",
       "\n",
       "                                              geometry    ind_G1    ind_G2  \\\n",
       "0    MULTIPOLYGON (((180.00000 -16.06713, 180.00000...  0.252912  0.095938   \n",
       "1    POLYGON ((33.90371 -0.95000, 34.07262 -1.05982...  1.075720  0.517204   \n",
       "2    MULTIPOLYGON (((-122.84000 49.00000, -122.9742...  0.748314  0.495615   \n",
       "3    MULTIPOLYGON (((-122.84000 49.00000, -120.0000...  0.294605  0.424099   \n",
       "4    POLYGON ((87.35997 49.21498, 86.59878 48.54918... -0.555794 -0.237080   \n",
       "..                                                 ...       ...       ...   \n",
       "159  POLYGON ((22.38053 42.32026, 22.88137 41.99930...  0.606070 -0.163945   \n",
       "160  POLYGON ((18.82982 45.90887, 18.82984 45.90888...  0.730533  0.264337   \n",
       "161  POLYGON ((20.07070 42.58863, 19.80161 42.50009...  0.411711  0.173121   \n",
       "162  POLYGON ((-61.68000 10.76000, -61.10500 10.890...  0.545371  0.239779   \n",
       "163  POLYGON ((30.83385 3.50917, 29.95350 4.17370, ... -0.650828 -0.489947   \n",
       "\n",
       "       ind_G3    ind_G4    ind_G5    ind_G6    ind_G7  Weighted Score  \n",
       "0    0.054045  0.228927 -0.087957 -0.179872  0.028263        0.056037  \n",
       "1   -0.288644 -0.131403 -0.328067  0.101725  0.248201        0.170677  \n",
       "2    0.650504  0.815250 -0.263090 -0.002476  0.460946        0.415009  \n",
       "3    0.390168  0.723603 -0.291956 -0.031368  0.444502        0.279093  \n",
       "4   -0.215473 -0.146118 -0.457223 -0.053331 -0.081706       -0.249532  \n",
       "..        ...       ...       ...       ...       ...             ...  \n",
       "159 -0.280346  0.032018 -0.000697  0.180272  0.241007        0.087768  \n",
       "160 -0.342695  0.024004  0.184370  0.096810 -0.081706        0.125093  \n",
       "161 -0.183989  0.018298       NaN -0.056563  0.257451        0.103338  \n",
       "162 -0.306766 -0.001712 -0.049309 -0.072400  0.441418        0.113769  \n",
       "163 -1.000000 -0.890980       NaN  0.028386 -0.418808       -0.570363  \n",
       "\n",
       "[164 rows x 10 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "\n",
    "red_green_scale = [\n",
    "    [0, 'red'], \n",
    "    [0.5, 'yellow'], \n",
    "    [1, 'green']  \n",
    "]\n",
    "\n",
    "###\n",
    "\n",
    "dim_df = pd.read_csv(f'../upload_data/dim_{dimension}.csv').rename(columns = {'weighted_mean': 'Weighted Score'})\n",
    "geo_merge_2 = world.merge(dim_df, left_on = 'iso_a3', right_on = 'iso_a3')\n",
    "geo_merge_2 = geo_merge_2[['name_x', 'geometry','Weighted Score']]\n",
    "\n",
    "\n",
    "fig_2 = px.choropleth(geo_merge_2,\n",
    "                    geojson=geo_merge_2.geometry,\n",
    "                    locations=geo_merge.index,\n",
    "                    color=\"Total Score\",\n",
    "                    hover_name=geo_merge_2.name_x,  # or any column for names\n",
    "                    hover_data=['Weighted Score'],  # Add more columns here\n",
    "                    projection=\"mercator\",\n",
    "                    color_continuous_scale=red_green_scale  # Or use 'Plotly3' for a built-in option\n",
    "                    )\n",
    "fig_2.update_geos(fitbounds=\"locations\", visible=False)\n",
    "fig_2.update_layout(width=1000, height=900)\n",
    "fig_2.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8357d77f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5bf2ba7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['name_x'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [28], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m world \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mread_file(gpd\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mget_path(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnaturalearth_lowres\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      2\u001b[0m geo_merge \u001b[38;5;241m=\u001b[39m world\u001b[38;5;241m.\u001b[39mmerge(all_df, left_on \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124miso_a3\u001b[39m\u001b[38;5;124m'\u001b[39m, right_on \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124miso\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m geo_merge \u001b[38;5;241m=\u001b[39m geo_merge\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpop_est\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontinent\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname_x\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124miso_a3\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgdp_md_est\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcountry-code\u001b[39m\u001b[38;5;124m'\u001b[39m])\\\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname_y\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCountry Name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted_mean\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal Score\u001b[39m\u001b[38;5;124m\"\u001b[39m})\\\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCountry Name\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m red_green_scale \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      9\u001b[0m     [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m     10\u001b[0m     [\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myellow\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m     11\u001b[0m     [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgreen\u001b[39m\u001b[38;5;124m'\u001b[39m]  \n\u001b[1;32m     12\u001b[0m ]\n\u001b[1;32m     14\u001b[0m fig \u001b[38;5;241m=\u001b[39m px\u001b[38;5;241m.\u001b[39mchoropleth(geo_merge,\n\u001b[1;32m     15\u001b[0m                     geojson\u001b[38;5;241m=\u001b[39mgeo_merge\u001b[38;5;241m.\u001b[39mgeometry,\n\u001b[1;32m     16\u001b[0m                     locations\u001b[38;5;241m=\u001b[39mgeo_merge\u001b[38;5;241m.\u001b[39mindex,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m                     color_continuous_scale\u001b[38;5;241m=\u001b[39mred_green_scale  \u001b[38;5;66;03m# Or use 'Plotly3' for a built-in option\u001b[39;00m\n\u001b[1;32m     23\u001b[0m                     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/frame.py:4957\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4809\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   4810\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   4811\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4818\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   4819\u001b[0m ):\n\u001b[1;32m   4820\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4821\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   4822\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4955\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   4956\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4957\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4958\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4959\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4960\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4961\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4962\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4963\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4964\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4965\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/generic.py:4267\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4265\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4267\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/generic.py:4311\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, consolidate, only_slice)\u001b[0m\n\u001b[1;32m   4309\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4310\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4311\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4312\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4314\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/indexes/base.py:6661\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   6660\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 6661\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6662\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   6663\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['name_x'] not found in axis\""
     ]
    }
   ],
   "source": [
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "geo_merge = world.merge(all_df, left_on = 'iso_a3', right_on = 'iso')\n",
    "\n",
    "geo_merge = geo_merge.drop(columns=['pop_est', 'continent', 'name_x', 'iso_a3', 'gdp_md_est', 'country-code'])\\\n",
    "    .rename(columns={'name_y': 'Country Name', 'weighted_mean': \"Total Score\"})\\\n",
    "    .set_index('Country Name')\n",
    "\n",
    "red_green_scale = [\n",
    "    [0, 'red'], \n",
    "    [0.5, 'yellow'], \n",
    "    [1, 'green']  \n",
    "]\n",
    "\n",
    "fig = px.choropleth(geo_merge,\n",
    "                    geojson=geo_merge.geometry,\n",
    "                    locations=geo_merge.index,\n",
    "                    color=\"Total Score\",\n",
    "                    hover_name=geo_merge.index,  # or any column for names\n",
    "                    hover_data=['Total Score', 'Dimension_G', 'Dimension_S', 'Dimension_S', 'Dimension_I', 'Dimension_C',\n",
    "       'Dimension_E', 'Dimension_R'],  # Add more columns here\n",
    "                    projection=\"mercator\",\n",
    "                    color_continuous_scale=red_green_scale  # Or use 'Plotly3' for a built-in option\n",
    "                    )\n",
    "fig.update_geos(fitbounds=\"locations\", visible=False)\n",
    "fig.update_layout(width=1000, height=900)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ecb215",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d1d9798e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>ind_C1</th>\n",
       "      <th>ind_C3</th>\n",
       "      <th>ind_C4</th>\n",
       "      <th>weighted_mean</th>\n",
       "      <th>iso_a3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W. Sahara</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>ESH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New Caledonia</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>NCL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Falkland Is.</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>FLK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Antarctica</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>ATA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fr. S. Antarctic Lands</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>ATF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>Libya</td>\n",
       "      <td>1.492524</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.246262</td>\n",
       "      <td>LBY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>Sudan</td>\n",
       "      <td>0.381323</td>\n",
       "      <td>0.080089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.230706</td>\n",
       "      <td>SDN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>Palestine</td>\n",
       "      <td>-0.654342</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.966366</td>\n",
       "      <td>0.156012</td>\n",
       "      <td>PSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>Myanmar</td>\n",
       "      <td>0.146947</td>\n",
       "      <td>-0.368115</td>\n",
       "      <td>-0.091092</td>\n",
       "      <td>-0.104087</td>\n",
       "      <td>MMR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>Ukraine</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>0.194340</td>\n",
       "      <td>0.852545</td>\n",
       "      <td>-0.151038</td>\n",
       "      <td>UKR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>174 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name    ind_C1    ind_C3    ind_C4  weighted_mean  \\\n",
       "0                 W. Sahara  1.500000       NaN       NaN       1.500000   \n",
       "1             New Caledonia  1.500000       NaN       NaN       1.500000   \n",
       "2              Falkland Is.  1.500000       NaN       NaN       1.500000   \n",
       "3                Antarctica  1.500000       NaN       NaN       1.500000   \n",
       "4    Fr. S. Antarctic Lands  1.500000       NaN       NaN       1.500000   \n",
       "..                      ...       ...       ...       ...            ...   \n",
       "169                   Libya  1.492524 -1.000000       NaN       0.246262   \n",
       "170                   Sudan  0.381323  0.080089       NaN       0.230706   \n",
       "171               Palestine -0.654342       NaN  0.966366       0.156012   \n",
       "172                 Myanmar  0.146947 -0.368115 -0.091092      -0.104087   \n",
       "173                 Ukraine -1.500000  0.194340  0.852545      -0.151038   \n",
       "\n",
       "    iso_a3  \n",
       "0      ESH  \n",
       "1      NCL  \n",
       "2      FLK  \n",
       "3      ATA  \n",
       "4      ATF  \n",
       "..     ...  \n",
       "169    LBY  \n",
       "170    SDN  \n",
       "171    PSE  \n",
       "172    MMR  \n",
       "173    UKR  \n",
       "\n",
       "[174 rows x 6 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('../upload_data/dim_C.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3190ec48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57be1ba3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6fc7a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd024c74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af8e092",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a13f2e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b470da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce20b6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4bdbb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a4f7c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2e0e5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07cc471",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_X_complete(indicator_dictionary, \"R\", manual_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccf70de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_individual_indicators(dimension_df):\n",
    "    \n",
    "    just_ind_df = dimension_df.drop(columns='weighted_mean')\n",
    "\n",
    "    world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "    geo_merge = world.merge(just_ind_df, left_on = 'name', right_index = True)\n",
    "\n",
    "    nrows, ncols = 4, 2\n",
    "\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(15, 10))\n",
    "\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, column in enumerate(just_ind_df.columns):\n",
    "        geo_merge.plot(column=column, cmap='RdYlGn', missing_kwds={'color': 'black'}, ax=axes[idx])\n",
    "        axes[idx].set_title(f'Map for {column}')\n",
    "        axes[idx].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d2f23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_individual_indicators(dim_X_complete(indicator_dictionary, 'R', manual_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
