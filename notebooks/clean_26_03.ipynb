{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4d85ca2",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8036826",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# General\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "# Data Analysis\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "# WBAPI\n",
    "\n",
    "import wbgapi as wb\n",
    "\n",
    "# Data Processing\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Aesthetic\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class color:\n",
    "   BOLD = '\\033[1m'\n",
    "   END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934e23af",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Manual Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "289ba8bd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vdem_df = pd.read_csv(\"../data/vdem/V-Dem-CY-Full+Others-v13.csv\", usecols=['country_text_id', 'v2regsupgroupssize', 'year'])\n",
    "\n",
    "owid_freedom_of_expression_df = pd.read_csv('../data/owid/freedom-of-expression-index.csv')\n",
    "\n",
    "owid_pa_index_df = pd.read_csv('../data/owid/rigorous-and-impartial-public-administration-index.csv')\n",
    "\n",
    "owid_state_control_df = pd.read_csv('../data/owid/percentage-of-territory-controlled-by-government.csv')\n",
    "\n",
    "acled_df = pd.read_csv('../data/acled/2023_all_data.csv', usecols= ['event_type', 'country', 'fatalities', 'population_best', 'year', 'iso'])\n",
    "\n",
    "nd_df = pd.read_csv('../data/nd/gain.csv')\n",
    "\n",
    "unhcr_df = pd.read_csv('../data/population.csv')\n",
    "\n",
    "geo_df = pd.read_csv('../data/geodata.csv')\n",
    "\n",
    "iso_list = pd.read_csv(\"../data/all.csv\", usecols= ['name', 'alpha-3', 'country-code'])\n",
    "\n",
    "manual_data = {\n",
    "    'V-DEM': vdem_df,\n",
    "    'OWiD': {\n",
    "        'Public Administration Index': owid_pa_index_df,\n",
    "        'Freedom of Expression Index': owid_freedom_of_expression_df,\n",
    "        'State Control over Territory': owid_state_control_df\n",
    "    },\n",
    "    'ACLED': acled_df,\n",
    "    'ND': nd_df,\n",
    "    'UNHCR': unhcr_df,\n",
    "    'iso_list': iso_list,\n",
    "    'geodata': geo_df\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44b9d11",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Fragility Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dde8e7d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dimension_weights = {\n",
    "    'G': 3,\n",
    "    'S': 2,\n",
    "    'I': 2,\n",
    "    'C': 3,\n",
    "    'E': 1,\n",
    "    'R': 1\n",
    "}\n",
    "\n",
    "indicator_dictionary = {\n",
    "    'G': {\n",
    "        1:['V-DEM', 'Size of Regime Support Group', 3],\n",
    "        2:['OWiD', 'Public Administration Index', 2],\n",
    "        3:['WB', 'Control of Corruption: Estimate', 2],\n",
    "        4:['WB', 'Rule of Law: Estimate', 2],\n",
    "        5:['WB', 'Tax Revenue', 2, slice(1,2)],\n",
    "        6:['WB', 'Proportion of Seats Held by Women', 1],\n",
    "        7:['OWiD', 'Freedom of Expression Index', 1]\n",
    "    },\n",
    "    'S': {\n",
    "        1:['WB', 'Gini Index', -3],\n",
    "        2:['WB', 'Inflation, Consumer Prices', -2],\n",
    "        3:['WB', 'Unemployment, Total', -2, slice(1,2)],\n",
    "        4:['WB', 'Women Business and the Law Index', 2],\n",
    "        5:['ACLED', 'Protest Count', -2],\n",
    "        6:['WB', 'Age Dependency Ratio', -1, slice(0,1)],\n",
    "        7:['WB', 'Ease of Doing Business Score', 1]\n",
    "    },\n",
    "    'I': {\n",
    "        1:['WB', 'GDP per Capita', 3, slice(0,1)],\n",
    "        2:['WB', 'Poverty Gap at $2.15 a Day', -3],\n",
    "        3:['WB', 'Human Capital Index', 2, slice(0,1)],\n",
    "        4:['WB', 'Women who Believe a Husband is Justified in Beating his Wife', -2, slice(4,5)],\n",
    "        5:['WB', 'Current Health Expenditure per Capita, PPP', 2],\n",
    "        6:[],\n",
    "        7:[]\n",
    "    },\n",
    "    'C': {\n",
    "        1:['ACLED', 'Battle Related Fatalities', -3],\n",
    "        2:[],\n",
    "        3:['OWiD', 'State Control over Territory', 2],\n",
    "        4:['WB', 'Intentional homicides', -2, slice(2,3)],\n",
    "        5:[],\n",
    "        6:[],\n",
    "        7:[]\n",
    "    },\n",
    "    'E': {\n",
    "        1:['ND', 'GAIN Index', 3],\n",
    "        2:[],\n",
    "        3:[],\n",
    "        4:[],\n",
    "        5:[],\n",
    "        6:[],\n",
    "        7:[]\n",
    "    },\n",
    "    'R': {\n",
    "        1:['ACLED', 'Violence in Neighbouring States', -3],\n",
    "        2:['UNHCR', 'Refugee In-Flow', -2],\n",
    "        3:['WB','Total Natural Resources Rents', -1],\n",
    "        4:[],\n",
    "        5:[],\n",
    "        6:[],\n",
    "        7:[]\n",
    "    }\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e11bef8",
   "metadata": {},
   "source": [
    "# Data Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd81b23c",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## WB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad9f8ace",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def indicator_to_df(query, specify = False):\n",
    "\n",
    "    # Function to get indicator code\n",
    "\n",
    "    if specify:\n",
    "        return pd.DataFrame(wb.series.Series(q= query)).reset_index().iloc[specify]\n",
    "    return pd.DataFrame(wb.series.Series(q= query)).reset_index()\n",
    "\n",
    "def wb_data_completer(indicator, coverage_threshold = 0.85, years_to_check = 10, database = None, specify = False):\n",
    "    \n",
    "    def fetch_data_and_calculate_completeness(database_number):\n",
    "        \n",
    "        # Checks coverage of data\n",
    "        \n",
    "        wb.db = database_number\n",
    "        db_ind = indicator_to_df(indicator, specify = specify)\n",
    "        \n",
    "        if len(db_ind) == 0:  # If no data is found for this database\n",
    "            return 0  # Completeness is 0%\n",
    "        return float(wb.data.DataFrame(db_ind['index'], mrv=1).notna().mean())\n",
    "    \n",
    "    # Check which database to use if not specified\n",
    "    \n",
    "    if database is None:\n",
    "        \n",
    "        db2_complete = fetch_data_and_calculate_completeness(2)\n",
    "        db3_complete = fetch_data_and_calculate_completeness(3)\n",
    "        \n",
    "        database = 2 if db2_complete >= db3_complete or db3_complete == 0 else 3\n",
    "    \n",
    "    # Check coverage of most recent year\n",
    "    \n",
    "    wb.db = database\n",
    "    coverage_complete = fetch_data_and_calculate_completeness(database)\n",
    "    final_ind = indicator_to_df(indicator, specify = specify)\n",
    "        \n",
    "    # Return mrv = 1 if already passing data threshold\n",
    "    \n",
    "    if coverage_complete > coverage_threshold:\n",
    "        print(f\"\"\"Data for '{indicator}' found in WB Database {database}. Returning data for the most recent year. \n",
    "        Coverage = {round(coverage_complete, 4)*100}%, greater than selected threshold of {round(coverage_threshold, 4)*100}%.\\n\"\"\")\n",
    "        final_ind = wb.data.DataFrame(final_ind['index'], mrv=1)\n",
    "        final_ind.columns = ['Final Value']\n",
    "        \n",
    "        return final_ind\n",
    "    \n",
    "    # Otherwise go back number of years specified\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        print(f\"\"\"Data for '{indicator}' does not meet the coverage threshold of {coverage_threshold*100}% in WB Database {database}.\n",
    "        Extracting data from previous years.\"\"\")\n",
    "        \n",
    "        # Get Data\n",
    "        \n",
    "        \n",
    "        multiyear_df = wb.data.DataFrame(final_ind['index'], mrv=years_to_check)\n",
    "        \n",
    "        # Loop through DF in reverse order\n",
    "        \n",
    "        current_year = int(multiyear_df.columns[-1][2:])\n",
    "        all_years = list(range(current_year, current_year - years_to_check, -1)) \n",
    "        \n",
    "        for i, year in enumerate(all_years):\n",
    "            year_column = f'YR{year}'\n",
    "            \n",
    "            # Skip years that don't have a corresponding column in the DataFrame\n",
    "            \n",
    "            if year_column not in multiyear_df.columns:\n",
    "                continue \n",
    "                \n",
    "            # For the first year, initialize 'Final_Value' with its values\n",
    "            \n",
    "            if i == 0:\n",
    "                multiyear_df['Final_Value'] = multiyear_df[year_column]\n",
    "                \n",
    "            # Fill missing values in 'Final_Value' with the current year's data\n",
    " \n",
    "            else:\n",
    "                multiyear_df['Final_Value'] = multiyear_df['Final_Value'].fillna(multiyear_df[year_column])\n",
    "            \n",
    "            # Check data completeness for 'Final_Value' after potential filling\n",
    "            \n",
    "            data_coverage = multiyear_df['Final_Value'].notna().mean()\n",
    "            if data_coverage >= coverage_threshold:\n",
    "                print(f\"\"\"Achieved {round(data_coverage,4)*100}% data coverage by going back to data from {year},\n",
    "                exceeding minimum threshold of {coverage_threshold*100}%. Returning this dataframe.\\n\"\"\")\n",
    "                break\n",
    "                \n",
    "        # Return Final DF\n",
    "                \n",
    "        if data_coverage < coverage_threshold:\n",
    "            \n",
    "            print(f\"\"\"Data coverage at {round(data_coverage,4)*100}% after going back {years_to_check} years.\n",
    "            Failed to exceed minimum threshold of {coverage_threshold*100}%. Returning best dataframe anyway.\\n\"\"\")\n",
    "            \n",
    "            \n",
    "        return multiyear_df[['Final_Value']]\n",
    "\n",
    "def indicator_returner(query, dimension = 'dim', indicator = 'ind', specify = False):\n",
    "    \n",
    "    df = wb_data_completer(query, specify = specify)\n",
    "    df.columns = [f'ind_{dimension}{indicator}']\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a556672",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c60b961",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def scale_and_weight(merged_df, weight_list, single_dimension = True):\n",
    "    \n",
    "    # Scale\n",
    "    \n",
    "    if not single_dimension:\n",
    "        temp_df = merged_df[['iso']]\n",
    "        merged_df = merged_df.drop(columns = 'iso')\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_nums = scaler.fit_transform(merged_df)\n",
    "    scaled_df = pd.DataFrame(scaled_nums, columns=scaler.get_feature_names_out()).sub(0.5)\n",
    "    scaled_df.index = merged_df.index\n",
    "    \n",
    "    # Weight\n",
    "    \n",
    "    keys = scaled_df.columns\n",
    "    \n",
    "    weights = dict(zip(keys, weight_list))\n",
    "\n",
    "    weighted_df = pd.DataFrame()\n",
    "\n",
    "    for column, weight in weights.items():\n",
    "        weighted_df[column] = scaled_df[column] * weight\n",
    "        \n",
    "    # Weighted mean\n",
    "    \n",
    "    weighted_df['weighted_mean'] = weighted_df.mean(axis=1)\n",
    "    \n",
    "    if single_dimension:\n",
    "        weighted_df['weighted_mean'] = weighted_df.apply(lambda row: np.nan if row[keys].isnull().sum() > 2 else row['weighted_mean'], axis=1)\n",
    "    \n",
    "    weighted_df = weighted_df.sort_values('weighted_mean', ascending=False)\n",
    "    \n",
    "    if not single_dimension:\n",
    "        return weighted_df.join(temp_df)\n",
    "    \n",
    "    # Adding country names as index\n",
    "    \n",
    "    world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "    listylist = list(weighted_df.columns)\n",
    "    listylist.append('name')\n",
    "    listylist.append('iso_a3')\n",
    "    final_df = weighted_df.merge(world, left_index=True, right_on='iso_a3')[listylist].set_index('name')\n",
    "    \n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d107159",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Single Dimension Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15839794",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def dimension_data_loader(dimension_dict, dimension, manual_data):\n",
    "    \n",
    "    full_df = None\n",
    "    \n",
    "    for ind_num, ind_value in dimension_dict.items():\n",
    "        \n",
    "        if ind_value[0] == 'WB':\n",
    "            \n",
    "            if len(ind_value) == 3:\n",
    "            \n",
    "                ind_x = indicator_returner(ind_value[1], f\"{dimension}\", f\"{ind_num}\")\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                ind_x = indicator_returner(ind_value[1], f\"{dimension}\", f\"{ind_num}\", specify= ind_value[-1])\n",
    "                \n",
    "            \n",
    "        if ind_value[0] == 'V-DEM':\n",
    "            \n",
    "            rel_df = manual_data[ind_value[0]]\n",
    "            \n",
    "            ind_x = rel_df[rel_df['year'] == 2022][['country_text_id', 'v2regsupgroupssize']].set_index('country_text_id')\n",
    "            ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "            \n",
    "            \n",
    "        if ind_value[0] == 'OWiD':\n",
    "            \n",
    "            rel_df = manual_data[ind_value[0]]\n",
    "            \n",
    "            if ind_value[1] ==  'Public Administration Index':\n",
    "               \n",
    "                ind_x = rel_df[ind_value[1]]\n",
    "                ind_x = ind_x[ind_x['Year'] == 2022].set_index('Code')[['public_admin_vdem_owid']]\n",
    "                ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "               \n",
    "            if ind_value[1] ==  'Freedom of Expression Index':\n",
    "                ind_x = rel_df[ind_value[1]]\n",
    "                ind_x = ind_x[ind_x['Year'] == 2022].set_index('Code')[['freeexpr_vdem_owid']]\n",
    "                ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "                \n",
    "            if ind_value[1] ==  'State Control over Territory':\n",
    "                ind_x = rel_df[ind_value[1]]\n",
    "                ind_x = ind_x[ind_x['Year'] == 2022].set_index('Code')[['terr_contr_vdem_owid']]\n",
    "                ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "                \n",
    "                \n",
    "        if ind_value[0] == 'ACLED':\n",
    "            \n",
    "            rel_df = manual_data[ind_value[0]]\n",
    "            rel_df_2 = manual_data['iso_list']\n",
    "            \n",
    "            if ind_value[1] ==  'Protest Count':\n",
    "                \n",
    "                grouped_df = rel_df[rel_df['event_type'] == 'Protests'][['country', 'year', 'iso']].groupby(by = 'iso')\\\n",
    "                    .agg({'year': 'count'})\n",
    "                ind_x = grouped_df.merge(rel_df_2, left_index=True, right_on= 'country-code').set_index('alpha-3')[['year']]\n",
    "                ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "                \n",
    "                \n",
    "#                 aclest = manual_data['ACLED'][manual_data['ACLED']['event_type'] == 'Protests'][['country', 'year', 'iso']].groupby(by = 'iso')\\\n",
    "#                     .agg({'year': 'count'})\n",
    "#                 # aclest.merge(iso_list, how = 'left', left_index=True, right_on='country-code')\n",
    "#                 ind_x = aclest.merge(iso_list, how = 'left', left_index=True, right_on='country-code').set_index('alpha-3')[['year']]\n",
    "#                 ind_x\n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "            if ind_value[1] ==  'Battle Related Fatalities':\n",
    "                \n",
    "                grouped_df = rel_df[rel_df['event_type'].isin(['Explosions/Remote violence', 'Battles'])]\\\n",
    "                    [['country', 'fatalities', 'iso']].groupby(by = 'iso').agg({'fatalities': 'sum'})\n",
    "                ind_x = grouped_df.merge(rel_df_2, left_index=True, right_on= 'country-code', how = 'right').set_index('alpha-3')[['fatalities']]\n",
    "                ind_x['fatalities'] = ind_x['fatalities'].fillna(0)\n",
    "                ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "                \n",
    "            if ind_value[1] ==  'Violence in Neighbouring States':\n",
    "                \n",
    "                ## FIX ISO NOT NAME HERE\n",
    "                \n",
    "                grouped_df = rel_df.groupby(by = 'country').sum()[['fatalities']]\n",
    "                geo_df = manual_data['geodata']\n",
    "                merged_geo = geo_df.merge(grouped_df, left_on='country_border_name', right_index=True, how = 'left')\n",
    "                merged_grouped = merged_geo.groupby('country_name').sum()\n",
    "                ind_x = merged_grouped.merge(rel_df_2, left_index=True, right_on= 'name', how = 'right').set_index('alpha-3')[['fatalities']]\n",
    "                ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "                \n",
    "\n",
    "        if ind_value[0] == 'ND':\n",
    "            \n",
    "            rel_df = manual_data[ind_value[0]]\n",
    "            ind_x = rel_df.set_index('ISO3')[['2021']]\n",
    "            ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "            \n",
    "            \n",
    "        if ind_value[0] == 'UNHCR':\n",
    "            \n",
    "            rel_df = manual_data[ind_value[0]]\n",
    "            ind_x = rel_df.set_index(\"Country of asylum (ISO)\")[[\"Refugees under UNHCR's mandate\"]]\n",
    "            ind_x.columns = [f'ind_{dimension}{ind_num}']\n",
    "            \n",
    "        \n",
    "        print(f'''Successfully loaded Indicator {dimension}{ind_num} from {ind_value[0]} Database\\n''')\n",
    "        \n",
    "        ### Merging DF ###\n",
    "               \n",
    "        if not isinstance(full_df, pd.DataFrame):\n",
    "            \n",
    "            full_df = ind_x\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            full_df = full_df.merge(ind_x, left_index = True, right_index = True, how = 'left')\n",
    "        \n",
    "    return full_df\n",
    "\n",
    "\n",
    "\n",
    "def dim_X_complete(indicator_dictionary, dimension, manual_data):\n",
    "    \n",
    "    dimension_dict = indicator_dictionary[dimension]\n",
    "    dimension_dict = {k: v for k, v in dimension_dict.items() if v}\n",
    "    \n",
    "    print(f\"\"\"\\n\\n\n",
    "    --------------------------Dimension {dimension}------------------------------\\n\n",
    "    \"\"\")\n",
    "    \n",
    "    ### Loading Data ###\n",
    "    \n",
    "    print(color.BOLD + \"Loading Data.....\\n\" + color.END)\n",
    "    \n",
    "    full_df = dimension_data_loader(dimension_dict, dimension, manual_data)\n",
    "    \n",
    "    ### Scaling and Weighting ###\n",
    "    \n",
    "    print (color.BOLD + \"Scaling & Weighting Data....\" + color.END)\n",
    "    \n",
    "    weight_list = []\n",
    "    for values in dimension_dict.values():\n",
    "        weight_list.append(values[2])\n",
    "        \n",
    "    full_df = scale_and_weight(full_df, weight_list)\n",
    "    \n",
    "    print(f\"\"\"\\n**Successfully loaded , merged, scaled, and weighted Dimension {dimension} Data**\\n\"\"\")\n",
    "    print(color.BOLD  + \"\"\"Overall Data Coverage:\"\"\" + color.END + \"(Weighted Mean missing if more than 2 indicators are missing for that Dimension..)\")\n",
    "    print(1- full_df.isna().sum()/len(full_df))\n",
    "\n",
    "    print(\"\"\"\\n\\n\n",
    "    ---------------------------------------------------------------------------\\n\\n\n",
    "    \n",
    "    \"\"\")\n",
    "            \n",
    "            \n",
    "    return full_df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13d1ab6",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## All Dimensions Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e82d4da5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def all_dimension_pipeline(indicator_dictionary, dimension_weights,manual_data):\n",
    "\n",
    "    all_dim_df = None\n",
    "\n",
    "    for key in indicator_dictionary.keys():\n",
    "\n",
    "        dimension_df = dim_X_complete(indicator_dictionary, key, manual_data)[['weighted_mean', 'iso_a3']]\n",
    "\n",
    "        dimension_df.columns = [f'Dimension_{key}', 'iso']\n",
    "\n",
    "        if not isinstance(all_dim_df, pd.DataFrame):\n",
    "\n",
    "            all_dim_df = dimension_df\n",
    "\n",
    "        else:\n",
    "\n",
    "            all_dim_df = all_dim_df.merge(dimension_df, left_on = 'iso', right_on = 'iso', how = 'left')\n",
    "        \n",
    "    overall_scoring_df = scale_and_weight(all_dim_df, dimension_weights.values(), single_dimension=False)\n",
    "            \n",
    "    submit_df = overall_scoring_df.merge(manual_data['iso_list'],how='left', left_on='iso', right_on='alpha-3')\\\n",
    "        .set_index('name').drop(columns='alpha-3')\n",
    "    \n",
    "    return submit_df\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7646df12",
   "metadata": {},
   "source": [
    "## Compare to OECD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b938beff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "    --------------------------Dimension G------------------------------\n",
      "\n",
      "    \n",
      "\u001b[1mLoading Data.....\n",
      "\u001b[0m\n",
      "Successfully loaded Indicator G1 from V-DEM Database\n",
      "\n",
      "Successfully loaded Indicator G2 from OWiD Database\n",
      "\n",
      "Data for 'Control of Corruption: Estimate' found in WB Database 3. Returning data for the most recent year. \n",
      "        Coverage = 99.53%, greater than selected threshold of 85.0%.\n",
      "\n",
      "Successfully loaded Indicator G3 from WB Database\n",
      "\n",
      "Data for 'Rule of Law: Estimate' found in WB Database 3. Returning data for the most recent year. \n",
      "        Coverage = 99.53%, greater than selected threshold of 85.0%.\n",
      "\n",
      "Successfully loaded Indicator G4 from WB Database\n",
      "\n",
      "Data for 'Tax Revenue' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Data coverage at 67.67% after going back 10 years.\n",
      "            Failed to exceed minimum threshold of 85.0%. Returning best dataframe anyway.\n",
      "\n",
      "Successfully loaded Indicator G5 from WB Database\n",
      "\n",
      "Data for 'Proportion of Seats Held by Women' found in WB Database 2. Returning data for the most recent year. \n",
      "        Coverage = 88.35%, greater than selected threshold of 85.0%.\n",
      "\n",
      "Successfully loaded Indicator G6 from WB Database\n",
      "\n",
      "Successfully loaded Indicator G7 from OWiD Database\n",
      "\n",
      "\u001b[1mScaling & Weighting Data....\u001b[0m\n",
      "\n",
      "**Successfully loaded , merged, scaled, and weighted Dimension G Data**\n",
      "\n",
      "\u001b[1mOverall Data Coverage:\u001b[0m(Weighted Mean missing if more than 2 indicators are missing for that Dimension..)\n",
      "ind_G1           0.981707\n",
      "ind_G2           0.993902\n",
      "ind_G3           1.000000\n",
      "ind_G4           1.000000\n",
      "ind_G5           0.774390\n",
      "ind_G6           0.951220\n",
      "ind_G7           0.993902\n",
      "weighted_mean    0.993902\n",
      "iso_a3           1.000000\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "    ---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "    \n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "    --------------------------Dimension S------------------------------\n",
      "\n",
      "    \n",
      "\u001b[1mLoading Data.....\n",
      "\u001b[0m\n",
      "Data for 'Gini Index' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Data coverage at 53.76% after going back 10 years.\n",
      "            Failed to exceed minimum threshold of 85.0%. Returning best dataframe anyway.\n",
      "\n",
      "Successfully loaded Indicator S1 from WB Database\n",
      "\n",
      "Data for 'Inflation, Consumer Prices' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Achieved 85.34% data coverage by going back to data from 2018,\n",
      "                exceeding minimum threshold of 85.0%. Returning this dataframe.\n",
      "\n",
      "Successfully loaded Indicator S2 from WB Database\n",
      "\n",
      "Data for 'Unemployment, Total' found in WB Database 2. Returning data for the most recent year. \n",
      "        Coverage = 87.97%, greater than selected threshold of 85.0%.\n",
      "\n",
      "Successfully loaded Indicator S3 from WB Database\n",
      "\n",
      "Data for 'Women Business and the Law Index' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Data coverage at 75.56% after going back 10 years.\n",
      "            Failed to exceed minimum threshold of 85.0%. Returning best dataframe anyway.\n",
      "\n",
      "Successfully loaded Indicator S4 from WB Database\n",
      "\n",
      "Successfully loaded Indicator S5 from ACLED Database\n",
      "\n",
      "Data for 'Age Dependency Ratio' found in WB Database 2. Returning data for the most recent year. \n",
      "        Coverage = 99.62%, greater than selected threshold of 85.0%.\n",
      "\n",
      "Successfully loaded Indicator S6 from WB Database\n",
      "\n",
      "Data for 'Ease of Doing Business Score' found in WB Database 2. Returning data for the most recent year. \n",
      "        Coverage = 89.47%, greater than selected threshold of 85.0%.\n",
      "\n",
      "Successfully loaded Indicator S7 from WB Database\n",
      "\n",
      "\u001b[1mScaling & Weighting Data....\u001b[0m\n",
      "\n",
      "**Successfully loaded , merged, scaled, and weighted Dimension S Data**\n",
      "\n",
      "\u001b[1mOverall Data Coverage:\u001b[0m(Weighted Mean missing if more than 2 indicators are missing for that Dimension..)\n",
      "ind_S1           0.763314\n",
      "ind_S2           0.911243\n",
      "ind_S3           0.988166\n",
      "ind_S4           0.970414\n",
      "ind_S5           0.970414\n",
      "ind_S6           1.000000\n",
      "ind_S7           0.970414\n",
      "weighted_mean    0.964497\n",
      "iso_a3           1.000000\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "    ---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "    \n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "    --------------------------Dimension I------------------------------\n",
      "\n",
      "    \n",
      "\u001b[1mLoading Data.....\n",
      "\u001b[0m\n",
      "Data for 'GDP per Capita' found in WB Database 2. Returning data for the most recent year. \n",
      "        Coverage = 91.35%, greater than selected threshold of 85.0%.\n",
      "\n",
      "Successfully loaded Indicator I1 from WB Database\n",
      "\n",
      "Data for 'Poverty Gap at $2.15 a Day' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Data coverage at 59.019999999999996% after going back 10 years.\n",
      "            Failed to exceed minimum threshold of 85.0%. Returning best dataframe anyway.\n",
      "\n",
      "Successfully loaded Indicator I2 from WB Database\n",
      "\n",
      "Data for 'Human Capital Index' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Data coverage at 65.41% after going back 10 years.\n",
      "            Failed to exceed minimum threshold of 85.0%. Returning best dataframe anyway.\n",
      "\n",
      "Successfully loaded Indicator I3 from WB Database\n",
      "\n",
      "Data for 'Women who Believe a Husband is Justified in Beating his Wife' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Data coverage at 22.56% after going back 10 years.\n",
      "            Failed to exceed minimum threshold of 85.0%. Returning best dataframe anyway.\n",
      "\n",
      "Successfully loaded Indicator I4 from WB Database\n",
      "\n",
      "Data for 'Current Health Expenditure per Capita, PPP' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Achieved 87.59% data coverage by going back to data from 2020,\n",
      "                exceeding minimum threshold of 85.0%. Returning this dataframe.\n",
      "\n",
      "Successfully loaded Indicator I5 from WB Database\n",
      "\n",
      "\u001b[1mScaling & Weighting Data....\u001b[0m\n",
      "\n",
      "**Successfully loaded , merged, scaled, and weighted Dimension I Data**\n",
      "\n",
      "\u001b[1mOverall Data Coverage:\u001b[0m(Weighted Mean missing if more than 2 indicators are missing for that Dimension..)\n",
      "ind_I1           0.940828\n",
      "ind_I2           0.763314\n",
      "ind_I3           0.893491\n",
      "ind_I4           0.343195\n",
      "ind_I5           0.934911\n",
      "weighted_mean    0.899408\n",
      "iso_a3           1.000000\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "    ---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "    \n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "    --------------------------Dimension C------------------------------\n",
      "\n",
      "    \n",
      "\u001b[1mLoading Data.....\n",
      "\u001b[0m\n",
      "Successfully loaded Indicator C1 from ACLED Database\n",
      "\n",
      "Successfully loaded Indicator C3 from OWiD Database\n",
      "\n",
      "Data for 'Intentional homicides' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Data coverage at 84.21% after going back 10 years.\n",
      "            Failed to exceed minimum threshold of 85.0%. Returning best dataframe anyway.\n",
      "\n",
      "Successfully loaded Indicator C4 from WB Database\n",
      "\n",
      "\u001b[1mScaling & Weighting Data....\u001b[0m\n",
      "\n",
      "**Successfully loaded , merged, scaled, and weighted Dimension C Data**\n",
      "\n",
      "\u001b[1mOverall Data Coverage:\u001b[0m(Weighted Mean missing if more than 2 indicators are missing for that Dimension..)\n",
      "ind_C1           1.000000\n",
      "ind_C3           0.936782\n",
      "ind_C4           0.816092\n",
      "weighted_mean    1.000000\n",
      "iso_a3           1.000000\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "    ---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "    \n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "    --------------------------Dimension E------------------------------\n",
      "\n",
      "    \n",
      "\u001b[1mLoading Data.....\n",
      "\u001b[0m\n",
      "Successfully loaded Indicator E1 from ND Database\n",
      "\n",
      "\u001b[1mScaling & Weighting Data....\u001b[0m\n",
      "\n",
      "**Successfully loaded , merged, scaled, and weighted Dimension E Data**\n",
      "\n",
      "\u001b[1mOverall Data Coverage:\u001b[0m(Weighted Mean missing if more than 2 indicators are missing for that Dimension..)\n",
      "ind_E1           1.0\n",
      "weighted_mean    1.0\n",
      "iso_a3           1.0\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "    ---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "    \n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "    --------------------------Dimension R------------------------------\n",
      "\n",
      "    \n",
      "\u001b[1mLoading Data.....\n",
      "\u001b[0m\n",
      "Successfully loaded Indicator R1 from ACLED Database\n",
      "\n",
      "Successfully loaded Indicator R2 from UNHCR Database\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 'Total Natural Resources Rents' found in WB Database 2. Returning data for the most recent year. \n",
      "        Coverage = 92.11%, greater than selected threshold of 85.0%.\n",
      "\n",
      "Successfully loaded Indicator R3 from WB Database\n",
      "\n",
      "\u001b[1mScaling & Weighting Data....\u001b[0m\n",
      "\n",
      "**Successfully loaded , merged, scaled, and weighted Dimension R Data**\n",
      "\n",
      "\u001b[1mOverall Data Coverage:\u001b[0m(Weighted Mean missing if more than 2 indicators are missing for that Dimension..)\n",
      "ind_R1           0.954023\n",
      "ind_R2           0.879310\n",
      "ind_R3           0.913793\n",
      "weighted_mean    0.994253\n",
      "iso_a3           1.000000\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "    ---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "    \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "all_df = all_dimension_pipeline(indicator_dictionary=indicator_dictionary, dimension_weights=dimension_weights, manual_data=manual_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20bbee7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "oecd_df = pd.read_excel('../data/state_o_f/List of fragile contexts (2022) (1).xlsx')\n",
    "\n",
    "oecd_df = oecd_df.reset_index().rename(columns={'index':'OECD Rank'}).set_index('iso3c')\n",
    "\n",
    "oecd_df['OECD Rank'] = oecd_df['OECD Rank']+1\n",
    "\n",
    "score_df = all_df.set_index('iso')[['weighted_mean']]\n",
    "\n",
    "score_df['BMZ Rank'] = score_df['weighted_mean'].rank()\n",
    "\n",
    "score_df['BMZ Rank'] = score_df['BMZ Rank'].astype(int)\n",
    "\n",
    "compare_df = oecd_df.merge(score_df, left_index=True, right_index=True, how = 'left')[['context', 'OECD Rank', 'BMZ Rank']]\n",
    "\n",
    "compare_df = compare_df.fillna(999)\n",
    "\n",
    "compare_df['BMZ Rank'] = compare_df['BMZ Rank'].astype(int)\n",
    "\n",
    "compare_df = compare_df.rename(columns={'context': \"Country Name\"}).set_index('Country Name')\n",
    "\n",
    "compare_df['Comparison'] = compare_df['BMZ Rank'] - compare_df['OECD Rank']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61ac108",
   "metadata": {},
   "source": [
    "## All Dimensions Seperately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05959c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def all_the_data(indicator_dictionary, manual_data):\n",
    "    \n",
    "    all_data_dic = {}\n",
    "\n",
    "    for key in indicator_dictionary.keys():\n",
    "        all_data_dic[key] = dim_X_complete(indicator_dictionary, key, manual_data)\n",
    "        \n",
    "    return all_data_dic\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecff3fa6",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# To CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee54276",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Overall Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6268547b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ac347e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_df.to_csv(\"../upload_data/full_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c245f76",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Each Dim Seperately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6abede98",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "    --------------------------Dimension G------------------------------\n",
      "\n",
      "    \n",
      "\u001b[1mLoading Data.....\n",
      "\u001b[0m\n",
      "Successfully loaded Indicator G1 from V-DEM Database\n",
      "\n",
      "Successfully loaded Indicator G2 from OWiD Database\n",
      "\n",
      "Data for 'Control of Corruption: Estimate' found in WB Database 3. Returning data for the most recent year. \n",
      "        Coverage = 99.53%, greater than selected threshold of 85.0%.\n",
      "\n",
      "Successfully loaded Indicator G3 from WB Database\n",
      "\n",
      "Data for 'Rule of Law: Estimate' found in WB Database 3. Returning data for the most recent year. \n",
      "        Coverage = 99.53%, greater than selected threshold of 85.0%.\n",
      "\n",
      "Successfully loaded Indicator G4 from WB Database\n",
      "\n",
      "Data for 'Tax Revenue' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Data coverage at 67.67% after going back 10 years.\n",
      "            Failed to exceed minimum threshold of 85.0%. Returning best dataframe anyway.\n",
      "\n",
      "Successfully loaded Indicator G5 from WB Database\n",
      "\n",
      "Data for 'Proportion of Seats Held by Women' found in WB Database 2. Returning data for the most recent year. \n",
      "        Coverage = 88.35%, greater than selected threshold of 85.0%.\n",
      "\n",
      "Successfully loaded Indicator G6 from WB Database\n",
      "\n",
      "Successfully loaded Indicator G7 from OWiD Database\n",
      "\n",
      "\u001b[1mScaling & Weighting Data....\u001b[0m\n",
      "\n",
      "**Successfully loaded , merged, scaled, and weighted Dimension G Data**\n",
      "\n",
      "\u001b[1mOverall Data Coverage:\u001b[0m(Weighted Mean missing if more than 2 indicators are missing for that Dimension..)\n",
      "ind_G1           0.981707\n",
      "ind_G2           0.993902\n",
      "ind_G3           1.000000\n",
      "ind_G4           1.000000\n",
      "ind_G5           0.774390\n",
      "ind_G6           0.951220\n",
      "ind_G7           0.993902\n",
      "weighted_mean    0.993902\n",
      "iso_a3           1.000000\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "    ---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "    \n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "    --------------------------Dimension S------------------------------\n",
      "\n",
      "    \n",
      "\u001b[1mLoading Data.....\n",
      "\u001b[0m\n",
      "Data for 'Gini Index' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Data coverage at 53.76% after going back 10 years.\n",
      "            Failed to exceed minimum threshold of 85.0%. Returning best dataframe anyway.\n",
      "\n",
      "Successfully loaded Indicator S1 from WB Database\n",
      "\n",
      "Data for 'Inflation, Consumer Prices' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Achieved 85.34% data coverage by going back to data from 2018,\n",
      "                exceeding minimum threshold of 85.0%. Returning this dataframe.\n",
      "\n",
      "Successfully loaded Indicator S2 from WB Database\n",
      "\n",
      "Data for 'Unemployment, Total' found in WB Database 2. Returning data for the most recent year. \n",
      "        Coverage = 87.97%, greater than selected threshold of 85.0%.\n",
      "\n",
      "Successfully loaded Indicator S3 from WB Database\n",
      "\n",
      "Data for 'Women Business and the Law Index' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Data coverage at 75.56% after going back 10 years.\n",
      "            Failed to exceed minimum threshold of 85.0%. Returning best dataframe anyway.\n",
      "\n",
      "Successfully loaded Indicator S4 from WB Database\n",
      "\n",
      "Successfully loaded Indicator S5 from ACLED Database\n",
      "\n",
      "Data for 'Age Dependency Ratio' found in WB Database 2. Returning data for the most recent year. \n",
      "        Coverage = 99.62%, greater than selected threshold of 85.0%.\n",
      "\n",
      "Successfully loaded Indicator S6 from WB Database\n",
      "\n",
      "Data for 'Ease of Doing Business Score' found in WB Database 2. Returning data for the most recent year. \n",
      "        Coverage = 89.47%, greater than selected threshold of 85.0%.\n",
      "\n",
      "Successfully loaded Indicator S7 from WB Database\n",
      "\n",
      "\u001b[1mScaling & Weighting Data....\u001b[0m\n",
      "\n",
      "**Successfully loaded , merged, scaled, and weighted Dimension S Data**\n",
      "\n",
      "\u001b[1mOverall Data Coverage:\u001b[0m(Weighted Mean missing if more than 2 indicators are missing for that Dimension..)\n",
      "ind_S1           0.763314\n",
      "ind_S2           0.911243\n",
      "ind_S3           0.988166\n",
      "ind_S4           0.970414\n",
      "ind_S5           0.970414\n",
      "ind_S6           1.000000\n",
      "ind_S7           0.970414\n",
      "weighted_mean    0.964497\n",
      "iso_a3           1.000000\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "    ---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "    \n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "    --------------------------Dimension I------------------------------\n",
      "\n",
      "    \n",
      "\u001b[1mLoading Data.....\n",
      "\u001b[0m\n",
      "Data for 'GDP per Capita' found in WB Database 2. Returning data for the most recent year. \n",
      "        Coverage = 91.35%, greater than selected threshold of 85.0%.\n",
      "\n",
      "Successfully loaded Indicator I1 from WB Database\n",
      "\n",
      "Data for 'Poverty Gap at $2.15 a Day' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Data coverage at 59.019999999999996% after going back 10 years.\n",
      "            Failed to exceed minimum threshold of 85.0%. Returning best dataframe anyway.\n",
      "\n",
      "Successfully loaded Indicator I2 from WB Database\n",
      "\n",
      "Data for 'Human Capital Index' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Data coverage at 65.41% after going back 10 years.\n",
      "            Failed to exceed minimum threshold of 85.0%. Returning best dataframe anyway.\n",
      "\n",
      "Successfully loaded Indicator I3 from WB Database\n",
      "\n",
      "Data for 'Women who Believe a Husband is Justified in Beating his Wife' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Data coverage at 22.56% after going back 10 years.\n",
      "            Failed to exceed minimum threshold of 85.0%. Returning best dataframe anyway.\n",
      "\n",
      "Successfully loaded Indicator I4 from WB Database\n",
      "\n",
      "Data for 'Current Health Expenditure per Capita, PPP' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Achieved 87.59% data coverage by going back to data from 2020,\n",
      "                exceeding minimum threshold of 85.0%. Returning this dataframe.\n",
      "\n",
      "Successfully loaded Indicator I5 from WB Database\n",
      "\n",
      "\u001b[1mScaling & Weighting Data....\u001b[0m\n",
      "\n",
      "**Successfully loaded , merged, scaled, and weighted Dimension I Data**\n",
      "\n",
      "\u001b[1mOverall Data Coverage:\u001b[0m(Weighted Mean missing if more than 2 indicators are missing for that Dimension..)\n",
      "ind_I1           0.940828\n",
      "ind_I2           0.763314\n",
      "ind_I3           0.893491\n",
      "ind_I4           0.343195\n",
      "ind_I5           0.934911\n",
      "weighted_mean    0.899408\n",
      "iso_a3           1.000000\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "    ---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "    \n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "    --------------------------Dimension C------------------------------\n",
      "\n",
      "    \n",
      "\u001b[1mLoading Data.....\n",
      "\u001b[0m\n",
      "Successfully loaded Indicator C1 from ACLED Database\n",
      "\n",
      "Successfully loaded Indicator C3 from OWiD Database\n",
      "\n",
      "Data for 'Intentional homicides' does not meet the coverage threshold of 85.0% in WB Database 2.\n",
      "        Extracting data from previous years.\n",
      "Data coverage at 84.21% after going back 10 years.\n",
      "            Failed to exceed minimum threshold of 85.0%. Returning best dataframe anyway.\n",
      "\n",
      "Successfully loaded Indicator C4 from WB Database\n",
      "\n",
      "\u001b[1mScaling & Weighting Data....\u001b[0m\n",
      "\n",
      "**Successfully loaded , merged, scaled, and weighted Dimension C Data**\n",
      "\n",
      "\u001b[1mOverall Data Coverage:\u001b[0m(Weighted Mean missing if more than 2 indicators are missing for that Dimension..)\n",
      "ind_C1           1.000000\n",
      "ind_C3           0.936782\n",
      "ind_C4           0.816092\n",
      "weighted_mean    1.000000\n",
      "iso_a3           1.000000\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "    ---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "    \n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "    --------------------------Dimension E------------------------------\n",
      "\n",
      "    \n",
      "\u001b[1mLoading Data.....\n",
      "\u001b[0m\n",
      "Successfully loaded Indicator E1 from ND Database\n",
      "\n",
      "\u001b[1mScaling & Weighting Data....\u001b[0m\n",
      "\n",
      "**Successfully loaded , merged, scaled, and weighted Dimension E Data**\n",
      "\n",
      "\u001b[1mOverall Data Coverage:\u001b[0m(Weighted Mean missing if more than 2 indicators are missing for that Dimension..)\n",
      "ind_E1           1.0\n",
      "weighted_mean    1.0\n",
      "iso_a3           1.0\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "    ---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "    \n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "    --------------------------Dimension R------------------------------\n",
      "\n",
      "    \n",
      "\u001b[1mLoading Data.....\n",
      "\u001b[0m\n",
      "Successfully loaded Indicator R1 from ACLED Database\n",
      "\n",
      "Successfully loaded Indicator R2 from UNHCR Database\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 'Total Natural Resources Rents' found in WB Database 2. Returning data for the most recent year. \n",
      "        Coverage = 92.11%, greater than selected threshold of 85.0%.\n",
      "\n",
      "Successfully loaded Indicator R3 from WB Database\n",
      "\n",
      "\u001b[1mScaling & Weighting Data....\u001b[0m\n",
      "\n",
      "**Successfully loaded , merged, scaled, and weighted Dimension R Data**\n",
      "\n",
      "\u001b[1mOverall Data Coverage:\u001b[0m(Weighted Mean missing if more than 2 indicators are missing for that Dimension..)\n",
      "ind_R1           0.954023\n",
      "ind_R2           0.879310\n",
      "ind_R3           0.913793\n",
      "weighted_mean    0.994253\n",
      "iso_a3           1.000000\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "    ---------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "    \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "all_the_data_dictionary = all_the_data(indicator_dictionary, manual_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf1944f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for key in all_the_data_dictionary.keys():\n",
    "    \n",
    "    df = all_the_data_dictionary[key]\n",
    "    \n",
    "    df.to_csv(f\"../upload_data/dim_{key}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3b8732",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## OECD Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bffc6c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "compare_df.to_csv(\"../upload_data/compare_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4549e075",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbf5c83",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b799c8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dd75e9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594f4f2c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db34de7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99757db9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9debf9c4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b209fc0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa75791",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1a9e86",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d0a457",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_the_data_dictionary = all_the_data(indicator_dictionary, manual_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35029692",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# PCA Methodology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d33963",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_the_data_dictionary['G']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032738c4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ed7b00",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376e983e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = all_the_data_dictionary['G'].drop(columns=['weighted_mean', 'iso_a3', 'ind_G5']).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dbe9e0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cfb51e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_dim_x = pd.read_csv(\"../upload_data/full_df.csv\").drop(columns=['weighted_mean', 'iso', 'country-code']).dropna().set_index('name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b030147",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.read_csv(\"../upload_data/dim_G.csv\").drop(columns=['weighted_mean', 'iso_a3', 'ind_G5']).dropna().set_index('name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc659ba",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b2a863",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "\n",
    "principalComponents = pca.fit_transform(x.values)\n",
    "\n",
    "\n",
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['principal component 1', 'principal component 2'], index = x.index).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3504fc1c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(principalDf,\n",
    "                 x='principal component 1',\n",
    "                 y='principal component 2',\n",
    "                 hover_name='name',  \n",
    "                 title='Scatter plot of Principal Components')\n",
    "\n",
    "fig.update_traces(marker=dict(size=10),\n",
    "                  selector=dict(mode='markers'))  # Optional: Adjust the marker size\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273d7d82",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## CLustering??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda44525",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import Birch, KMeans\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "\n",
    "def pca_and_clustering(df_of_indicators, model_choice = \"Birch\", num_of_clusters = 5, random_state = False):\n",
    "    \n",
    "    pca = PCA(n_components=2)\n",
    "\n",
    "    principalComponents = pca.fit_transform(df_of_indicators.values)\n",
    "    \n",
    "    principalDf = pd.DataFrame(data = principalComponents,\\\n",
    "                               columns = ['principal component 1', 'principal component 2'],\\\n",
    "                               index = df_of_indicators.index).reset_index()\n",
    "    \n",
    "    X = principalDf.drop(columns=['name']).values\n",
    "    \n",
    "    if model_choice == \"Birch\":\n",
    "        if random_state:\n",
    "            model = Birch(n_clusters=num_of_clusters, random_state = 25)\n",
    "        else:\n",
    "            model = Birch(n_clusters=num_of_clusters)\n",
    "    if model_choice == \"KMeans\":\n",
    "        if random_state:\n",
    "            model = KMeans(n_clusters=num_of_clusters, random_state=25)\n",
    "        else:\n",
    "            model = KMeans(n_clusters=num_of_clusters)\n",
    "    if model_choice == \"GaussianMixture\":\n",
    "        if random_state:\n",
    "            model = GaussianMixture(n_components=num_of_clusters, random_state=25)\n",
    "        else:\n",
    "            model = GaussianMixture(n_components=num_of_clusters)\n",
    "    model.fit(X)\n",
    "    yhat = model.predict(X)  \n",
    "    principalDf = pd.concat([pd.DataFrame(yhat, columns=['Cluster']), principalDf], axis=1)\n",
    "    principalDf['Cluster'] = principalDf['Cluster'].astype(str)\n",
    "    fig = px.scatter(principalDf,\n",
    "                 x='principal component 1',\n",
    "                 y='principal component 2',\n",
    "                 hover_name='name',\n",
    "                 color = 'Cluster',\n",
    "                 title='Scatter plot of Principal Components')\n",
    "\n",
    "    fig.update_traces(marker=dict(size=10), selector=dict(mode='markers'))  \n",
    "\n",
    "    fig.show()\n",
    "pca_and_clustering(all_dim_x, model_choice= \"GaussianMixture\",num_of_clusters=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06016af3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "\n",
    "principalComponents = pca.fit_transform(x.values)\n",
    "\n",
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['principal component 1', 'principal component 2'], index = x.index).reset_index()\n",
    "\n",
    "principalDf\n",
    "\n",
    "X = principalDf.drop(columns=['name']).values\n",
    "\n",
    "model = Birch(n_clusters=6)\n",
    "\n",
    "model.fit(X)\n",
    "\n",
    "yhat = model.predict(X)\n",
    "\n",
    "\n",
    "principalDf = pd.concat([pd.DataFrame(yhat, columns=['Cluster']), principalDf], axis=1)\n",
    "principalDf['Cluster'] = principalDf['Cluster'].astype(str)\n",
    "\n",
    "\n",
    "\n",
    "fig = px.scatter(principalDf,\n",
    "                 x='principal component 1',\n",
    "                 y='principal component 2',\n",
    "                 hover_name='name',\n",
    "                 color = 'Cluster',\n",
    "                 title='Scatter plot of Principal Components')\n",
    "\n",
    "fig.update_traces(marker=dict(size=10),\n",
    "                  selector=dict(mode='markers'))  \n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6505355c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4e8446",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc148697",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646ab9ec",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8af353f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d66058",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd26dd5e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c9737f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42439abc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec171e4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020fb6b5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa2ee14",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf4ff68c",
   "metadata": {},
   "source": [
    "# Visuallizing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18f90c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ind_G1</th>\n",
       "      <th>ind_G2</th>\n",
       "      <th>ind_G3</th>\n",
       "      <th>ind_G4</th>\n",
       "      <th>ind_G5</th>\n",
       "      <th>ind_G6</th>\n",
       "      <th>ind_G7</th>\n",
       "      <th>weighted_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Denmark</th>\n",
       "      <td>1.234519</td>\n",
       "      <td>0.785184</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.972645</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.211435</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.814826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sweden</th>\n",
       "      <td>1.386573</td>\n",
       "      <td>0.897720</td>\n",
       "      <td>0.839809</td>\n",
       "      <td>0.873597</td>\n",
       "      <td>0.563604</td>\n",
       "      <td>0.257850</td>\n",
       "      <td>0.483556</td>\n",
       "      <td>0.757530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Zealand</th>\n",
       "      <td>1.225935</td>\n",
       "      <td>0.532047</td>\n",
       "      <td>0.887561</td>\n",
       "      <td>0.893256</td>\n",
       "      <td>0.710350</td>\n",
       "      <td>0.323186</td>\n",
       "      <td>0.460946</td>\n",
       "      <td>0.719040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Taiwan</th>\n",
       "      <td>1.400674</td>\n",
       "      <td>0.670220</td>\n",
       "      <td>0.410776</td>\n",
       "      <td>0.670174</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.391059</td>\n",
       "      <td>0.708581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Norway</th>\n",
       "      <td>1.003372</td>\n",
       "      <td>0.790582</td>\n",
       "      <td>0.842675</td>\n",
       "      <td>0.907566</td>\n",
       "      <td>0.440850</td>\n",
       "      <td>0.234211</td>\n",
       "      <td>0.486639</td>\n",
       "      <td>0.672271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Haiti</th>\n",
       "      <td>-1.152974</td>\n",
       "      <td>-0.698826</td>\n",
       "      <td>-0.813682</td>\n",
       "      <td>-0.571521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.196814</td>\n",
       "      <td>-0.608038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eritrea</th>\n",
       "      <td>-0.919375</td>\n",
       "      <td>-0.399541</td>\n",
       "      <td>-0.730584</td>\n",
       "      <td>-0.757154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.457862</td>\n",
       "      <td>-0.652903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Turkmenistan</th>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-0.596816</td>\n",
       "      <td>-0.803226</td>\n",
       "      <td>-0.625641</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.077762</td>\n",
       "      <td>-0.473279</td>\n",
       "      <td>-0.679454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Venezuela</th>\n",
       "      <td>-0.788167</td>\n",
       "      <td>-0.671030</td>\n",
       "      <td>-0.903901</td>\n",
       "      <td>-0.957769</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.234841</td>\n",
       "      <td>-0.711141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Palestine</th>\n",
       "      <td>-0.050582</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.458460</td>\n",
       "      <td>-0.183120</td>\n",
       "      <td>0.233810</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ind_G1    ind_G2    ind_G3    ind_G4    ind_G5    ind_G6  \\\n",
       "name                                                                       \n",
       "Denmark       1.234519  0.785184  1.000000  0.972645  1.000000  0.211435   \n",
       "Sweden        1.386573  0.897720  0.839809  0.873597  0.563604  0.257850   \n",
       "New Zealand   1.225935  0.532047  0.887561  0.893256  0.710350  0.323186   \n",
       "Taiwan        1.400674  0.670220  0.410776  0.670174       NaN       NaN   \n",
       "Norway        1.003372  0.790582  0.842675  0.907566  0.440850  0.234211   \n",
       "...                ...       ...       ...       ...       ...       ...   \n",
       "Haiti        -1.152974 -0.698826 -0.813682 -0.571521       NaN       NaN   \n",
       "Eritrea      -0.919375 -0.399541 -0.730584 -0.757154       NaN       NaN   \n",
       "Turkmenistan -1.500000 -0.596816 -0.803226 -0.625641       NaN -0.077762   \n",
       "Venezuela    -0.788167 -0.671030 -0.903901 -0.957769       NaN       NaN   \n",
       "Palestine    -0.050582       NaN -0.458460 -0.183120  0.233810       NaN   \n",
       "\n",
       "                ind_G7  weighted_mean  \n",
       "name                                   \n",
       "Denmark       0.500000       0.814826  \n",
       "Sweden        0.483556       0.757530  \n",
       "New Zealand   0.460946       0.719040  \n",
       "Taiwan        0.391059       0.708581  \n",
       "Norway        0.486639       0.672271  \n",
       "...                ...            ...  \n",
       "Haiti         0.196814      -0.608038  \n",
       "Eritrea      -0.457862      -0.652903  \n",
       "Turkmenistan -0.473279      -0.679454  \n",
       "Venezuela    -0.234841      -0.711141  \n",
       "Palestine          NaN            NaN  \n",
       "\n",
       "[164 rows x 8 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimension = 'G'\n",
    "\n",
    "dim_df = pd.read_csv(f'../upload_data/dim_{dimension}.csv').set_index('name').drop(columns=['iso_a3'])\n",
    "\n",
    "dim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e910324",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5e5007",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a69e7e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ind_G1</th>\n",
       "      <th>ind_G2</th>\n",
       "      <th>ind_G3</th>\n",
       "      <th>ind_G4</th>\n",
       "      <th>ind_G5</th>\n",
       "      <th>ind_G6</th>\n",
       "      <th>ind_G7</th>\n",
       "      <th>weighted_mean</th>\n",
       "      <th>iso_a3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Denmark</th>\n",
       "      <td>1.234519</td>\n",
       "      <td>0.785184</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.972645</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.211435</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.814826</td>\n",
       "      <td>DNK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sweden</th>\n",
       "      <td>1.386573</td>\n",
       "      <td>0.897720</td>\n",
       "      <td>0.839809</td>\n",
       "      <td>0.873597</td>\n",
       "      <td>0.563604</td>\n",
       "      <td>0.257850</td>\n",
       "      <td>0.483556</td>\n",
       "      <td>0.757530</td>\n",
       "      <td>SWE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Zealand</th>\n",
       "      <td>1.225935</td>\n",
       "      <td>0.532047</td>\n",
       "      <td>0.887561</td>\n",
       "      <td>0.893256</td>\n",
       "      <td>0.710350</td>\n",
       "      <td>0.323186</td>\n",
       "      <td>0.460946</td>\n",
       "      <td>0.719040</td>\n",
       "      <td>NZL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Taiwan</th>\n",
       "      <td>1.400674</td>\n",
       "      <td>0.670220</td>\n",
       "      <td>0.410776</td>\n",
       "      <td>0.670174</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.391059</td>\n",
       "      <td>0.708581</td>\n",
       "      <td>TWN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Norway</th>\n",
       "      <td>1.003372</td>\n",
       "      <td>0.790582</td>\n",
       "      <td>0.842675</td>\n",
       "      <td>0.907566</td>\n",
       "      <td>0.440850</td>\n",
       "      <td>0.234211</td>\n",
       "      <td>0.486639</td>\n",
       "      <td>0.672271</td>\n",
       "      <td>NOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Haiti</th>\n",
       "      <td>-1.152974</td>\n",
       "      <td>-0.698826</td>\n",
       "      <td>-0.813682</td>\n",
       "      <td>-0.571521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.196814</td>\n",
       "      <td>-0.608038</td>\n",
       "      <td>HTI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eritrea</th>\n",
       "      <td>-0.919375</td>\n",
       "      <td>-0.399541</td>\n",
       "      <td>-0.730584</td>\n",
       "      <td>-0.757154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.457862</td>\n",
       "      <td>-0.652903</td>\n",
       "      <td>ERI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Turkmenistan</th>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-0.596816</td>\n",
       "      <td>-0.803226</td>\n",
       "      <td>-0.625641</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.077762</td>\n",
       "      <td>-0.473279</td>\n",
       "      <td>-0.679454</td>\n",
       "      <td>TKM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Venezuela</th>\n",
       "      <td>-0.788167</td>\n",
       "      <td>-0.671030</td>\n",
       "      <td>-0.903901</td>\n",
       "      <td>-0.957769</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.234841</td>\n",
       "      <td>-0.711141</td>\n",
       "      <td>VEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Palestine</th>\n",
       "      <td>-0.050582</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.458460</td>\n",
       "      <td>-0.183120</td>\n",
       "      <td>0.233810</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PSE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ind_G1    ind_G2    ind_G3    ind_G4    ind_G5    ind_G6  \\\n",
       "name                                                                       \n",
       "Denmark       1.234519  0.785184  1.000000  0.972645  1.000000  0.211435   \n",
       "Sweden        1.386573  0.897720  0.839809  0.873597  0.563604  0.257850   \n",
       "New Zealand   1.225935  0.532047  0.887561  0.893256  0.710350  0.323186   \n",
       "Taiwan        1.400674  0.670220  0.410776  0.670174       NaN       NaN   \n",
       "Norway        1.003372  0.790582  0.842675  0.907566  0.440850  0.234211   \n",
       "...                ...       ...       ...       ...       ...       ...   \n",
       "Haiti        -1.152974 -0.698826 -0.813682 -0.571521       NaN       NaN   \n",
       "Eritrea      -0.919375 -0.399541 -0.730584 -0.757154       NaN       NaN   \n",
       "Turkmenistan -1.500000 -0.596816 -0.803226 -0.625641       NaN -0.077762   \n",
       "Venezuela    -0.788167 -0.671030 -0.903901 -0.957769       NaN       NaN   \n",
       "Palestine    -0.050582       NaN -0.458460 -0.183120  0.233810       NaN   \n",
       "\n",
       "                ind_G7  weighted_mean iso_a3  \n",
       "name                                          \n",
       "Denmark       0.500000       0.814826    DNK  \n",
       "Sweden        0.483556       0.757530    SWE  \n",
       "New Zealand   0.460946       0.719040    NZL  \n",
       "Taiwan        0.391059       0.708581    TWN  \n",
       "Norway        0.486639       0.672271    NOR  \n",
       "...                ...            ...    ...  \n",
       "Haiti         0.196814      -0.608038    HTI  \n",
       "Eritrea      -0.457862      -0.652903    ERI  \n",
       "Turkmenistan -0.473279      -0.679454    TKM  \n",
       "Venezuela    -0.234841      -0.711141    VEN  \n",
       "Palestine          NaN            NaN    PSE  \n",
       "\n",
       "[164 rows x 9 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_the_data_dictionary['G']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b6329c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4118137e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405c96cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969ed95a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009997e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4ff7ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead51f55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321f44fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc570e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4dbf57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9334c16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07cc471",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_X_complete(indicator_dictionary, \"R\", manual_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccf70de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_individual_indicators(dimension_df):\n",
    "    \n",
    "    just_ind_df = dimension_df.drop(columns='weighted_mean')\n",
    "\n",
    "    world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "    geo_merge = world.merge(just_ind_df, left_on = 'name', right_index = True)\n",
    "\n",
    "    nrows, ncols = 4, 2\n",
    "\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(15, 10))\n",
    "\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, column in enumerate(just_ind_df.columns):\n",
    "        geo_merge.plot(column=column, cmap='RdYlGn', missing_kwds={'color': 'black'}, ax=axes[idx])\n",
    "        axes[idx].set_title(f'Map for {column}')\n",
    "        axes[idx].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d2f23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_individual_indicators(dim_X_complete(indicator_dictionary, 'R', manual_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
